{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <h1>\n",
    "        VSL RL : SUMO Simulation\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmae/opt/anaconda3/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('C:\\PHD\\Workspace\\gym_sumo_vsl_maroc\\gym_sumo\\envs')\n",
    "from utils import plot_policy, plot_action_values, test_agent\n",
    "import SUMOInitializeEnv\n",
    "import gym\n",
    "import sumo_env as env\n",
    "import ql_agent as QLAgent\n",
    "import epsilon_greedy as EpsilonGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gym.envs.registration import register\n",
    "from SUMOInitializeEnv import SUMOEnv_Initializer\n",
    "register(\n",
    "    id='SumoGUI-v0',\n",
    "    entry_point='SUMOInitializeEnv:SUMOEnv_Initializer'\n",
    ")\n",
    "env = gym.make('SumoGUI-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_grid(low,high, bins=(500,500)):\n",
    "        grid= []\n",
    "        for i, lower_upper in enumerate(zip(low,high)):\n",
    "            grid_column= np.linspace(lower_upper[0], lower_upper[1], bins[i]+1)\n",
    "            grid.append(grid_column)\n",
    "        return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 9.110400871461584\n",
      "current reward: 9.110400871461584; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 10.161682553371627\n",
      "current reward: 10.161682553371627; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[2.03233651 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 11.324628263615253\n",
      "current reward: 11.324628263615253; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[4.29726216 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 9.705181882198413\n",
      "current reward: 9.705181882198413; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (15, 3)\n",
      "act action : 19\n",
      "reward: 10.849314540622425\n",
      "current reward: 10.849314540622425; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "[2.16986291 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (15, 3)\n",
      "act action : 19\n",
      "reward: 12.002380403063084\n",
      "current reward: 12.002380403063084; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "[4.57033899 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (15, 3)\n",
      "act action : 19\n",
      "reward: 10.902577266070486\n",
      "current reward: 10.902577266070486; current state: [4.0, 0.005688282138794083]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (19, 3)\n",
      "act action : 19\n",
      "reward: 11.431341511697582\n",
      "current reward: 11.431341511697582; current state: [4.0, 0.005688282138794083]\n",
      "maximizing action\n",
      "[2.2862683 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (19, 3)\n",
      "act action : 19\n",
      "reward: 12.42018099684753\n",
      "current reward: 12.42018099684753; current state: [4.0, 0.005688282138794083]\n",
      "maximizing action\n",
      "[4.7703045 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (19, 3)\n",
      "act action : 19\n",
      "reward: 12.937414911543053\n",
      "current reward: 12.937414911543053; current state: [5.0, 0.007110352673492606]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (23, 3)\n",
      "act action : 19\n",
      "reward: 11.849434860615267\n",
      "current reward: 11.849434860615267; current state: [6.0, 0.008532423208191125]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (27, 3)\n",
      "act action : 19\n",
      "reward: 12.885426647580823\n",
      "current reward: 12.885426647580823; current state: [5.814814814814815, 0.16989784903164776]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (25, 3)\n",
      "act action : 19\n",
      "reward: 13.933698583840522\n",
      "current reward: 13.933698583840522; current state: [5.814814814814815, 0.008532423208191125]\n",
      "maximizing action\n",
      "[2.78673972 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (25, 3)\n",
      "act action : 19\n",
      "reward: 15.184865531355426\n",
      "current reward: 15.184865531355426; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (31, 3)\n",
      "act action : 19\n",
      "reward: 15.919263035445093\n",
      "current reward: 15.919263035445093; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "[3.18385261 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (31, 3)\n",
      "act action : 19\n",
      "reward: 15.234162286575062\n",
      "current reward: 15.234162286575062; current state: [8.0, 0.011376564277588166]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (35, 3)\n",
      "act action : 19\n",
      "reward: 15.59893355473533\n",
      "current reward: 15.59893355473533; current state: [8.0, 0.011376564277588166]\n",
      "maximizing action\n",
      "[3.11978671 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (35, 3)\n",
      "act action : 19\n",
      "reward: 16.12573893921288\n",
      "current reward: 16.12573893921288; current state: [8.407407407407407, 1.828532400685563]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (35, 9)\n",
      "act action : 19\n",
      "reward: 16.95137641272017\n",
      "current reward: 16.95137641272017; current state: [8.407407407407407, 0.012798634812286692]\n",
      "maximizing action\n",
      "[6.3449345 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (35, 3)\n",
      "act action : 19\n",
      "reward: 17.906022624584025\n",
      "current reward: 17.906022624584025; current state: [8.703703703703704, 0.8101435599656912]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (37, 5)\n",
      "act action : 19\n",
      "reward: 17.752229656107463\n",
      "current reward: 17.752229656107463; current state: [8.666666666666666, 5.737227704709428]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (37, 25)\n",
      "act action : 19\n",
      "reward: 18.55808558092287\n",
      "current reward: 18.55808558092287; current state: [10.0, 0.01422070534698521]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (43, 3)\n",
      "act action : 19\n",
      "reward: 18.14375190575696\n",
      "current reward: 18.14375190575696; current state: [10.62962962962963, 1.9423339336482224]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (45, 9)\n",
      "act action : 19\n",
      "reward: 18.907767604130182\n",
      "current reward: 18.907767604130182; current state: [11.0, 0.01564277588168373]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (47, 3)\n",
      "act action : 19\n",
      "reward: 19.823139897370528\n",
      "current reward: 19.823139897370528; current state: [11.0, 0.01564277588168373]\n",
      "maximizing action\n",
      "[3.96462798 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (47, 3)\n",
      "act action : 19\n",
      "reward: 21.063094094524995\n",
      "current reward: 21.063094094524995; current state: [11.185185185185185, 4.159135506636833]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (47, 19)\n",
      "act action : 19\n",
      "reward: 21.816316852111623\n",
      "current reward: 21.816316852111623; current state: [10.777777777777779, 0.18213454412558366]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (45, 3)\n",
      "act action : 19\n",
      "reward: 21.781085440918222\n",
      "current reward: 21.781085440918222; current state: [12.11111111111111, 1.8148819059648924]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (51, 9)\n",
      "act action : 19\n",
      "reward: 22.370776135168665\n",
      "current reward: 22.370776135168665; current state: [13.0, 0.018486916951080776]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (55, 3)\n",
      "act action : 19\n",
      "reward: 22.386136978100215\n",
      "current reward: 22.386136978100215; current state: [12.555555555555555, 4.808890580233308]\n",
      "exploring action\n",
      "Current action = 33, current state (53, 21)\n",
      "act action : 33\n",
      "reward: 22.711397092479274\n",
      "current reward: 22.711397092479274; current state: [13.037037037037036, 1.8420925486289135]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (55, 9)\n",
      "act action : 19\n",
      "reward: 23.423262146634475\n",
      "current reward: 23.423262146634475; current state: [13.518518518518519, 1.2535058203632274]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (57, 7)\n",
      "act action : 19\n",
      "reward: 22.62842937120053\n",
      "current reward: 22.62842937120053; current state: [13.444444444444445, 3.192157016791696]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (55, 15)\n",
      "act action : 19\n",
      "reward: 23.298257154367878\n",
      "current reward: 23.298257154367878; current state: [13.962962962962964, 0.021331058020477824]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (57, 3)\n",
      "act action : 19\n",
      "reward: 26.520200748929387\n",
      "current reward: 26.520200748929387; current state: [15.0, 0.021331058020477824]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (63, 3)\n",
      "act action : 19\n",
      "reward: 24.17425684366256\n",
      "current reward: 24.17425684366256; current state: [16.0, 0.022753128555176333]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (67, 3)\n",
      "act action : 19\n",
      "reward: 24.641445308524435\n",
      "current reward: 24.641445308524435; current state: [15.814814814814815, 1.4040592367870905]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (65, 7)\n",
      "act action : 19\n",
      "reward: 25.136010213669213\n",
      "current reward: 25.136010213669213; current state: [14.037037037037036, 5.403282060883311]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (59, 23)\n",
      "act action : 19\n",
      "reward: 25.508777083442123\n",
      "current reward: 25.508777083442123; current state: [16.40740740740741, 2.1291705802394096]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (67, 11)\n",
      "act action : 19\n",
      "reward: 24.926263651488195\n",
      "current reward: 24.926263651488195; current state: [17.37037037037037, 0.09928542797355984]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (71, 3)\n",
      "act action : 19\n",
      "reward: 25.570385417193517\n",
      "current reward: 25.570385417193517; current state: [16.74074074074074, 1.8728827335766738]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (69, 9)\n",
      "act action : 19\n",
      "reward: 25.058245537923636\n",
      "current reward: 25.058245537923636; current state: [17.0, 2.1820119874709207]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (71, 11)\n",
      "act action : 19\n",
      "reward: 25.52680899244182\n",
      "current reward: 25.52680899244182; current state: [17.0, 2.0121013874781926]\n",
      "maximizing action\n",
      "[5.1053618 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (71, 11)\n",
      "act action : 19\n",
      "reward: 26.007147884452213\n",
      "current reward: 26.007147884452213; current state: [18.333333333333332, 1.9499006942849464]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (75, 9)\n",
      "act action : 19\n",
      "reward: 25.284536709668455\n",
      "current reward: 25.284536709668455; current state: [20.0, 0.02844141069397042]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (83, 3)\n",
      "act action : 19\n",
      "reward: 25.782422023692522\n",
      "current reward: 25.782422023692522; current state: [19.296296296296298, 2.341838467305168]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (79, 11)\n",
      "act action : 19\n",
      "reward: 27.578428656129972\n",
      "current reward: 27.578428656129972; current state: [18.037037037037038, 5.427805475604499]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (75, 23)\n",
      "act action : 19\n",
      "reward: 28.055624352377325\n",
      "current reward: 28.055624352377325; current state: [18.037037037037038, 1.2254757471916096]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (75, 7)\n",
      "act action : 19\n",
      "reward: 24.83654168461874\n",
      "current reward: 24.83654168461874; current state: [19.666666666666668, 0.12696346498356315]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (81, 3)\n",
      "act action : 19\n",
      "reward: 25.236625104348278\n",
      "current reward: 25.236625104348278; current state: [18.11111111111111, 7.279823737883521]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (75, 31)\n",
      "act action : 19\n",
      "reward: 29.280252754161353\n",
      "current reward: 29.280252754161353; current state: [20.444444444444443, 1.8515056708989799]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (83, 9)\n",
      "act action : 19\n",
      "reward: 26.476282787951902\n",
      "current reward: 26.476282787951902; current state: [22.185185185185187, 2.140883649285765]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 11)\n",
      "act action : 19\n",
      "reward: 27.72007058184751\n",
      "current reward: 27.72007058184751; current state: [18.925925925925927, 7.416202319051076]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 31)\n",
      "act action : 19\n",
      "reward: 25.090061802621637\n",
      "current reward: 25.090061802621637; current state: [22.296296296296298, 0.0341296928327645]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 3)\n",
      "act action : 19\n",
      "reward: 25.555129541943675\n",
      "current reward: 25.555129541943675; current state: [24.0, 0.0341296928327645]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 3)\n",
      "act action : 19\n",
      "reward: 25.95699230354875\n",
      "current reward: 25.95699230354875; current state: [22.296296296296298, 4.337507560747985]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 19)\n",
      "act action : 19\n",
      "reward: 25.268128049653015\n",
      "current reward: 25.268128049653015; current state: [23.22222222222222, 3.4953713762941465]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 15)\n",
      "act action : 19\n",
      "reward: 27.57627688387055\n",
      "current reward: 27.57627688387055; current state: [22.333333333333332, 2.4196585483809976]\n",
      "maximizing action\n",
      "[5.54401412 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (91, 11)\n",
      "act action : 19\n",
      "reward: 25.0712002485777\n",
      "current reward: 25.0712002485777; current state: [21.37037037037037, 8.019967850421331]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 35)\n",
      "act action : 19\n",
      "reward: 25.459756386930906\n",
      "current reward: 25.459756386930906; current state: [22.296296296296298, 3.907854865186531]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 17)\n",
      "act action : 19\n",
      "reward: 25.87428215606081\n",
      "current reward: 25.87428215606081; current state: [24.14814814814815, 3.7027874029877643]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 17)\n",
      "act action : 19\n",
      "reward: 28.755070003576208\n",
      "current reward: 28.755070003576208; current state: [24.11111111111111, 3.8031989944034765]\n",
      "maximizing action\n",
      "[5.751014 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (99, 17)\n",
      "act action : 19\n",
      "reward: 25.686231817572267\n",
      "current reward: 25.686231817572267; current state: [24.11111111111111, 3.6656191601033066]\n",
      "maximizing action\n",
      "[10.88826036  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 17)\n",
      "act action : 19\n",
      "reward: 27.406744360231375\n",
      "current reward: 27.406744360231375; current state: [23.0, 6.04758557357873]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 27)\n",
      "act action : 19\n",
      "reward: 25.65637240699749\n",
      "current reward: 25.65637240699749; current state: [24.0, 2.412701808634747]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 11)\n",
      "act action : 19\n",
      "reward: 27.16517221902718\n",
      "current reward: 27.16517221902718; current state: [27.962962962962962, 0.041240045506257116]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 3)\n",
      "act action : 19\n",
      "reward: 27.6513865044634\n",
      "current reward: 27.6513865044634; current state: [25.88888888888889, 4.720835227906285]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 21)\n",
      "act action : 19\n",
      "reward: 26.009498002227343\n",
      "current reward: 26.009498002227343; current state: [27.962962962962962, 0.041240045506257116]\n",
      "maximizing action\n",
      "[5.5302773 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (113, 3)\n",
      "act action : 19\n",
      "reward: 25.519523646753992\n",
      "current reward: 25.519523646753992; current state: [26.77777777777778, 3.5592583240991864]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 17)\n",
      "act action : 19\n",
      "reward: 28.788518878351592\n",
      "current reward: 28.788518878351592; current state: [24.62962962962963, 4.766093680474432]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 21)\n",
      "act action : 19\n",
      "reward: 25.477020448813548\n",
      "current reward: 25.477020448813548; current state: [26.555555555555557, 3.5830300378184465]\n",
      "maximizing action\n",
      "[5.75770378 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 17)\n",
      "act action : 19\n",
      "reward: 27.878734744270307\n",
      "current reward: 27.878734744270307; current state: [28.77777777777778, 3.658378083357466]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 25.659612745068227\n",
      "current reward: 25.659612745068227; current state: [28.555555555555557, 2.458770698173098]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 26.00552194608868\n",
      "current reward: 26.00552194608868; current state: [29.703703703703702, 1.073984816716769]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 7)\n",
      "act action : 19\n",
      "reward: 26.35259886963718\n",
      "current reward: 26.35259886963718; current state: [28.555555555555557, 3.9513362338778215]\n",
      "maximizing action\n",
      "[5.13192255 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 25.990321794386983\n",
      "current reward: 25.990321794386983; current state: [27.074074074074073, 9.505660373516283]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 41)\n",
      "act action : 19\n",
      "reward: 26.30617610462568\n",
      "current reward: 26.30617610462568; current state: [28.25925925925926, 1.7971842139559178]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 9)\n",
      "act action : 19\n",
      "reward: 28.512057593446638\n",
      "current reward: 28.512057593446638; current state: [28.25925925925926, 4.118493420891992]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 26.683380936954645\n",
      "current reward: 26.683380936954645; current state: [31.814814814814813, 1.8098579335699814]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 9)\n",
      "act action : 19\n",
      "reward: 26.857596360452316\n",
      "current reward: 26.857596360452316; current state: [23.51851851851852, 7.9167132446384]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 33)\n",
      "act action : 19\n",
      "reward: 28.420031770161927\n",
      "current reward: 28.420031770161927; current state: [25.444444444444443, 0.04835039817974972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 3)\n",
      "act action : 19\n",
      "reward: 26.721050224962628\n",
      "current reward: 26.721050224962628; current state: [32.77777777777778, 0.16120082394894025]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 3)\n",
      "act action : 19\n",
      "reward: 26.326357889740127\n",
      "current reward: 26.326357889740127; current state: [31.22222222222222, 3.745830805481946]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 17)\n",
      "act action : 19\n",
      "reward: 26.619659419565306\n",
      "current reward: 26.619659419565306; current state: [29.962962962962962, 4.628551609625601]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 28.596060332220546\n",
      "current reward: 28.596060332220546; current state: [29.51851851851852, 1.6520601541045636]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 9)\n",
      "act action : 19\n",
      "reward: 26.9088608000331\n",
      "current reward: 26.9088608000331; current state: [29.51851851851852, 2.0121291961622827]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 29.018268760428573\n",
      "current reward: 29.018268760428573; current state: [30.814814814814813, 3.5639269909279596]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 17)\n",
      "act action : 19\n",
      "reward: 26.73003580659146\n",
      "current reward: 26.73003580659146; current state: [29.51851851851852, 4.122141245605989]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 26.959485296637414\n",
      "current reward: 26.959485296637414; current state: [28.703703703703702, 6.8554739482951765]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 28.948031559965457\n",
      "current reward: 28.948031559965457; current state: [29.51851851851852, 5.9148143494097205]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 27.39036000180998\n",
      "current reward: 27.39036000180998; current state: [29.51851851851852, 4.515899505909802]\n",
      "maximizing action\n",
      "[5.71921207 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 27.593887324001496\n",
      "current reward: 27.593887324001496; current state: [26.185185185185187, 6.558164841691693]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 30.758819528730168\n",
      "current reward: 30.758819528730168; current state: [32.111111111111114, 0.05119453924914677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 3)\n",
      "act action : 19\n",
      "reward: 27.78550680675509\n",
      "current reward: 27.78550680675509; current state: [32.48148148148148, 4.021912453106769]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 27.831135435604935\n",
      "current reward: 27.831135435604935; current state: [32.111111111111114, 2.9684178745818093]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 13)\n",
      "act action : 19\n",
      "reward: 28.12575688641796\n",
      "current reward: 28.12575688641796; current state: [28.22222222222222, 9.654188330617732]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 41)\n",
      "act action : 19\n",
      "reward: 28.731241566949652\n",
      "current reward: 28.731241566949652; current state: [32.111111111111114, 4.480184461539931]\n",
      "maximizing action\n",
      "[5.56622709 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 27.881560695221594\n",
      "current reward: 27.881560695221594; current state: [31.22222222222222, 3.4818458661749476]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 15)\n",
      "act action : 19\n",
      "reward: 28.10835774974449\n",
      "current reward: 28.10835774974449; current state: [27.444444444444443, 5.064811471546047]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 23)\n",
      "act action : 19\n",
      "reward: 27.970884778535815\n",
      "current reward: 27.970884778535815; current state: [29.51851851851852, 6.391872899156355]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 28.09457929649433\n",
      "current reward: 28.09457929649433; current state: [27.444444444444443, 8.729244884924052]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 37)\n",
      "act action : 19\n",
      "reward: 29.37820446137086\n",
      "current reward: 29.37820446137086; current state: [28.22222222222222, 6.756872936254275]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 27.860698065350203\n",
      "current reward: 27.860698065350203; current state: [31.22222222222222, 2.087972725330665]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 11)\n",
      "act action : 19\n",
      "reward: 27.912796876247914\n",
      "current reward: 27.912796876247914; current state: [29.962962962962962, 6.701516877933989]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 29.22889847620372\n",
      "current reward: 29.22889847620372; current state: [24.925925925925927, 7.762666191095581]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 33)\n",
      "act action : 19\n",
      "reward: 27.880251856034207\n",
      "current reward: 27.880251856034207; current state: [26.185185185185187, 5.635196481722348]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 30.944449644519253\n",
      "current reward: 30.944449644519253; current state: [30.814814814814813, 7.619539588706008]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 33)\n",
      "act action : 19\n",
      "reward: 27.84791292080153\n",
      "current reward: 27.84791292080153; current state: [27.88888888888889, 4.105852266198322]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 27.1733511271086\n",
      "current reward: 27.1733511271086; current state: [29.11111111111111, 1.8098224051522327]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 27.416749765021574\n",
      "current reward: 27.416749765021574; current state: [24.22222222222222, 10.125343102979198]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 43)\n",
      "act action : 19\n",
      "reward: 28.5588183618709\n",
      "current reward: 28.5588183618709; current state: [25.444444444444443, 3.7741267428224172]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 17)\n",
      "act action : 19\n",
      "reward: 27.52377322027611\n",
      "current reward: 27.52377322027611; current state: [21.77777777777778, 7.275753121946529]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 31)\n",
      "act action : 19\n",
      "reward: 27.78311365184376\n",
      "current reward: 27.78311365184376; current state: [24.22222222222222, 3.459920223207383]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 15)\n",
      "act action : 19\n",
      "reward: 27.436841679423065\n",
      "current reward: 27.436841679423065; current state: [31.555555555555557, 2.0740557468477543]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 11)\n",
      "act action : 19\n",
      "reward: 29.957764245248942\n",
      "current reward: 29.957764245248942; current state: [27.88888888888889, 6.563436781800949]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 29)\n",
      "act action : 19\n",
      "reward: 27.843114664313276\n",
      "current reward: 27.843114664313276; current state: [24.22222222222222, 8.351776647908192]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 35)\n",
      "act action : 19\n",
      "reward: 27.696309647912233\n",
      "current reward: 27.696309647912233; current state: [31.22222222222222, 0.9567528727197762]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 5)\n",
      "act action : 19\n",
      "reward: 27.88113839178027\n",
      "current reward: 27.88113839178027; current state: [27.88888888888889, 6.400425615225584]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 27.526544541996913\n",
      "current reward: 27.526544541996913; current state: [24.22222222222222, 9.143940448780704]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 39)\n",
      "act action : 19\n",
      "reward: 27.87196460908658\n",
      "current reward: 27.87196460908658; current state: [29.11111111111111, 0.07086338813365639]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 3)\n",
      "act action : 19\n",
      "reward: 27.429798789751572\n",
      "current reward: 27.429798789751572; current state: [26.185185185185187, 5.654417508610641]\n",
      "maximizing action\n",
      "[6.18888993 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 29.05841986875261\n",
      "current reward: 29.05841986875261; current state: [24.22222222222222, 6.709359312622787]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 29)\n",
      "act action : 19\n",
      "reward: 27.93463012097733\n",
      "current reward: 27.93463012097733; current state: [26.666666666666668, 5.987714301355863]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 27.95260738498135\n",
      "current reward: 27.95260738498135; current state: [26.185185185185187, 5.860678401247997]\n",
      "maximizing action\n",
      "[12.0005739  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 29.486465351098705\n",
      "current reward: 29.486465351098705; current state: [27.444444444444443, 6.274107747140726]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.073077156018737\n",
      "current reward: 28.073077156018737; current state: [29.51851851851852, 3.9171393176208835]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.546906564045685\n",
      "current reward: 29.546906564045685; current state: [27.444444444444443, 4.430260346485224]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 28.327318486859483\n",
      "current reward: 28.327318486859483; current state: [24.925925925925927, 9.972155031964698]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 41)\n",
      "act action : 19\n",
      "reward: 27.510253103983\n",
      "current reward: 27.510253103983; current state: [31.22222222222222, 2.418437585626334]\n",
      "maximizing action\n",
      "[5.58255938 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 11)\n",
      "act action : 19\n",
      "reward: 29.62143642135724\n",
      "current reward: 29.62143642135724; current state: [29.962962962962962, 6.262966028295698]\n",
      "maximizing action\n",
      "[5.61891586 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 28.376863417679292\n",
      "current reward: 28.376863417679292; current state: [28.703703703703702, 6.782474778123835]\n",
      "maximizing action\n",
      "[5.78960631 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 30.77788614656643\n",
      "current reward: 30.77788614656643; current state: [26.185185185185187, 5.533744770705961]\n",
      "maximizing action\n",
      "[17.89786697  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 28.125095199433716\n",
      "current reward: 28.125095199433716; current state: [29.51851851851852, 2.5570072639810495]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 28.1639361994793\n",
      "current reward: 28.1639361994793; current state: [25.444444444444443, 7.290233486925645]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 31)\n",
      "act action : 19\n",
      "reward: 28.310318576021675\n",
      "current reward: 28.310318576021675; current state: [26.666666666666668, 5.752726005985547]\n",
      "maximizing action\n",
      "[5.59052148 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 28.440222089408604\n",
      "current reward: 28.440222089408604; current state: [26.185185185185187, 8.065462266239328]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 28.71857789572297\n",
      "current reward: 28.71857789572297; current state: [29.962962962962962, 2.473964805788193]\n",
      "maximizing action\n",
      "[5.80365375 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 28.56935627653267\n",
      "current reward: 28.56935627653267; current state: [28.22222222222222, 6.103222494147372]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 28.920195862107573\n",
      "current reward: 28.920195862107573; current state: [28.22222222222222, 4.015154113369546]\n",
      "maximizing action\n",
      "[5.33667619 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 28.860899407132006\n",
      "current reward: 28.860899407132006; current state: [33.407407407407405, 4.067532428642243]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 19)\n",
      "act action : 19\n",
      "reward: 26.769771676922336\n",
      "current reward: 26.769771676922336; current state: [32.111111111111114, 3.120036682263999]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 15)\n",
      "act action : 19\n",
      "reward: 29.048586492814916\n",
      "current reward: 29.048586492814916; current state: [25.62962962962963, 9.181311089572548]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 39)\n",
      "act action : 19\n",
      "reward: 28.546030121457207\n",
      "current reward: 28.546030121457207; current state: [30.333333333333332, 7.437850662766897]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 31)\n",
      "act action : 19\n",
      "reward: 27.429616775953463\n",
      "current reward: 27.429616775953463; current state: [32.111111111111114, 2.3961682580676933]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 28.874894107672088\n",
      "current reward: 28.874894107672088; current state: [29.0, 6.819417965931644]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 29.08119857199503\n",
      "current reward: 29.08119857199503; current state: [28.22222222222222, 4.801718949103362]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 28.99102450553377\n",
      "current reward: 28.99102450553377; current state: [24.333333333333332, 7.55964114726929]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 28.577226660761017\n",
      "current reward: 28.577226660761017; current state: [28.22222222222222, 3.4469888831054702]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 15)\n",
      "act action : 19\n",
      "reward: 28.687975231848693\n",
      "current reward: 28.687975231848693; current state: [29.962962962962962, 4.045110579907931]\n",
      "maximizing action\n",
      "[5.39189706 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.654187230422036\n",
      "current reward: 28.654187230422036; current state: [24.333333333333332, 10.360994659374034]\n",
      "maximizing action\n",
      "[5.71176367 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 43)\n",
      "act action : 19\n",
      "reward: 28.851830645942233\n",
      "current reward: 28.851830645942233; current state: [29.51851851851852, 3.871684949600857]\n",
      "maximizing action\n",
      "[5.90001201 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.708487784778367\n",
      "current reward: 29.708487784778367; current state: [30.814814814814813, 5.245085935388575]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 23)\n",
      "act action : 19\n",
      "reward: 28.778737473923172\n",
      "current reward: 28.778737473923172; current state: [26.333333333333332, 11.351772711894421]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 47)\n",
      "act action : 19\n",
      "reward: 30.13902597171752\n",
      "current reward: 30.13902597171752; current state: [27.666666666666668, 6.1422460594918356]\n",
      "maximizing action\n",
      "[5.50530891 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 28.772696433136037\n",
      "current reward: 28.772696433136037; current state: [30.333333333333332, 5.588316552039839]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 25)\n",
      "act action : 19\n",
      "reward: 28.743311444279104\n",
      "current reward: 28.743311444279104; current state: [28.22222222222222, 5.0105786152749126]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 23)\n",
      "act action : 19\n",
      "reward: 29.393018311090614\n",
      "current reward: 29.393018311090614; current state: [30.333333333333332, 0.13844367217273051]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 3)\n",
      "act action : 19\n",
      "reward: 29.901384626807197\n",
      "current reward: 29.901384626807197; current state: [33.0, 3.669653459892448]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 17)\n",
      "act action : 19\n",
      "reward: 28.69347776608537\n",
      "current reward: 28.69347776608537; current state: [29.51851851851852, 8.555061987692035]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 37)\n",
      "act action : 19\n",
      "reward: 29.59212101507202\n",
      "current reward: 29.59212101507202; current state: [27.666666666666668, 10.24490286642542]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 43)\n",
      "act action : 19\n",
      "reward: 29.37082463412295\n",
      "current reward: 29.37082463412295; current state: [26.333333333333332, 6.4073946384136775]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 28.688236358408474\n",
      "current reward: 28.688236358408474; current state: [29.77777777777778, 3.9791668054758977]\n",
      "maximizing action\n",
      "[11.84170956  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 28.858613988990452\n",
      "current reward: 28.858613988990452; current state: [31.14814814814815, 6.059673011093299]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 27)\n",
      "act action : 19\n",
      "reward: 30.352522868613963\n",
      "current reward: 30.352522868613963; current state: [26.333333333333332, 9.966938279171549]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 41)\n",
      "act action : 19\n",
      "reward: 28.238986813407667\n",
      "current reward: 28.238986813407667; current state: [27.037037037037038, 4.091275809603921]\n",
      "maximizing action\n",
      "[5.6654637 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 28.130642833305316\n",
      "current reward: 28.130642833305316; current state: [33.0, 2.522097964349196]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 13)\n",
      "act action : 19\n",
      "reward: 28.144121653121672\n",
      "current reward: 28.144121653121672; current state: [31.14814814814815, 6.417647274440794]\n",
      "maximizing action\n",
      "[6.07050457 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 27)\n",
      "act action : 19\n",
      "reward: 28.311635954367933\n",
      "current reward: 28.311635954367933; current state: [29.77777777777778, 5.481576303350487]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 29.032521757858053\n",
      "current reward: 29.032521757858053; current state: [31.14814814814815, 6.387222845919235]\n",
      "maximizing action\n",
      "[11.73283176  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 27)\n",
      "act action : 19\n",
      "reward: 28.33004190950688\n",
      "current reward: 28.33004190950688; current state: [32.51851851851852, 4.408645179914741]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 19)\n",
      "act action : 19\n",
      "reward: 28.300204057136693\n",
      "current reward: 28.300204057136693; current state: [24.333333333333332, 12.890454480553737]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 53)\n",
      "act action : 19\n",
      "reward: 28.05366291389176\n",
      "current reward: 28.05366291389176; current state: [26.333333333333332, 6.931856763144212]\n",
      "maximizing action\n",
      "[6.15176391 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 29.009232917048706\n",
      "current reward: 29.009232917048706; current state: [32.111111111111114, 1.5624029640743886]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 28.107970385525675\n",
      "current reward: 28.107970385525675; current state: [26.925925925925927, 5.751935334807981]\n",
      "maximizing action\n",
      "[11.27856589  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 28.307035315504592\n",
      "current reward: 28.307035315504592; current state: [28.22222222222222, 2.9935819966498096]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 28.356205006127414\n",
      "current reward: 28.356205006127414; current state: [28.22222222222222, 4.889684898280202]\n",
      "maximizing action\n",
      "[5.7982049 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 28.230702787939467\n",
      "current reward: 28.230702787939467; current state: [27.666666666666668, 9.01380873446464]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 39)\n",
      "act action : 19\n",
      "reward: 29.068682130167332\n",
      "current reward: 29.068682130167332; current state: [26.333333333333332, 6.533749803484382]\n",
      "maximizing action\n",
      "[11.95361049  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 28.20361083946014\n",
      "current reward: 28.20361083946014; current state: [27.037037037037038, 5.610335949146653]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.319039182795038\n",
      "current reward: 28.319039182795038; current state: [31.666666666666668, 6.977872713487396]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 29)\n",
      "act action : 19\n",
      "reward: 28.39190975950756\n",
      "current reward: 28.39190975950756; current state: [33.888888888888886, 4.828415061400546]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (137, 21)\n",
      "act action : 19\n",
      "reward: 28.583781514588257\n",
      "current reward: 28.583781514588257; current state: [28.40740740740741, 7.560232439800608]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 33)\n",
      "act action : 19\n",
      "reward: 28.561034542121586\n",
      "current reward: 28.561034542121586; current state: [27.037037037037038, 9.422841266769561]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 39)\n",
      "act action : 19\n",
      "reward: 28.15447824149295\n",
      "current reward: 28.15447824149295; current state: [29.14814814814815, 5.265109474019373]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 23)\n",
      "act action : 19\n",
      "reward: 28.150000866504723\n",
      "current reward: 28.150000866504723; current state: [31.14814814814815, 5.3458342005083415]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 23)\n",
      "act action : 19\n",
      "reward: 28.313651848864186\n",
      "current reward: 28.313651848864186; current state: [34.77777777777778, 2.0149794651912045]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (141, 11)\n",
      "act action : 19\n",
      "reward: 27.784387573317172\n",
      "current reward: 27.784387573317172; current state: [29.77777777777778, 5.4674699046514625]\n",
      "maximizing action\n",
      "[5.80650435 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 28.437229960895795\n",
      "current reward: 28.437229960895795; current state: [31.14814814814815, 4.362980272051802]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 19)\n",
      "act action : 19\n",
      "reward: 28.07074365106689\n",
      "current reward: 28.07074365106689; current state: [28.40740740740741, 6.9022778712241415]\n",
      "maximizing action\n",
      "[5.57213961 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 28.26298542797045\n",
      "current reward: 28.26298542797045; current state: [26.333333333333332, 6.633662962097367]\n",
      "maximizing action\n",
      "[17.59433266  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 27.89697934856719\n",
      "current reward: 27.89697934856719; current state: [35.25925925925926, 2.848497021779073]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (143, 13)\n",
      "act action : 19\n",
      "reward: 27.955489872121973\n",
      "current reward: 27.955489872121973; current state: [28.22222222222222, 8.077571167611508]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 35)\n",
      "act action : 19\n",
      "reward: 28.556601408591703\n",
      "current reward: 28.556601408591703; current state: [33.0, 5.081209381739994]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 23)\n",
      "act action : 19\n",
      "reward: 28.082191420753094\n",
      "current reward: 28.082191420753094; current state: [29.0, 4.222588621013306]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 29.623595065105558\n",
      "current reward: 29.623595065105558; current state: [26.925925925925927, 6.379585405509892]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 29.409324274770658\n",
      "current reward: 29.409324274770658; current state: [26.925925925925927, 10.44713627669677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 43)\n",
      "act action : 19\n",
      "reward: 28.145570792554256\n",
      "current reward: 28.145570792554256; current state: [30.814814814814813, 0.05119453924914677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 3)\n",
      "act action : 19\n",
      "reward: 28.033546306176973\n",
      "current reward: 28.033546306176973; current state: [33.407407407407405, 3.2998571027043333]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 15)\n",
      "act action : 19\n",
      "reward: 29.648391278357348\n",
      "current reward: 29.648391278357348; current state: [23.666666666666668, 9.606574383159591]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 28.629747326688904\n",
      "current reward: 28.629747326688904; current state: [29.11111111111111, 2.0200278040459883]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 29.820878382745775\n",
      "current reward: 29.820878382745775; current state: [31.555555555555557, 1.029764038048163]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 7)\n",
      "act action : 19\n",
      "reward: 28.877815263575116\n",
      "current reward: 28.877815263575116; current state: [24.22222222222222, 12.630163817830928]\n",
      "maximizing action\n",
      "[5.61073258 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 53)\n",
      "act action : 19\n",
      "reward: 28.693996702299557\n",
      "current reward: 28.693996702299557; current state: [27.88888888888889, 4.808372126012819]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 28.821873881701624\n",
      "current reward: 28.821873881701624; current state: [27.074074074074073, 3.9260917710375653]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 28.44383293808802\n",
      "current reward: 28.44383293808802; current state: [27.88888888888889, 5.669578405923778]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 25)\n",
      "act action : 19\n",
      "reward: 28.66553747622682\n",
      "current reward: 28.66553747622682; current state: [26.666666666666668, 8.287420247270271]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 35)\n",
      "act action : 19\n",
      "reward: 28.82424217723806\n",
      "current reward: 28.82424217723806; current state: [27.074074074074073, 6.695452536645268]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 28.721249399948164\n",
      "current reward: 28.721249399948164; current state: [29.444444444444443, 2.030773747994732]\n",
      "maximizing action\n",
      "[5.96417568 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 31.37906369823581\n",
      "current reward: 31.37906369823581; current state: [26.25925925925926, 8.222751321505935]\n",
      "maximizing action\n",
      "[5.74371558 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 28.914664313522326\n",
      "current reward: 28.914664313522326; current state: [24.703703703703702, 2.959314409739877]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 13)\n",
      "act action : 19\n",
      "reward: 29.24015580149407\n",
      "current reward: 29.24015580149407; current state: [25.88888888888889, 2.9077886262475827]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 13)\n",
      "act action : 19\n",
      "reward: 30.50591265210188\n",
      "current reward: 30.50591265210188; current state: [29.444444444444443, 1.3743952180494972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 7)\n",
      "act action : 19\n",
      "reward: 29.517166848288593\n",
      "current reward: 29.517166848288593; current state: [24.703703703703702, 4.804486153533729]\n",
      "maximizing action\n",
      "[5.09540409 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 21)\n",
      "act action : 19\n",
      "reward: 30.58024606412465\n",
      "current reward: 30.58024606412465; current state: [18.77777777777778, 7.466760547760908]\n",
      "maximizing action\n",
      "[5.01801236 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (77, 31)\n",
      "act action : 19\n",
      "reward: 29.929804125077776\n",
      "current reward: 29.929804125077776; current state: [23.0, 2.0689472331893093]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 11)\n",
      "act action : 19\n",
      "reward: 30.862133352155457\n",
      "current reward: 30.862133352155457; current state: [29.11111111111111, 2.639229642596866]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 13)\n",
      "act action : 19\n",
      "reward: 29.664244500292565\n",
      "current reward: 29.664244500292565; current state: [27.88888888888889, 4.303114047965643]\n",
      "maximizing action\n",
      "[5.43467023 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 29.882795087176543\n",
      "current reward: 29.882795087176543; current state: [23.0, 9.23563798730115]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 39)\n",
      "act action : 19\n",
      "reward: 29.991905223099653\n",
      "current reward: 29.991905223099653; current state: [26.666666666666668, 2.821762502716738]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 13)\n",
      "act action : 19\n",
      "reward: 29.42923568784359\n",
      "current reward: 29.42923568784359; current state: [29.962962962962962, 4.1983774773166616]\n",
      "maximizing action\n",
      "[11.12273451  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 29.984079818849683\n",
      "current reward: 29.984079818849683; current state: [27.444444444444443, 7.070173517605538]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 29.702014551077472\n",
      "current reward: 29.702014551077472; current state: [29.11111111111111, 1.4963730604337953]\n",
      "maximizing action\n",
      "[5.90343337 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 7)\n",
      "act action : 19\n",
      "reward: 29.09175216182206\n",
      "current reward: 29.09175216182206; current state: [26.185185185185187, 9.789580084101901]\n",
      "maximizing action\n",
      "[5.63842806 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 41)\n",
      "act action : 19\n",
      "reward: 30.032618646016207\n",
      "current reward: 30.032618646016207; current state: [28.703703703703702, 3.891841921015336]\n",
      "maximizing action\n",
      "[10.32998691  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 29.269612694718194\n",
      "current reward: 29.269612694718194; current state: [26.185185185185187, 8.660926030314355]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 37)\n",
      "act action : 19\n",
      "reward: 29.02053235927433\n",
      "current reward: 29.02053235927433; current state: [29.51851851851852, 3.5189242538275827]\n",
      "maximizing action\n",
      "[17.61343236  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 28.32538528530844\n",
      "current reward: 28.32538528530844; current state: [32.111111111111114, 2.6112475074585344]\n",
      "maximizing action\n",
      "[5.62515138 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 13)\n",
      "act action : 19\n",
      "reward: 29.613014948369095\n",
      "current reward: 29.613014948369095; current state: [29.962962962962962, 6.312601137614627]\n",
      "maximizing action\n",
      "[11.29428854  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 28.33997089543848\n",
      "current reward: 28.33997089543848; current state: [22.40740740740741, 9.432819165776142]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 39)\n",
      "act action : 19\n",
      "reward: 28.558241422718822\n",
      "current reward: 28.558241422718822; current state: [28.703703703703702, 4.504259396175391]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 28.361043969624223\n",
      "current reward: 28.361043969624223; current state: [30.333333333333332, 3.7352805032593492]\n",
      "exploring action\n",
      "Current action = 33, current state (123, 17)\n",
      "act action : 33\n",
      "reward: 29.689968145048862\n",
      "current reward: 29.689968145048862; current state: [24.925925925925927, 8.663515009397079]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 28.417400823817484\n",
      "current reward: 28.417400823817484; current state: [27.88888888888889, 3.212463954835369]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 15)\n",
      "act action : 19\n",
      "reward: 27.672935385095602\n",
      "current reward: 27.672935385095602; current state: [26.666666666666668, 9.34490995270261]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 27.794547972875034\n",
      "current reward: 27.794547972875034; current state: [29.444444444444443, 0.9654902385340067]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 5)\n",
      "act action : 19\n",
      "reward: 28.97000982379231\n",
      "current reward: 28.97000982379231; current state: [27.074074074074073, 8.295575817247807]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 27.743433672291406\n",
      "current reward: 27.743433672291406; current state: [27.074074074074073, 4.899677111668575]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 28.545465048616624\n",
      "current reward: 28.545465048616624; current state: [28.77777777777778, 0.9142972523538498]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 5)\n",
      "act action : 19\n",
      "reward: 27.48919200843265\n",
      "current reward: 27.48919200843265; current state: [25.11111111111111, 8.279962735587922]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 28.11099391365883\n",
      "current reward: 28.11099391365883; current state: [20.51851851851852, 11.264964785654566]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 47)\n",
      "act action : 19\n",
      "reward: 27.31185718786217\n",
      "current reward: 27.31185718786217; current state: [26.25925925925926, 3.443010971633823]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 15)\n",
      "act action : 19\n",
      "reward: 27.526122582434777\n",
      "current reward: 27.526122582434777; current state: [26.25925925925926, 5.717315028005219]\n",
      "maximizing action\n",
      "[23.52288601  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 28.165410839871658\n",
      "current reward: 28.165410839871658; current state: [22.11111111111111, 12.184685448835184]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 51)\n",
      "act action : 19\n",
      "reward: 27.26708004366844\n",
      "current reward: 27.26708004366844; current state: [22.814814814814813, 8.249911706910565]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (93, 35)\n",
      "act action : 19\n",
      "reward: 28.877328633381115\n",
      "current reward: 28.877328633381115; current state: [23.962962962962962, 2.3386577215771656]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 11)\n",
      "act action : 19\n",
      "reward: 27.686543246203232\n",
      "current reward: 27.686543246203232; current state: [27.074074074074073, 10.156372901407966]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 43)\n",
      "act action : 19\n",
      "reward: 27.970224484535375\n",
      "current reward: 27.970224484535375; current state: [27.074074074074073, 2.0205705715354263]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 28.221845531671917\n",
      "current reward: 28.221845531671917; current state: [27.074074074074073, 8.019581744026638]\n",
      "maximizing action\n",
      "[5.54868673 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 29.146690516325183\n",
      "current reward: 29.146690516325183; current state: [29.11111111111111, 5.09523459127109]\n",
      "maximizing action\n",
      "[5.63000017 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 23)\n",
      "act action : 19\n",
      "reward: 28.351785797528734\n",
      "current reward: 28.351785797528734; current state: [26.25925925925926, 3.638105572375851]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 17)\n",
      "act action : 19\n",
      "reward: 28.334929427875238\n",
      "current reward: 28.334929427875238; current state: [24.703703703703702, 6.579678881790186]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 29)\n",
      "act action : 19\n",
      "reward: 28.5455182918234\n",
      "current reward: 28.5455182918234; current state: [21.14814814814815, 4.903647575036429]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 21)\n",
      "act action : 19\n",
      "reward: 27.810564669529153\n",
      "current reward: 27.810564669529153; current state: [23.51851851851852, 4.521734694535776]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 21)\n",
      "act action : 19\n",
      "reward: 29.64862250092214\n",
      "current reward: 29.64862250092214; current state: [27.074074074074073, 9.153911533172353]\n",
      "maximizing action\n",
      "[5.63089565 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 39)\n",
      "act action : 19\n",
      "reward: 28.444042637019567\n",
      "current reward: 28.444042637019567; current state: [23.51851851851852, 7.102306739572094]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 28.14059322689948\n",
      "current reward: 28.14059322689948; current state: [22.333333333333332, 10.126694334499515]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 43)\n",
      "act action : 19\n",
      "reward: 28.283456111858786\n",
      "current reward: 28.283456111858786; current state: [23.962962962962962, 10.848562793538907]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 45)\n",
      "act action : 19\n",
      "reward: 28.12585023612191\n",
      "current reward: 28.12585023612191; current state: [25.88888888888889, 3.981236135199805]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 28.33308608946332\n",
      "current reward: 28.33308608946332; current state: [22.333333333333332, 9.140673251381582]\n",
      "maximizing action\n",
      "[5.71164828 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (91, 39)\n",
      "act action : 19\n",
      "reward: 28.54369859248348\n",
      "current reward: 28.54369859248348; current state: [25.88888888888889, 2.360440212697401]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 11)\n",
      "act action : 19\n",
      "reward: 28.42323428670902\n",
      "current reward: 28.42323428670902; current state: [27.88888888888889, 5.89681286981733]\n",
      "maximizing action\n",
      "[5.7331075 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (113, 25)\n",
      "act action : 19\n",
      "reward: 30.796277979759306\n",
      "current reward: 30.796277979759306; current state: [29.444444444444443, 1.5613365640526455]\n",
      "maximizing action\n",
      "[5.48334995 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 28.008802066958065\n",
      "current reward: 28.008802066958065; current state: [27.88888888888889, 7.631692429371818]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 33)\n",
      "act action : 19\n",
      "reward: 28.046187067349695\n",
      "current reward: 28.046187067349695; current state: [22.333333333333332, 10.621303258455326]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 45)\n",
      "act action : 19\n",
      "reward: 28.994335458068022\n",
      "current reward: 28.994335458068022; current state: [27.88888888888889, 2.0155966001814787]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 11)\n",
      "act action : 19\n",
      "reward: 28.038766754828032\n",
      "current reward: 28.038766754828032; current state: [24.22222222222222, 9.542404129541413]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 41)\n",
      "act action : 19\n",
      "reward: 27.99496124597427\n",
      "current reward: 27.99496124597427; current state: [24.703703703703702, 3.803883591110243]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 17)\n",
      "act action : 19\n",
      "reward: 27.847178993736282\n",
      "current reward: 27.847178993736282; current state: [27.88888888888889, 5.220065024244759]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 23)\n",
      "act action : 19\n",
      "reward: 29.579169405912314\n",
      "current reward: 29.579169405912314; current state: [27.074074074074073, 6.5623199226331]\n",
      "maximizing action\n",
      "[5.74424988 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 27.33927651139418\n",
      "current reward: 27.33927651139418; current state: [26.666666666666668, 5.365567600469371]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.10184457885207\n",
      "current reward: 29.10184457885207; current state: [31.555555555555557, 0.8340356822486547]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 5)\n",
      "act action : 19\n",
      "reward: 29.217347479233222\n",
      "current reward: 29.217347479233222; current state: [29.11111111111111, 3.2387530372520437]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 27.853143417058714\n",
      "current reward: 27.853143417058714; current state: [29.962962962962962, 3.040244377436587]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 15)\n",
      "act action : 19\n",
      "reward: 29.60752111990976\n",
      "current reward: 29.60752111990976; current state: [24.22222222222222, 13.078097722452673]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 55)\n",
      "act action : 19\n",
      "reward: 29.003352368781407\n",
      "current reward: 29.003352368781407; current state: [32.48148148148148, 0.5626525865158303]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 5)\n",
      "act action : 19\n",
      "reward: 28.139260538048237\n",
      "current reward: 28.139260538048237; current state: [27.444444444444443, 6.172449573436918]\n",
      "maximizing action\n",
      "[5.61461543 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 27.843357865309418\n",
      "current reward: 27.843357865309418; current state: [24.925925925925927, 6.019746933538938]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 27)\n",
      "act action : 19\n",
      "reward: 28.48510383362874\n",
      "current reward: 28.48510383362874; current state: [26.185185185185187, 9.768252914348833]\n",
      "maximizing action\n",
      "[11.64495179  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 41)\n",
      "act action : 19\n",
      "reward: 28.296156262188287\n",
      "current reward: 28.296156262188287; current state: [23.51851851851852, 8.34277453980915]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 35)\n",
      "act action : 19\n",
      "reward: 28.290968553023998\n",
      "current reward: 28.290968553023998; current state: [25.88888888888889, 7.051196635211993]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 28.179574875268056\n",
      "current reward: 28.179574875268056; current state: [25.88888888888889, 10.586760065378499]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 45)\n",
      "act action : 19\n",
      "reward: 27.88497490814113\n",
      "current reward: 27.88497490814113; current state: [29.11111111111111, 3.8591258668304693]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.013292123278273\n",
      "current reward: 28.013292123278273; current state: [29.11111111111111, 3.161444933103923]\n",
      "maximizing action\n",
      "[5.57062868 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 28.43746518894233\n",
      "current reward: 28.43746518894233; current state: [29.11111111111111, 4.284918738650095]\n",
      "maximizing action\n",
      "[5.92471901 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 28.695733402064572\n",
      "current reward: 28.695733402064572; current state: [27.444444444444443, 6.654769393872686]\n",
      "maximizing action\n",
      "[11.21210518  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 29.742432532243043\n",
      "current reward: 29.742432532243043; current state: [30.333333333333332, 0.7806432868697355]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 5)\n",
      "act action : 19\n",
      "reward: 28.686918177029014\n",
      "current reward: 28.686918177029014; current state: [31.22222222222222, 2.1624372575730764]\n",
      "maximizing action\n",
      "[11.50684666  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 11)\n",
      "act action : 19\n",
      "reward: 28.799572494641552\n",
      "current reward: 28.799572494641552; current state: [26.666666666666668, 6.963582233098312]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 28.473446113712836\n",
      "current reward: 28.473446113712836; current state: [28.703703703703702, 3.10681891028392]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 15)\n",
      "act action : 19\n",
      "reward: 28.570879145041175\n",
      "current reward: 28.570879145041175; current state: [26.185185185185187, 8.391127805546649]\n",
      "maximizing action\n",
      "[11.52664844  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 28.82012496100079\n",
      "current reward: 28.82012496100079; current state: [27.074074074074073, 5.433842253089175]\n",
      "maximizing action\n",
      "[5.59417696 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 23)\n",
      "act action : 19\n",
      "reward: 28.845698414005458\n",
      "current reward: 28.845698414005458; current state: [29.11111111111111, 6.081638440578313]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 27)\n",
      "act action : 19\n",
      "reward: 30.033202185614382\n",
      "current reward: 30.033202185614382; current state: [27.88888888888889, 6.602770468251454]\n",
      "maximizing action\n",
      "[5.56862293 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 29)\n",
      "act action : 19\n",
      "reward: 28.856704987764875\n",
      "current reward: 28.856704987764875; current state: [23.0, 12.549263665035436]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 53)\n",
      "act action : 19\n",
      "reward: 28.989463300574794\n",
      "current reward: 28.989463300574794; current state: [28.25925925925926, 4.6555745853587895]\n",
      "maximizing action\n",
      "[11.44434546  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 29.972017428127533\n",
      "current reward: 29.972017428127533; current state: [27.40740740740741, 3.8659773062198366]\n",
      "maximizing action\n",
      "[5.68876659 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 29.14151549647504\n",
      "current reward: 29.14151549647504; current state: [23.51851851851852, 13.69811962400023]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 57)\n",
      "act action : 19\n",
      "reward: 30.35753546237797\n",
      "current reward: 30.35753546237797; current state: [25.88888888888889, 3.6407661368544275]\n",
      "maximizing action\n",
      "[5.66661722 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 29.51265058483951\n",
      "current reward: 29.51265058483951; current state: [31.555555555555557, 2.7281367125580114]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 13)\n",
      "act action : 19\n",
      "reward: 30.43163926274875\n",
      "current reward: 30.43163926274875; current state: [24.22222222222222, 11.010700661363309]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 47)\n",
      "act action : 19\n",
      "reward: 29.721222827137893\n",
      "current reward: 29.721222827137893; current state: [26.185185185185187, 5.79420123777543]\n",
      "maximizing action\n",
      "[29.15596818  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 30.864631971187535\n",
      "current reward: 30.864631971187535; current state: [28.703703703703702, 3.459970024698286]\n",
      "maximizing action\n",
      "[5.71417583 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 15)\n",
      "act action : 19\n",
      "reward: 30.893214814837943\n",
      "current reward: 30.893214814837943; current state: [31.22222222222222, 4.05491561923041]\n",
      "maximizing action\n",
      "[5.61414873 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 19)\n",
      "act action : 19\n",
      "reward: 29.363320120382962\n",
      "current reward: 29.363320120382962; current state: [32.48148148148148, 2.880475490518396]\n",
      "maximizing action\n",
      "[11.54775437  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 13)\n",
      "act action : 19\n",
      "reward: 29.532456845274368\n",
      "current reward: 29.532456845274368; current state: [32.48148148148148, 1.9847354409898714]\n",
      "maximizing action\n",
      "[5.62159408 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 29.450862705483157\n",
      "current reward: 29.450862705483157; current state: [28.703703703703702, 7.0833495595067735]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 31)\n",
      "act action : 19\n",
      "reward: 29.383751532546864\n",
      "current reward: 29.383751532546864; current state: [27.444444444444443, 7.977668197686563]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 33)\n",
      "act action : 19\n",
      "reward: 29.49053375904568\n",
      "current reward: 29.49053375904568; current state: [25.444444444444443, 6.296671871233527]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 29.369031587668008\n",
      "current reward: 29.369031587668008; current state: [24.925925925925927, 7.3330091876862875]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 31)\n",
      "act action : 19\n",
      "reward: 29.148072195222895\n",
      "current reward: 29.148072195222895; current state: [29.11111111111111, 0.04835039817974972]\n",
      "maximizing action\n",
      "[5.48595976 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 3)\n",
      "act action : 19\n",
      "reward: 28.3725439238477\n",
      "current reward: 28.3725439238477; current state: [26.185185185185187, 9.064495668699172]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 39)\n",
      "act action : 19\n",
      "reward: 28.64713925839668\n",
      "current reward: 28.64713925839668; current state: [24.925925925925927, 7.5116745457141905]\n",
      "maximizing action\n",
      "[5.57605037 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 33)\n",
      "act action : 19\n",
      "reward: 28.049806409169634\n",
      "current reward: 28.049806409169634; current state: [29.962962962962962, 4.330024300820279]\n",
      "maximizing action\n",
      "[17.11023117  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.14243863790229\n",
      "current reward: 28.14243863790229; current state: [30.333333333333332, 3.70601730270646]\n",
      "maximizing action\n",
      "[0.         0.         0.         0.         0.         5.93799363]\n",
      "Current action = 33, current state (123, 17)\n",
      "act action : 33\n",
      "reward: 29.435501418572425\n",
      "current reward: 29.435501418572425; current state: [27.074074074074073, 4.4546909524088605]\n",
      "maximizing action\n",
      "[11.29159226  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 27.676439807261104\n",
      "current reward: 27.676439807261104; current state: [29.11111111111111, 3.3708459063838485]\n",
      "maximizing action\n",
      "[11.25812172  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 27.77849823511654\n",
      "current reward: 27.77849823511654; current state: [29.11111111111111, 2.115620388632422]\n",
      "maximizing action\n",
      "[12.23998842  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 27.54768072106909\n",
      "current reward: 27.54768072106909; current state: [31.22222222222222, 2.9278157693249405]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 13)\n",
      "act action : 19\n",
      "reward: 29.275289908944888\n",
      "current reward: 29.275289908944888; current state: [25.444444444444443, 8.092464878201863]\n",
      "maximizing action\n",
      "[5.62219878 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 27.605271860277867\n",
      "current reward: 27.605271860277867; current state: [26.666666666666668, 2.570547177605741]\n",
      "maximizing action\n",
      "[5.88584714 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 13)\n",
      "act action : 19\n",
      "reward: 28.699260689932654\n",
      "current reward: 28.699260689932654; current state: [26.185185185185187, 7.255919786282317]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 27.73027109124698\n",
      "current reward: 27.73027109124698; current state: [27.444444444444443, 5.082104049248977]\n",
      "maximizing action\n",
      "[11.36331664  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 23)\n",
      "act action : 19\n",
      "reward: 27.585414010933786\n",
      "current reward: 27.585414010933786; current state: [26.925925925925927, 5.826576525539053]\n",
      "maximizing action\n",
      "[16.93997296  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.144949978869832\n",
      "current reward: 29.144949978869832; current state: [22.40740740740741, 10.400520189934312]\n",
      "maximizing action\n",
      "[5.65669122 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (91, 43)\n",
      "act action : 19\n",
      "reward: 27.609096103874176\n",
      "current reward: 27.609096103874176; current state: [24.925925925925927, 5.774190691949378]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 25)\n",
      "act action : 19\n",
      "reward: 27.775582462987288\n",
      "current reward: 27.775582462987288; current state: [27.444444444444443, 5.666157533906563]\n",
      "maximizing action\n",
      "[5.66380784 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.034784190950788\n",
      "current reward: 28.034784190950788; current state: [28.703703703703702, 6.8859525093337375]\n",
      "maximizing action\n",
      "[11.94518354  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 29.231534744250244\n",
      "current reward: 29.231534744250244; current state: [29.51851851851852, 2.181670588810093]\n",
      "maximizing action\n",
      "[11.51752501  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 28.0987108514872\n",
      "current reward: 28.0987108514872; current state: [28.703703703703702, 3.1633405529677328]\n",
      "maximizing action\n",
      "[11.89281879  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 15)\n",
      "act action : 19\n",
      "reward: 27.261828361205062\n",
      "current reward: 27.261828361205062; current state: [29.51851851851852, 7.5170541273917655]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 33)\n",
      "act action : 19\n",
      "reward: 28.86501920348816\n",
      "current reward: 28.86501920348816; current state: [26.925925925925927, 5.255322789945699]\n",
      "maximizing action\n",
      "[5.82036892 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 27.819237315335176\n",
      "current reward: 27.819237315335176; current state: [25.444444444444443, 5.5350994846374055]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 25)\n",
      "act action : 19\n",
      "reward: 27.984102639268745\n",
      "current reward: 27.984102639268745; current state: [31.555555555555557, 0.04835039817974972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 3)\n",
      "act action : 19\n",
      "reward: 27.90666800541425\n",
      "current reward: 27.90666800541425; current state: [27.444444444444443, 11.111580713155174]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 47)\n",
      "act action : 19\n",
      "reward: 28.718254858140316\n",
      "current reward: 28.718254858140316; current state: [29.11111111111111, 1.2714799342076049]\n",
      "maximizing action\n",
      "[11.7217838  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 7)\n",
      "act action : 19\n",
      "reward: 28.28417398380259\n",
      "current reward: 28.28417398380259; current state: [23.0, 8.226452521377155]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 35)\n",
      "act action : 19\n",
      "reward: 27.833550452349925\n",
      "current reward: 27.833550452349925; current state: [19.88888888888889, 11.965560151480101]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (81, 49)\n",
      "act action : 19\n",
      "reward: 27.98173389841897\n",
      "current reward: 27.98173389841897; current state: [29.11111111111111, 2.4584637536130782]\n",
      "maximizing action\n",
      "[17.74952456  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 28.24474469215868\n",
      "current reward: 28.24474469215868; current state: [27.88888888888889, 10.269876030967364]\n",
      "maximizing action\n",
      "[5.87416493 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 43)\n",
      "act action : 19\n",
      "reward: 28.20470132359566\n",
      "current reward: 28.20470132359566; current state: [30.333333333333332, 2.7033701471978984]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 13)\n",
      "act action : 19\n",
      "reward: 28.462034539848847\n",
      "current reward: 28.462034539848847; current state: [27.88888888888889, 4.313095878923895]\n",
      "maximizing action\n",
      "[11.40250272  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 27.806090495862048\n",
      "current reward: 27.806090495862048; current state: [24.22222222222222, 8.573193942862842]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 37)\n",
      "act action : 19\n",
      "reward: 27.787585270750224\n",
      "current reward: 27.787585270750224; current state: [28.25925925925926, 1.4182827195653818]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 7)\n",
      "act action : 19\n",
      "reward: 29.607360287692142\n",
      "current reward: 29.607360287692142; current state: [25.88888888888889, 10.569075382224902]\n",
      "maximizing action\n",
      "[5.57699498 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 45)\n",
      "act action : 19\n",
      "reward: 28.937757192637434\n",
      "current reward: 28.937757192637434; current state: [23.51851851851852, 6.387845166355607]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 27)\n",
      "act action : 19\n",
      "reward: 27.750141355001336\n",
      "current reward: 27.750141355001336; current state: [25.88888888888889, 1.39523113446382]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 7)\n",
      "act action : 19\n",
      "reward: 28.982047782960354\n",
      "current reward: 28.982047782960354; current state: [26.666666666666668, 6.798973521363714]\n",
      "maximizing action\n",
      "[5.69468922 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 27.926733953811368\n",
      "current reward: 27.926733953811368; current state: [24.22222222222222, 7.920654155878139]\n",
      "maximizing action\n",
      "[5.70639396 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 27.346152550222154\n",
      "current reward: 27.346152550222154; current state: [24.925925925925927, 2.541720231960087]\n",
      "maximizing action\n",
      "[5.84803116 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 13)\n",
      "act action : 19\n",
      "reward: 27.467105876006524\n",
      "current reward: 27.467105876006524; current state: [29.962962962962962, 1.7244938845613849]\n",
      "maximizing action\n",
      "[5.38177216 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 9)\n",
      "act action : 19\n",
      "reward: 28.100951055651027\n",
      "current reward: 28.100951055651027; current state: [29.11111111111111, 3.8213596538456356]\n",
      "maximizing action\n",
      "[5.60265842 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 27.162871124032847\n",
      "current reward: 27.162871124032847; current state: [29.962962962962962, 4.413637642860663]\n",
      "maximizing action\n",
      "[22.73871889  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 27.19481727618731\n",
      "current reward: 27.19481727618731; current state: [26.666666666666668, 7.538171366188705]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 29.017418928987208\n",
      "current reward: 29.017418928987208; current state: [27.444444444444443, 1.3654570012250662]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 7)\n",
      "act action : 19\n",
      "reward: 27.426833862973222\n",
      "current reward: 27.426833862973222; current state: [29.962962962962962, 0.7636418081064449]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 5)\n",
      "act action : 19\n",
      "reward: 29.155227099507783\n",
      "current reward: 29.155227099507783; current state: [27.444444444444443, 10.702164450565006]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 45)\n",
      "act action : 19\n",
      "reward: 27.42094416316108\n",
      "current reward: 27.42094416316108; current state: [25.62962962962963, 9.419622065663654]\n",
      "maximizing action\n",
      "[5.70920602 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 39)\n",
      "act action : 19\n",
      "reward: 27.565186263266266\n",
      "current reward: 27.565186263266266; current state: [28.22222222222222, 4.668340398540572]\n",
      "maximizing action\n",
      "[17.43874894  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 27.61418384766959\n",
      "current reward: 27.61418384766959; current state: [30.333333333333332, 1.5731128057121055]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 9)\n",
      "act action : 19\n",
      "reward: 27.40801192761815\n",
      "current reward: 27.40801192761815; current state: [22.40740740740741, 14.234842904642322]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 59)\n",
      "act action : 19\n",
      "reward: 27.337918010016807\n",
      "current reward: 27.337918010016807; current state: [26.185185185185187, 7.293325587175661]\n",
      "maximizing action\n",
      "[5.54605422 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 28.103960794241555\n",
      "current reward: 28.103960794241555; current state: [30.333333333333332, 0.3926302034810792]\n",
      "maximizing action\n",
      "[5.98027693 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 3)\n",
      "act action : 19\n",
      "reward: 27.58808115725591\n",
      "current reward: 27.58808115725591; current state: [30.333333333333332, 2.3663576634008647]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 27.638561358113815\n",
      "current reward: 27.638561358113815; current state: [26.185185185185187, 10.47053029908154]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 43)\n",
      "act action : 19\n",
      "reward: 28.07765121347064\n",
      "current reward: 28.07765121347064; current state: [29.962962962962962, 3.502757565171986]\n",
      "maximizing action\n",
      "[23.27850942  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 28.349274184062633\n",
      "current reward: 28.349274184062633; current state: [30.814814814814813, 6.973841060164431]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 29)\n",
      "act action : 19\n",
      "reward: 27.949874683488236\n",
      "current reward: 27.949874683488236; current state: [32.48148148148148, 4.480970315687714]\n",
      "maximizing action\n",
      "[11.14253923  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 28.783165999073447\n",
      "current reward: 28.783165999073447; current state: [31.22222222222222, 6.049374269691952]\n",
      "maximizing action\n",
      "[17.39884015  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 27)\n",
      "act action : 19\n",
      "reward: 27.89373089923407\n",
      "current reward: 27.89373089923407; current state: [26.185185185185187, 13.187203966611854]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 55)\n",
      "act action : 19\n",
      "reward: 28.20038579581315\n",
      "current reward: 28.20038579581315; current state: [27.444444444444443, 5.984536734087897]\n",
      "maximizing action\n",
      "[11.27076467  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.826011080001138\n",
      "current reward: 28.826011080001138; current state: [24.703703703703702, 7.141353159887202]\n",
      "maximizing action\n",
      "[5.82961444 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 31)\n",
      "act action : 19\n",
      "reward: 27.96688720286117\n",
      "current reward: 27.96688720286117; current state: [24.703703703703702, 4.148985147738521]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 19)\n",
      "act action : 19\n",
      "reward: 27.641099883617784\n",
      "current reward: 27.641099883617784; current state: [26.666666666666668, 7.833367245164815]\n",
      "maximizing action\n",
      "[5.79452933 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 29.288464002085803\n",
      "current reward: 29.288464002085803; current state: [24.703703703703702, 10.653840126307298]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 45)\n",
      "act action : 19\n",
      "reward: 27.85249445298494\n",
      "current reward: 27.85249445298494; current state: [27.074074074074073, 3.8867983212647452]\n",
      "maximizing action\n",
      "[11.51706969  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 28.479449655606334\n",
      "current reward: 28.479449655606334; current state: [25.88888888888889, 2.2327976937786653]\n",
      "maximizing action\n",
      "[5.68464686 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 11)\n",
      "act action : 19\n",
      "reward: 27.742039194097202\n",
      "current reward: 27.742039194097202; current state: [28.25925925925926, 2.7385354515753138]\n",
      "maximizing action\n",
      "[5.671241 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 27.474106916090477\n",
      "current reward: 27.474106916090477; current state: [25.444444444444443, 7.213487248916565]\n",
      "maximizing action\n",
      "[5.66206372 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 31)\n",
      "act action : 19\n",
      "reward: 27.579823833113448\n",
      "current reward: 27.579823833113448; current state: [19.962962962962962, 2.5304951781246015]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (81, 13)\n",
      "act action : 19\n",
      "reward: 29.40341166486635\n",
      "current reward: 29.40341166486635; current state: [21.666666666666668, 5.580973236745957]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 25)\n",
      "act action : 19\n",
      "reward: 27.205390133180412\n",
      "current reward: 27.205390133180412; current state: [28.25925925925926, 3.133421018429616]\n",
      "maximizing action\n",
      "[5.73759505 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 15)\n",
      "act action : 19\n",
      "reward: 29.01711242981918\n",
      "current reward: 29.01711242981918; current state: [25.88888888888889, 8.319314554861613]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 35)\n",
      "act action : 19\n",
      "reward: 27.324935037409627\n",
      "current reward: 27.324935037409627; current state: [27.88888888888889, 2.145862586005212]\n",
      "maximizing action\n",
      "[5.60775335 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 11)\n",
      "act action : 19\n",
      "reward: 27.441488450708906\n",
      "current reward: 27.441488450708906; current state: [26.666666666666668, 9.46750598011412]\n",
      "maximizing action\n",
      "[5.55890959 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 26.603563044409793\n",
      "current reward: 26.603563044409793; current state: [27.88888888888889, 2.973493505461659]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 13)\n",
      "act action : 19\n",
      "reward: 26.824996249860533\n",
      "current reward: 26.824996249860533; current state: [30.333333333333332, 1.410622797530318]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 7)\n",
      "act action : 19\n",
      "reward: 29.486523228193487\n",
      "current reward: 29.486523228193487; current state: [27.074074074074073, 6.647547555116525]\n",
      "maximizing action\n",
      "[17.16059169  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 26.467984023642675\n",
      "current reward: 26.467984023642675; current state: [32.77777777777778, 2.151767504542505]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 11)\n",
      "act action : 19\n",
      "reward: 26.69373785855014\n",
      "current reward: 26.69373785855014; current state: [29.11111111111111, 6.7276716859897325]\n",
      "maximizing action\n",
      "[5.81623971 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 26.78393103292378\n",
      "current reward: 26.78393103292378; current state: [25.88888888888889, 8.34864997496129]\n",
      "maximizing action\n",
      "[5.46498701 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 35)\n",
      "act action : 19\n",
      "reward: 26.41224403283643\n",
      "current reward: 26.41224403283643; current state: [29.11111111111111, 7.612489653525198]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 33)\n",
      "act action : 19\n",
      "reward: 26.664663116845478\n",
      "current reward: 26.664663116845478; current state: [29.11111111111111, 6.164321864479304]\n",
      "maximizing action\n",
      "[6.00664044 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 27)\n",
      "act action : 19\n",
      "reward: 26.963531591116865\n",
      "current reward: 26.963531591116865; current state: [25.444444444444443, 6.85055655411208]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 29)\n",
      "act action : 19\n",
      "reward: 27.452196074096463\n",
      "current reward: 27.452196074096463; current state: [29.962962962962962, 6.702894248729442]\n",
      "maximizing action\n",
      "[5.8457797 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 27.121029546538136\n",
      "current reward: 27.121029546538136; current state: [28.703703703703702, 7.551387640932158]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 33)\n",
      "act action : 19\n",
      "reward: 27.427922421492223\n",
      "current reward: 27.427922421492223; current state: [26.185185185185187, 7.5391227921640045]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 27.504264027045696\n",
      "current reward: 27.504264027045696; current state: [30.814814814814813, 2.455383318562011]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 11)\n",
      "act action : 19\n",
      "reward: 26.997436565958\n",
      "current reward: 26.997436565958; current state: [26.666666666666668, 10.248743507821056]\n",
      "maximizing action\n",
      "[5.62911416 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 43)\n",
      "act action : 19\n",
      "reward: 27.453728048067347\n",
      "current reward: 27.453728048067347; current state: [27.88888888888889, 3.6902315277089714]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 28.0050632423503\n",
      "current reward: 28.0050632423503; current state: [27.444444444444443, 3.4860682388245645]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 27.30664571675088\n",
      "current reward: 27.30664571675088; current state: [19.88888888888889, 13.146523959361586]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (81, 55)\n",
      "act action : 19\n",
      "reward: 28.323483577213494\n",
      "current reward: 28.323483577213494; current state: [25.62962962962963, 4.0582164224633095]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 19)\n",
      "act action : 19\n",
      "reward: 27.646580312687334\n",
      "current reward: 27.646580312687334; current state: [30.814814814814813, 4.258105128448154]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 27.795942426486913\n",
      "current reward: 27.795942426486913; current state: [24.333333333333332, 12.95245295544232]\n",
      "maximizing action\n",
      "[11.34953192  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 53)\n",
      "act action : 19\n",
      "reward: 27.472386196348378\n",
      "current reward: 27.472386196348378; current state: [25.0, 4.125637913902985]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 27.686880339698046\n",
      "current reward: 27.686880339698046; current state: [27.666666666666668, 10.746806467821076]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 45)\n",
      "act action : 19\n",
      "reward: 29.517124932429038\n",
      "current reward: 29.517124932429038; current state: [27.666666666666668, 5.245884427666457]\n",
      "maximizing action\n",
      "[5.91583388 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 23)\n",
      "act action : 19\n",
      "reward: 28.174797304595824\n",
      "current reward: 28.174797304595824; current state: [30.333333333333332, 6.586076309937367]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 29)\n",
      "act action : 19\n",
      "reward: 27.71015027634448\n",
      "current reward: 27.71015027634448; current state: [29.0, 7.583398173852463]\n",
      "maximizing action\n",
      "[5.33293262 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 33)\n",
      "act action : 19\n",
      "reward: 28.14748732718766\n",
      "current reward: 28.14748732718766; current state: [23.666666666666668, 9.82881003769418]\n",
      "maximizing action\n",
      "[5.72594947 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 29.428507347510138\n",
      "current reward: 29.428507347510138; current state: [32.111111111111114, 0.4345381493977892]\n",
      "maximizing action\n",
      "[5.55710136 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 3)\n",
      "act action : 19\n",
      "reward: 30.177587917532197\n",
      "current reward: 30.177587917532197; current state: [29.51851851851852, 5.1922834907443765]\n",
      "maximizing action\n",
      "[11.49395034  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 29.258626158626374\n",
      "current reward: 29.258626158626374; current state: [26.925925925925927, 6.906994368179063]\n",
      "maximizing action\n",
      "[11.28003601  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 28.89750753511648\n",
      "current reward: 28.89750753511648; current state: [29.962962962962962, 1.9246109416234485]\n",
      "maximizing action\n",
      "[11.00196237  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 9)\n",
      "act action : 19\n",
      "reward: 30.226726159999526\n",
      "current reward: 30.226726159999526; current state: [28.703703703703702, 8.511214389102264]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 37)\n",
      "act action : 19\n",
      "reward: 29.13520453323646\n",
      "current reward: 29.13520453323646; current state: [24.925925925925927, 11.14535728678866]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 47)\n",
      "act action : 19\n",
      "reward: 28.519619532056737\n",
      "current reward: 28.519619532056737; current state: [24.925925925925927, 5.376235394863702]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 23)\n",
      "act action : 19\n",
      "reward: 28.467817123834966\n",
      "current reward: 28.467817123834966; current state: [25.444444444444443, 7.824151712080034]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 28.106078689267274\n",
      "current reward: 28.106078689267274; current state: [26.185185185185187, 4.3973821462117195]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 19)\n",
      "act action : 19\n",
      "reward: 27.726711422435972\n",
      "current reward: 27.726711422435972; current state: [29.11111111111111, 4.25698438343167]\n",
      "maximizing action\n",
      "[11.66386569  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 28.056790213605804\n",
      "current reward: 28.056790213605804; current state: [28.703703703703702, 8.670320020597641]\n",
      "maximizing action\n",
      "[5.82704091 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 37)\n",
      "act action : 19\n",
      "reward: 28.28564782821299\n",
      "current reward: 28.28564782821299; current state: [27.444444444444443, 4.838873885148234]\n",
      "maximizing action\n",
      "[5.70909301 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 28.257614768254296\n",
      "current reward: 28.257614768254296; current state: [26.666666666666668, 1.6604022273141847]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 9)\n",
      "act action : 19\n",
      "reward: 28.09064153325126\n",
      "current reward: 28.09064153325126; current state: [27.88888888888889, 6.046879572762173]\n",
      "maximizing action\n",
      "[11.2598482  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 29.752072539964345\n",
      "current reward: 29.752072539964345; current state: [30.333333333333332, 3.8512065898916794]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         12.75265509]\n",
      "Current action = 33, current state (123, 17)\n",
      "act action : 33\n",
      "reward: 28.134077100422758\n",
      "current reward: 28.134077100422758; current state: [31.22222222222222, 0.34141809865836464]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 3)\n",
      "act action : 19\n",
      "reward: 29.737057394450563\n",
      "current reward: 29.737057394450563; current state: [24.925925925925927, 12.862462857442862]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 53)\n",
      "act action : 19\n",
      "reward: 28.717058699861866\n",
      "current reward: 28.717058699861866; current state: [28.703703703703702, 5.706505966757919]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 29.662645025767063\n",
      "current reward: 29.662645025767063; current state: [24.333333333333332, 8.807989042947584]\n",
      "maximizing action\n",
      "[5.54690897 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 37)\n",
      "act action : 19\n",
      "reward: 29.990470633863183\n",
      "current reward: 29.990470633863183; current state: [29.51851851851852, 4.378773405776448]\n",
      "maximizing action\n",
      "[28.17768235  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.3655747764136\n",
      "current reward: 28.3655747764136; current state: [27.444444444444443, 10.406284325178683]\n",
      "maximizing action\n",
      "[5.5940449 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (111, 43)\n",
      "act action : 19\n",
      "reward: 30.59358718070106\n",
      "current reward: 30.59358718070106; current state: [27.444444444444443, 3.704476120814895]\n",
      "maximizing action\n",
      "[17.21295962  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 29.612455397364254\n",
      "current reward: 29.612455397364254; current state: [26.925925925925927, 5.485310163381651]\n",
      "maximizing action\n",
      "[11.38421638  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.725097307714297\n",
      "current reward: 29.725097307714297; current state: [25.62962962962963, 6.130255436058506]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 27)\n",
      "act action : 19\n",
      "reward: 29.39160719065922\n",
      "current reward: 29.39160719065922; current state: [26.925925925925927, 2.9471973693791087]\n",
      "maximizing action\n",
      "[11.62569928  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 13)\n",
      "act action : 19\n",
      "reward: 28.908953740842392\n",
      "current reward: 28.908953740842392; current state: [33.0, 4.142775225326255]\n",
      "maximizing action\n",
      "[5.34389993 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 19)\n",
      "act action : 19\n",
      "reward: 29.128673201313145\n",
      "current reward: 29.128673201313145; current state: [29.0, 7.5749583954312705]\n",
      "maximizing action\n",
      "[10.96243009  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 33)\n",
      "act action : 19\n",
      "reward: 29.316122227811487\n",
      "current reward: 29.316122227811487; current state: [29.77777777777778, 4.784145789503749]\n",
      "maximizing action\n",
      "[11.23798953  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 29.54326462396948\n",
      "current reward: 29.54326462396948; current state: [32.51851851851852, 5.297458725555184]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 23)\n",
      "act action : 19\n",
      "reward: 30.57141385280421\n",
      "current reward: 30.57141385280421; current state: [29.77777777777778, 2.943732049835853]\n",
      "maximizing action\n",
      "[5.63278724 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 29.29770847151477\n",
      "current reward: 29.29770847151477; current state: [30.555555555555557, 8.542830127194495]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 37)\n",
      "act action : 19\n",
      "reward: 29.31893475609529\n",
      "current reward: 29.31893475609529; current state: [31.962962962962962, 8.488392940001797]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 35)\n",
      "act action : 19\n",
      "reward: 29.198407064190576\n",
      "current reward: 29.198407064190576; current state: [29.14814814814815, 4.415975869186464]\n",
      "maximizing action\n",
      "[17.27522374  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 29.390687665140025\n",
      "current reward: 29.390687665140025; current state: [31.666666666666668, 3.9855119901573195]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 29.694157169145498\n",
      "current reward: 29.694157169145498; current state: [28.40740740740741, 6.8240642759904695]\n",
      "maximizing action\n",
      "[11.2247367  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 29.13093633636579\n",
      "current reward: 29.13093633636579; current state: [27.666666666666668, 3.891246616656636]\n",
      "maximizing action\n",
      "[5.60101265 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 29.240968844535573\n",
      "current reward: 29.240968844535573; current state: [21.74074074074074, 12.410974716604263]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 51)\n",
      "act action : 19\n",
      "reward: 29.49674362133992\n",
      "current reward: 29.49674362133992; current state: [24.333333333333332, 5.638507455048701]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 29.15533911191234\n",
      "current reward: 29.15533911191234; current state: [26.185185185185187, 9.16845927037785]\n",
      "maximizing action\n",
      "[5.72942785 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 39)\n",
      "act action : 19\n",
      "reward: 30.212132869521884\n",
      "current reward: 30.212132869521884; current state: [26.925925925925927, 5.779751883509862]\n",
      "maximizing action\n",
      "[22.76896295  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.655492003044987\n",
      "current reward: 29.655492003044987; current state: [27.444444444444443, 4.663429105244909]\n",
      "maximizing action\n",
      "[11.36061596  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 29.442853422737958\n",
      "current reward: 29.442853422737958; current state: [27.88888888888889, 3.8229086931212057]\n",
      "maximizing action\n",
      "[11.44920642  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 29.431474728852624\n",
      "current reward: 29.431474728852624; current state: [26.185185185185187, 8.089785126998134]\n",
      "maximizing action\n",
      "[17.29067343  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 29.579840672301074\n",
      "current reward: 29.579840672301074; current state: [27.444444444444443, 3.050090698895312]\n",
      "maximizing action\n",
      "[5.46132914 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 29.09946033004681\n",
      "current reward: 29.09946033004681; current state: [30.333333333333332, 1.964692045572733]\n",
      "maximizing action\n",
      "[5.48160239 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 9)\n",
      "act action : 19\n",
      "reward: 30.462182038223744\n",
      "current reward: 30.462182038223744; current state: [29.11111111111111, 3.692034187091778]\n",
      "maximizing action\n",
      "[11.03523265  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 29.831298043908834\n",
      "current reward: 29.831298043908834; current state: [24.22222222222222, 5.9375394903225915]\n",
      "maximizing action\n",
      "[5.83106782 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 29.577766729008715\n",
      "current reward: 29.577766729008715; current state: [25.444444444444443, 9.415037018753626]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 39)\n",
      "act action : 19\n",
      "reward: 29.02592100040643\n",
      "current reward: 29.02592100040643; current state: [27.88888888888889, 4.233313296526397]\n",
      "maximizing action\n",
      "[16.96372082  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 28.932686253144112\n",
      "current reward: 28.932686253144112; current state: [23.666666666666668, 11.048434093025287]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 47)\n",
      "act action : 19\n",
      "reward: 29.963475543723575\n",
      "current reward: 29.963475543723575; current state: [24.925925925925927, 5.373339436887799]\n",
      "maximizing action\n",
      "[5.69356342 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 23)\n",
      "act action : 19\n",
      "reward: 28.264735426817982\n",
      "current reward: 28.264735426817982; current state: [26.925925925925927, 11.783892592561836]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 49)\n",
      "act action : 19\n",
      "reward: 28.431448327623503\n",
      "current reward: 28.431448327623503; current state: [26.925925925925927, 8.888325223059317]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 28.672409543465175\n",
      "current reward: 28.672409543465175; current state: [30.814814814814813, 3.0482107411777553]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 15)\n",
      "act action : 19\n",
      "reward: 29.65419815541259\n",
      "current reward: 29.65419815541259; current state: [29.51851851851852, 7.392262043562203]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 31)\n",
      "act action : 19\n",
      "reward: 28.16997999882236\n",
      "current reward: 28.16997999882236; current state: [31.22222222222222, 1.0997734125324525]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 7)\n",
      "act action : 19\n",
      "reward: 29.71603399680737\n",
      "current reward: 29.71603399680737; current state: [32.48148148148148, 1.4058070159227531]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 7)\n",
      "act action : 19\n",
      "reward: 28.33957059269078\n",
      "current reward: 28.33957059269078; current state: [20.555555555555557, 17.381565411801382]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 71)\n",
      "act action : 19\n",
      "reward: 27.715814044358627\n",
      "current reward: 27.715814044358627; current state: [28.22222222222222, 4.197683888373536]\n",
      "maximizing action\n",
      "[11.10885607  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 29.315722912706338\n",
      "current reward: 29.315722912706338; current state: [32.111111111111114, 2.024462383852376]\n",
      "maximizing action\n",
      "[5.77497882 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 29.352893361276767\n",
      "current reward: 29.352893361276767; current state: [25.444444444444443, 11.658344898517962]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 49)\n",
      "act action : 19\n",
      "reward: 27.420918282777667\n",
      "current reward: 27.420918282777667; current state: [26.185185185185187, 5.225858907422288]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 27.57731853297498\n",
      "current reward: 27.57731853297498; current state: [23.51851851851852, 2.2607995533383463]\n",
      "maximizing action\n",
      "[5.53730865 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 11)\n",
      "act action : 19\n",
      "reward: 27.032059566801205\n",
      "current reward: 27.032059566801205; current state: [24.703703703703702, 8.66934418530754]\n",
      "maximizing action\n",
      "[5.68348016 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 27.285548253372543\n",
      "current reward: 27.285548253372543; current state: [22.333333333333332, 9.380561720662286]\n",
      "maximizing action\n",
      "[11.420388  0.        0.        0.        0.        0.      ]\n",
      "Current action = 19, current state (91, 39)\n",
      "act action : 19\n",
      "reward: 27.316196689538042\n",
      "current reward: 27.316196689538042; current state: [25.444444444444443, 2.104949239278984]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 11)\n",
      "act action : 19\n",
      "reward: 27.004094469345446\n",
      "current reward: 27.004094469345446; current state: [27.40740740740741, 4.912595734976052]\n",
      "maximizing action\n",
      "[17.24918665  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 27.30997701180181\n",
      "current reward: 27.30997701180181; current state: [26.25925925925926, 1.6625909942044013]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 9)\n",
      "act action : 19\n",
      "reward: 26.835264801648822\n",
      "current reward: 26.835264801648822; current state: [23.962962962962962, 6.731250397511477]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 29)\n",
      "act action : 19\n",
      "reward: 28.861186526881117\n",
      "current reward: 28.861186526881117; current state: [25.11111111111111, 7.932024571225797]\n",
      "maximizing action\n",
      "[5.62121574 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 28.703819643570423\n",
      "current reward: 28.703819643570423; current state: [22.814814814814813, 8.39842470347407]\n",
      "maximizing action\n",
      "[5.77546573 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (93, 35)\n",
      "act action : 19\n",
      "reward: 27.67466701547474\n",
      "current reward: 27.67466701547474; current state: [27.40740740740741, 4.919922009684385]\n",
      "maximizing action\n",
      "[22.71118205  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 27.867708521091554\n",
      "current reward: 27.867708521091554; current state: [26.25925925925926, 6.51106751471982]\n",
      "maximizing action\n",
      "[23.17372853  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 29.483688020457492\n",
      "current reward: 29.483688020457492; current state: [25.88888888888889, 3.1655433928400036]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 15)\n",
      "act action : 19\n",
      "reward: 28.30970030811152\n",
      "current reward: 28.30970030811152; current state: [22.333333333333332, 7.180093857949357]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 31)\n",
      "act action : 19\n",
      "reward: 28.08374626550126\n",
      "current reward: 28.08374626550126; current state: [25.444444444444443, 3.8811042335476325]\n",
      "maximizing action\n",
      "[5.50475464 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 17)\n",
      "act action : 19\n",
      "reward: 27.90314325830519\n",
      "current reward: 27.90314325830519; current state: [26.666666666666668, 5.533671637733846]\n",
      "maximizing action\n",
      "[28.70006135  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 28.021079963496145\n",
      "current reward: 28.021079963496145; current state: [26.666666666666668, 6.548829347693067]\n",
      "maximizing action\n",
      "[17.05953752  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 28.13061785943859\n",
      "current reward: 28.13061785943859; current state: [25.444444444444443, 9.598354847588963]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 41)\n",
      "act action : 19\n",
      "reward: 27.965084949597244\n",
      "current reward: 27.965084949597244; current state: [31.555555555555557, 0.8681210965473953]\n",
      "maximizing action\n",
      "[5.8434695 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (129, 5)\n",
      "act action : 19\n",
      "reward: 27.54776497317104\n",
      "current reward: 27.54776497317104; current state: [24.22222222222222, 12.43212096691931]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 51)\n",
      "act action : 19\n",
      "reward: 29.39484297055468\n",
      "current reward: 29.39484297055468; current state: [28.25925925925926, 1.9595348211748547]\n",
      "maximizing action\n",
      "[5.70241152 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 9)\n",
      "act action : 19\n",
      "reward: 27.74668515306728\n",
      "current reward: 27.74668515306728; current state: [27.88888888888889, 4.3155670846422804]\n",
      "maximizing action\n",
      "[22.75025807  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 27.944041766874317\n",
      "current reward: 27.944041766874317; current state: [25.88888888888889, 9.014403744571194]\n",
      "maximizing action\n",
      "[11.22224328  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 39)\n",
      "act action : 19\n",
      "reward: 28.257552337876614\n",
      "current reward: 28.257552337876614; current state: [30.62962962962963, 0.9109810867745353]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 5)\n",
      "act action : 19\n",
      "reward: 27.885003281372565\n",
      "current reward: 27.885003281372565; current state: [25.444444444444443, 9.110808507057076]\n",
      "maximizing action\n",
      "[5.8051842 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (103, 39)\n",
      "act action : 19\n",
      "reward: 28.080267528523446\n",
      "current reward: 28.080267528523446; current state: [24.703703703703702, 4.113140949394438]\n",
      "maximizing action\n",
      "[5.52821998 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 19)\n",
      "act action : 19\n",
      "reward: 27.805317400587285\n",
      "current reward: 27.805317400587285; current state: [28.25925925925926, 6.028887484148857]\n",
      "maximizing action\n",
      "[5.78403917 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 28.160884876935526\n",
      "current reward: 28.160884876935526; current state: [22.333333333333332, 11.67948886056378]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 49)\n",
      "act action : 19\n",
      "reward: 31.430952651438883\n",
      "current reward: 31.430952651438883; current state: [23.51851851851852, 7.996604803098978]\n",
      "maximizing action\n",
      "[5.68400635 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 33)\n",
      "act action : 19\n",
      "reward: 28.64351815219641\n",
      "current reward: 28.64351815219641; current state: [29.11111111111111, 2.9814978437008723]\n",
      "maximizing action\n",
      "[5.9328489 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (119, 13)\n",
      "act action : 19\n",
      "reward: 28.689278370901757\n",
      "current reward: 28.689278370901757; current state: [26.25925925925926, 3.8741462472185675]\n",
      "maximizing action\n",
      "[5.66698589 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 17)\n",
      "act action : 19\n",
      "reward: 28.39824062938305\n",
      "current reward: 28.39824062938305; current state: [24.703703703703702, 2.362221531033173]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 11)\n",
      "act action : 19\n",
      "reward: 28.60632165893267\n",
      "current reward: 28.60632165893267; current state: [24.703703703703702, 5.843642013255389]\n",
      "maximizing action\n",
      "[5.55511649 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 25)\n",
      "act action : 19\n",
      "reward: 29.171881087833963\n",
      "current reward: 29.171881087833963; current state: [26.666666666666668, 1.1849856619985646]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 7)\n",
      "act action : 19\n",
      "reward: 28.509362368959255\n",
      "current reward: 28.509362368959255; current state: [25.88888888888889, 10.124033325564957]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 43)\n",
      "act action : 19\n",
      "reward: 28.863329578277188\n",
      "current reward: 28.863329578277188; current state: [29.444444444444443, 2.9744630585642664]\n",
      "maximizing action\n",
      "[11.67070457  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 13)\n",
      "act action : 19\n",
      "reward: 28.16611898628283\n",
      "current reward: 28.16611898628283; current state: [25.11111111111111, 4.846464957004591]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 28.490925829353785\n",
      "current reward: 28.490925829353785; current state: [25.11111111111111, 4.048821378266594]\n",
      "maximizing action\n",
      "[5.53737607 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 28.138496966472236\n",
      "current reward: 28.138496966472236; current state: [24.703703703703702, 5.997549077183942]\n",
      "maximizing action\n",
      "[11.38949271  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 25)\n",
      "act action : 19\n",
      "reward: 29.703166028698735\n",
      "current reward: 29.703166028698735; current state: [23.962962962962962, 7.039358910419668]\n",
      "maximizing action\n",
      "[5.62811865 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 28.323026038601665\n",
      "current reward: 28.323026038601665; current state: [23.22222222222222, 5.285645269739654]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 23)\n",
      "act action : 19\n",
      "reward: 27.78984617116375\n",
      "current reward: 27.78984617116375; current state: [27.40740740740741, 0.7732936736992637]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 5)\n",
      "act action : 19\n",
      "reward: 28.857401920219406\n",
      "current reward: 28.857401920219406; current state: [26.25925925925926, 4.344864403097274]\n",
      "maximizing action\n",
      "[5.54534228 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 19)\n",
      "act action : 19\n",
      "reward: 28.430817388907055\n",
      "current reward: 28.430817388907055; current state: [24.703703703703702, 8.83366096171221]\n",
      "maximizing action\n",
      "[11.14058982  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 27.63105706243462\n",
      "current reward: 27.63105706243462; current state: [25.88888888888889, 5.246392833939705]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 30.225617789923913\n",
      "current reward: 30.225617789923913; current state: [26.666666666666668, 4.052280497712785]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 27.65236211153103\n",
      "current reward: 27.65236211153103; current state: [29.11111111111111, 7.068291320582926]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 31)\n",
      "act action : 19\n",
      "reward: 28.75410047245576\n",
      "current reward: 28.75410047245576; current state: [24.703703703703702, 8.338186556919974]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 35)\n",
      "act action : 19\n",
      "reward: 29.03996523520389\n",
      "current reward: 29.03996523520389; current state: [25.444444444444443, 6.3186344309005635]\n",
      "maximizing action\n",
      "[5.87380632 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 27.61115492116331\n",
      "current reward: 27.61115492116331; current state: [25.88888888888889, 7.672841814434931]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 33)\n",
      "act action : 19\n",
      "reward: 28.01505017938337\n",
      "current reward: 28.01505017938337; current state: [23.0, 8.767348507994168]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 37)\n",
      "act action : 19\n",
      "reward: 27.21552118132256\n",
      "current reward: 27.21552118132256; current state: [26.666666666666668, 3.6278760456258055]\n",
      "maximizing action\n",
      "[11.33345072  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 17)\n",
      "act action : 19\n",
      "reward: 27.445956707205692\n",
      "current reward: 27.445956707205692; current state: [29.444444444444443, 3.66049136796839]\n",
      "maximizing action\n",
      "[17.00149226  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.40289198850159\n",
      "current reward: 28.40289198850159; current state: [24.703703703703702, 9.5587930020799]\n",
      "maximizing action\n",
      "[5.50205062 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 41)\n",
      "act action : 19\n",
      "reward: 27.44104422079258\n",
      "current reward: 27.44104422079258; current state: [28.25925925925926, 2.86007440697868]\n",
      "maximizing action\n",
      "[11.16606238  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 29.07417755888604\n",
      "current reward: 29.07417755888604; current state: [27.88888888888889, 6.332788592122895]\n",
      "maximizing action\n",
      "[17.2102627  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 27.494436026346225\n",
      "current reward: 27.494436026346225; current state: [25.444444444444443, 4.686207245920822]\n",
      "maximizing action\n",
      "[5.68923686 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 30.88317029425455\n",
      "current reward: 30.88317029425455; current state: [29.962962962962962, 1.3900406056155015]\n",
      "maximizing action\n",
      "[5.27051977 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 7)\n",
      "act action : 19\n",
      "reward: 27.39748048021158\n",
      "current reward: 27.39748048021158; current state: [22.40740740740741, 14.094303281262194]\n",
      "maximizing action\n",
      "[5.4675836 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (91, 59)\n",
      "act action : 19\n",
      "reward: 27.696500675778477\n",
      "current reward: 27.696500675778477; current state: [26.185185185185187, 1.1795645668813037]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 7)\n",
      "act action : 19\n",
      "reward: 27.19876919687593\n",
      "current reward: 27.19876919687593; current state: [32.48148148148148, 1.9933564864652369]\n",
      "maximizing action\n",
      "[11.51176662  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 27.51296629794507\n",
      "current reward: 27.51296629794507; current state: [32.48148148148148, 3.421341832097078]\n",
      "maximizing action\n",
      "[5.8097173 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (131, 15)\n",
      "act action : 19\n",
      "reward: 27.297370251536382\n",
      "current reward: 27.297370251536382; current state: [24.703703703703702, 6.449792854103631]\n",
      "maximizing action\n",
      "[5.69702077 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 27)\n",
      "act action : 19\n",
      "reward: 27.66953871042196\n",
      "current reward: 27.66953871042196; current state: [22.333333333333332, 7.634683058988497]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 33)\n",
      "act action : 19\n",
      "reward: 28.297296507845036\n",
      "current reward: 28.297296507845036; current state: [25.88888888888889, 5.881866887549914]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 28.118509290185575\n",
      "current reward: 28.118509290185575; current state: [26.666666666666668, 6.170833292680886]\n",
      "maximizing action\n",
      "[5.88186485 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 28.132772007076213\n",
      "current reward: 28.132772007076213; current state: [21.77777777777778, 10.962525533573032]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 45)\n",
      "act action : 19\n",
      "reward: 28.61236212916334\n",
      "current reward: 28.61236212916334; current state: [29.962962962962962, 2.5212026109895116]\n",
      "maximizing action\n",
      "[11.49232893  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 30.154280987307104\n",
      "current reward: 30.154280987307104; current state: [24.925925925925927, 8.24900648630471]\n",
      "maximizing action\n",
      "[5.80799305 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 35)\n",
      "act action : 19\n",
      "reward: 28.23861638809466\n",
      "current reward: 28.23861638809466; current state: [24.22222222222222, 5.631225571483308]\n",
      "maximizing action\n",
      "[11.74662117  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 28.51172546942931\n",
      "current reward: 28.51172546942931; current state: [25.444444444444443, 9.923259740753553]\n",
      "maximizing action\n",
      "[5.59301699 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 41)\n",
      "act action : 19\n",
      "reward: 30.01887000106973\n",
      "current reward: 30.01887000106973; current state: [27.88888888888889, 0.089117880965511]\n",
      "maximizing action\n",
      "[10.63418203  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 3)\n",
      "act action : 19\n",
      "reward: 28.455867386056656\n",
      "current reward: 28.455867386056656; current state: [28.703703703703702, 6.243921503330497]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 27)\n",
      "act action : 19\n",
      "reward: 30.058369600647513\n",
      "current reward: 30.058369600647513; current state: [28.703703703703702, 4.886058830171267]\n",
      "maximizing action\n",
      "[5.67220879 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 28.840282570270848\n",
      "current reward: 28.840282570270848; current state: [30.814814814814813, 4.230729362250825]\n",
      "maximizing action\n",
      "[5.55918849 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 29.741543665235966\n",
      "current reward: 29.741543665235966; current state: [26.925925925925927, 8.896461028867867]\n",
      "maximizing action\n",
      "[5.73448191 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 29.317095567172185\n",
      "current reward: 29.317095567172185; current state: [25.62962962962963, 3.74750220858236]\n",
      "maximizing action\n",
      "[11.56914733  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 28.83528402088065\n",
      "current reward: 28.83528402088065; current state: [29.51851851851852, 5.086854988816941]\n",
      "maximizing action\n",
      "[17.34567558  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 28.993206030806025\n",
      "current reward: 28.993206030806025; current state: [28.22222222222222, 5.987843969768961]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 25)\n",
      "act action : 19\n",
      "reward: 29.537471357696234\n",
      "current reward: 29.537471357696234; current state: [25.0, 7.97267831703545]\n",
      "maximizing action\n",
      "[11.36197967  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 28.843038979353178\n",
      "current reward: 28.843038979353178; current state: [28.22222222222222, 4.397671685747026]\n",
      "maximizing action\n",
      "[16.97200065  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 28.430363527616677\n",
      "current reward: 28.430363527616677; current state: [29.51851851851852, 3.6859628415662717]\n",
      "maximizing action\n",
      "[28.94836426  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.52269247195206\n",
      "current reward: 29.52269247195206; current state: [24.333333333333332, 14.041027516409157]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 59)\n",
      "act action : 19\n",
      "reward: 28.740675070191173\n",
      "current reward: 28.740675070191173; current state: [28.22222222222222, 0.05119453924914677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 3)\n",
      "act action : 19\n",
      "reward: 29.74176227620218\n",
      "current reward: 29.74176227620218; current state: [30.333333333333332, 7.035657775727665]\n",
      "maximizing action\n",
      "[5.48592336 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 31)\n",
      "act action : 19\n",
      "reward: 28.40380517351493\n",
      "current reward: 28.40380517351493; current state: [31.666666666666668, 0.052616609783845275]\n",
      "maximizing action\n",
      "[5.5813336 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (129, 3)\n",
      "act action : 19\n",
      "reward: 27.97659025805588\n",
      "current reward: 27.97659025805588; current state: [31.666666666666668, 3.5281141502109934]\n",
      "maximizing action\n",
      "[5.93883143 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 29.56733578821033\n",
      "current reward: 29.56733578821033; current state: [26.925925925925927, 5.280717412465784]\n",
      "maximizing action\n",
      "[17.32923584  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 28.299614113160185\n",
      "current reward: 28.299614113160185; current state: [29.962962962962962, 1.1169721393961776]\n",
      "maximizing action\n",
      "[10.75001587  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 7)\n",
      "act action : 19\n",
      "reward: 29.57898616383891\n",
      "current reward: 29.57898616383891; current state: [22.40740740740741, 8.87956483874617]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 37)\n",
      "act action : 19\n",
      "reward: 28.07756937456212\n",
      "current reward: 28.07756937456212; current state: [26.185185185185187, 3.2010614150241277]\n",
      "maximizing action\n",
      "[5.50522452 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 15)\n",
      "act action : 19\n",
      "reward: 27.601147512871577\n",
      "current reward: 27.601147512871577; current state: [29.962962962962962, 3.772034165370495]\n",
      "maximizing action\n",
      "[34.85290275  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 27.80509542730195\n",
      "current reward: 27.80509542730195; current state: [27.88888888888889, 3.545770405357901]\n",
      "maximizing action\n",
      "[17.33550136  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 29.676601053178302\n",
      "current reward: 29.676601053178302; current state: [24.22222222222222, 5.816394211148921]\n",
      "maximizing action\n",
      "[17.44896626  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 27.412998065982208\n",
      "current reward: 27.412998065982208; current state: [23.0, 8.301895088623533]\n",
      "maximizing action\n",
      "[5.56671009 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 35)\n",
      "act action : 19\n",
      "reward: 27.696587361497716\n",
      "current reward: 27.696587361497716; current state: [30.333333333333332, 0.8374887996915645]\n",
      "maximizing action\n",
      "[5.73738364 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 5)\n",
      "act action : 19\n",
      "reward: 29.976193334397966\n",
      "current reward: 29.976193334397966; current state: [28.25925925925926, 1.6776025821169536]\n",
      "maximizing action\n",
      "[11.25174855  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 9)\n",
      "act action : 19\n",
      "reward: 27.555104152597536\n",
      "current reward: 27.555104152597536; current state: [25.88888888888889, 4.8250745822088845]\n",
      "maximizing action\n",
      "[5.2018996 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (105, 21)\n",
      "act action : 19\n",
      "reward: 27.149517571528694\n",
      "current reward: 27.149517571528694; current state: [27.88888888888889, 7.491964220710958]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 28.170798579532345\n",
      "current reward: 28.170798579532345; current state: [29.703703703703702, 0.06222380713508024]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 3)\n",
      "act action : 19\n",
      "reward: 29.12246214103874\n",
      "current reward: 29.12246214103874; current state: [23.962962962962962, 9.00655144639771]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 39)\n",
      "act action : 19\n",
      "reward: 27.879091252487566\n",
      "current reward: 27.879091252487566; current state: [25.88888888888889, 3.7629279762888963]\n",
      "maximizing action\n",
      "[17.33620414  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 27.521799179061176\n",
      "current reward: 27.521799179061176; current state: [27.074074074074073, 4.9886454711856745]\n",
      "maximizing action\n",
      "[28.28472375  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 27.345664693227963\n",
      "current reward: 27.345664693227963; current state: [27.88888888888889, 1.7894868715087568]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 9)\n",
      "act action : 19\n",
      "reward: 27.59373395192379\n",
      "current reward: 27.59373395192379; current state: [23.0, 7.335948094909845]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 31)\n",
      "act action : 19\n",
      "reward: 27.323839323062703\n",
      "current reward: 27.323839323062703; current state: [27.444444444444443, 4.136660192200076]\n",
      "maximizing action\n",
      "[16.82688023  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 27.62221095788954\n",
      "current reward: 27.62221095788954; current state: [28.703703703703702, 9.348952354161051]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 39)\n",
      "act action : 19\n",
      "reward: 27.923568789887636\n",
      "current reward: 27.923568789887636; current state: [27.444444444444443, 6.804431780585321]\n",
      "maximizing action\n",
      "[22.45418849  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 28.107161647646492\n",
      "current reward: 28.107161647646492; current state: [33.407407407407405, 0.6214307022504578]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 5)\n",
      "act action : 19\n",
      "reward: 28.569681313811\n",
      "current reward: 28.569681313811; current state: [22.40740740740741, 16.712262644192183]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 69)\n",
      "act action : 19\n",
      "reward: 28.0142916124653\n",
      "current reward: 28.0142916124653; current state: [28.703703703703702, 4.354777047243155]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 28.5993126017749\n",
      "current reward: 28.5993126017749; current state: [32.48148148148148, 3.5085147629166435]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 17)\n",
      "act action : 19\n",
      "reward: 28.34732654590888\n",
      "current reward: 28.34732654590888; current state: [26.666666666666668, 8.985183714470088]\n",
      "maximizing action\n",
      "[11.59790102  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 28.22181444945211\n",
      "current reward: 28.22181444945211; current state: [28.703703703703702, 4.729702177662829]\n",
      "maximizing action\n",
      "[11.44026531  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 30.19823838724804\n",
      "current reward: 30.19823838724804; current state: [29.11111111111111, 1.3897516693500742]\n",
      "maximizing action\n",
      "[17.3786186  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 7)\n",
      "act action : 19\n",
      "reward: 28.218716115815443\n",
      "current reward: 28.218716115815443; current state: [26.666666666666668, 7.18637703914336]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 28.41990971075043\n",
      "current reward: 28.41990971075043; current state: [27.88888888888889, 4.817919064773229]\n",
      "maximizing action\n",
      "[5.76437478 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 27.856551612933075\n",
      "current reward: 27.856551612933075; current state: [26.666666666666668, 7.877090997530537]\n",
      "maximizing action\n",
      "[11.65222213  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 28.224866402064436\n",
      "current reward: 28.224866402064436; current state: [23.0, 13.656427005351865]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 57)\n",
      "act action : 19\n",
      "reward: 28.47401240631795\n",
      "current reward: 28.47401240631795; current state: [27.88888888888889, 1.0462178241671776]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 7)\n",
      "act action : 19\n",
      "reward: 29.40870501832909\n",
      "current reward: 29.40870501832909; current state: [31.22222222222222, 2.9481957890898176]\n",
      "maximizing action\n",
      "[5.85505798 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 13)\n",
      "act action : 19\n",
      "reward: 28.16788449601066\n",
      "current reward: 28.16788449601066; current state: [28.703703703703702, 7.539535386354635]\n",
      "maximizing action\n",
      "[5.48558448 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 33)\n",
      "act action : 19\n",
      "reward: 29.816409633492288\n",
      "current reward: 29.816409633492288; current state: [30.814814814814813, 2.4267577356551695]\n",
      "maximizing action\n",
      "[5.39948731 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 11)\n",
      "act action : 19\n",
      "reward: 28.416045129291053\n",
      "current reward: 28.416045129291053; current state: [26.185185185185187, 9.94288675823773]\n",
      "maximizing action\n",
      "[17.30418304  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 41)\n",
      "act action : 19\n",
      "reward: 28.569751297881112\n",
      "current reward: 28.569751297881112; current state: [25.444444444444443, 5.185039935325763]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 27.892963803816134\n",
      "current reward: 27.892963803816134; current state: [27.88888888888889, 1.4838024577904252]\n",
      "maximizing action\n",
      "[5.881741 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (113, 7)\n",
      "act action : 19\n",
      "reward: 28.139902917512728\n",
      "current reward: 28.139902917512728; current state: [24.22222222222222, 7.868671464008132]\n",
      "maximizing action\n",
      "[11.17562447  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 29.743335623840352\n",
      "current reward: 29.743335623840352; current state: [22.40740740740741, 4.555873075205871]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 21)\n",
      "act action : 19\n",
      "reward: 28.488297560497873\n",
      "current reward: 28.488297560497873; current state: [25.444444444444443, 2.7651202761689784]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 13)\n",
      "act action : 19\n",
      "reward: 28.59751931306944\n",
      "current reward: 28.59751931306944; current state: [26.185185185185187, 10.539751199285844]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 45)\n",
      "act action : 19\n",
      "reward: 30.099470645310987\n",
      "current reward: 30.099470645310987; current state: [24.22222222222222, 11.709667525269852]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 49)\n",
      "act action : 19\n",
      "reward: 30.17760871777944\n",
      "current reward: 30.17760871777944; current state: [30.333333333333332, 4.029722581592047]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 19)\n",
      "act action : 19\n",
      "reward: 29.176849656468885\n",
      "current reward: 29.176849656468885; current state: [32.48148148148148, 1.0940247213161616]\n",
      "maximizing action\n",
      "[5.66791412 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 7)\n",
      "act action : 19\n",
      "reward: 31.44107590417705\n",
      "current reward: 31.44107590417705; current state: [27.444444444444443, 9.760401698834064]\n",
      "maximizing action\n",
      "[5.26123522 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 41)\n",
      "act action : 19\n",
      "reward: 28.92794394912237\n",
      "current reward: 28.92794394912237; current state: [26.185185185185187, 6.088397224699715]\n",
      "maximizing action\n",
      "[5.73764727 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 29.069356866296786\n",
      "current reward: 29.069356866296786; current state: [27.444444444444443, 6.411303674004474]\n",
      "maximizing action\n",
      "[11.183287  0.        0.        0.        0.        0.      ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 29.20214324870612\n",
      "current reward: 29.20214324870612; current state: [27.444444444444443, 6.229846717875516]\n",
      "maximizing action\n",
      "[17.02371565  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.804164289877264\n",
      "current reward: 28.804164289877264; current state: [29.962962962962962, 2.9786568795736224]\n",
      "maximizing action\n",
      "[17.52318513  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 28.93120797852964\n",
      "current reward: 28.93120797852964; current state: [24.925925925925927, 10.185421663105794]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 43)\n",
      "act action : 19\n",
      "reward: 28.72850842228236\n",
      "current reward: 28.72850842228236; current state: [29.962962962962962, 4.15000904566556]\n",
      "maximizing action\n",
      "[33.8507973  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.787498681811645\n",
      "current reward: 28.787498681811645; current state: [26.185185185185187, 10.288201828111191]\n",
      "maximizing action\n",
      "[5.61553024 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 43)\n",
      "act action : 19\n",
      "reward: 28.653030816477877\n",
      "current reward: 28.653030816477877; current state: [24.22222222222222, 0.3840757876707254]\n",
      "maximizing action\n",
      "[5.18383535 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 3)\n",
      "act action : 19\n",
      "reward: 30.209861770575362\n",
      "current reward: 30.209861770575362; current state: [27.88888888888889, 8.921198295673678]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 37)\n",
      "act action : 19\n",
      "reward: 28.90276805154198\n",
      "current reward: 28.90276805154198; current state: [28.25925925925926, 3.634084650443416]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 17)\n",
      "act action : 19\n",
      "reward: 27.446160841572773\n",
      "current reward: 27.446160841572773; current state: [20.555555555555557, 13.030195434812741]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 55)\n",
      "act action : 19\n",
      "reward: 29.19897759321599\n",
      "current reward: 29.19897759321599; current state: [23.51851851851852, 3.5609072511593474]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 17)\n",
      "act action : 19\n",
      "reward: 27.924341910711224\n",
      "current reward: 27.924341910711224; current state: [25.444444444444443, 2.3197312280686737]\n",
      "maximizing action\n",
      "[5.40081889 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 11)\n",
      "act action : 19\n",
      "reward: 29.143736183881796\n",
      "current reward: 29.143736183881796; current state: [26.666666666666668, 4.076291823011594]\n",
      "maximizing action\n",
      "[5.53047242 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 28.340895406311414\n",
      "current reward: 28.340895406311414; current state: [34.0, 0.04835039817974972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 3)\n",
      "act action : 19\n",
      "reward: 28.085014006711276\n",
      "current reward: 28.085014006711276; current state: [26.185185185185187, 7.992195233771935]\n",
      "maximizing action\n",
      "[5.50085281 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 28.893954869327384\n",
      "current reward: 28.893954869327384; current state: [24.925925925925927, 3.9505352833246183]\n",
      "maximizing action\n",
      "[5.5694358 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (101, 17)\n",
      "act action : 19\n",
      "reward: 27.563301921805344\n",
      "current reward: 27.563301921805344; current state: [29.51851851851852, 6.489337423169643]\n",
      "maximizing action\n",
      "[16.96228272  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 28.103474334468263\n",
      "current reward: 28.103474334468263; current state: [30.814814814814813, 2.9056050355503467]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 13)\n",
      "act action : 19\n",
      "reward: 27.607696119053227\n",
      "current reward: 27.607696119053227; current state: [30.333333333333332, 7.9069032559318755]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 33)\n",
      "act action : 19\n",
      "reward: 29.495604542895233\n",
      "current reward: 29.495604542895233; current state: [32.111111111111114, 1.5322904374136397]\n",
      "maximizing action\n",
      "[17.00430547  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 28.020668982570385\n",
      "current reward: 28.020668982570385; current state: [26.185185185185187, 7.259172804831446]\n",
      "maximizing action\n",
      "[11.16684638  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 27.53386612740948\n",
      "current reward: 27.53386612740948; current state: [28.22222222222222, 7.828000941960676]\n",
      "maximizing action\n",
      "[5.71220691 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 33)\n",
      "act action : 19\n",
      "reward: 27.528065462219498\n",
      "current reward: 27.528065462219498; current state: [29.11111111111111, 4.500872672622533]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 26.979372610819038\n",
      "current reward: 26.979372610819038; current state: [26.185185185185187, 10.309943335522794]\n",
      "maximizing action\n",
      "[11.34613641  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 43)\n",
      "act action : 19\n",
      "reward: 27.1443873621127\n",
      "current reward: 27.1443873621127; current state: [26.666666666666668, 8.175656916682138]\n",
      "maximizing action\n",
      "[5.76484844 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 35)\n",
      "act action : 19\n",
      "reward: 27.424047344323355\n",
      "current reward: 27.424047344323355; current state: [31.555555555555557, 1.6884430218169517]\n",
      "maximizing action\n",
      "[5.37151927 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 9)\n",
      "act action : 19\n",
      "reward: 27.026498706833788\n",
      "current reward: 27.026498706833788; current state: [27.444444444444443, 9.685206814768675]\n",
      "maximizing action\n",
      "[11.04682401  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 41)\n",
      "act action : 19\n",
      "reward: 30.82860430505713\n",
      "current reward: 30.82860430505713; current state: [26.666666666666668, 6.094196487740169]\n",
      "maximizing action\n",
      "[11.50841926  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 27.38853244063098\n",
      "current reward: 27.38853244063098; current state: [29.11111111111111, 4.4024911878360955]\n",
      "maximizing action\n",
      "[23.15336127  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 27.59436318780107\n",
      "current reward: 27.59436318780107; current state: [30.333333333333332, 4.769144390177469]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 21)\n",
      "act action : 19\n",
      "reward: 28.585555267524303\n",
      "current reward: 28.585555267524303; current state: [26.185185185185187, 10.072960730986896]\n",
      "maximizing action\n",
      "[16.77501388  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 43)\n",
      "act action : 19\n",
      "reward: 28.52872346197779\n",
      "current reward: 28.52872346197779; current state: [27.444444444444443, 2.0330462066756607]\n",
      "maximizing action\n",
      "[5.64436911 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 27.886972354251\n",
      "current reward: 27.886972354251; current state: [27.444444444444443, 9.043298102822241]\n",
      "maximizing action\n",
      "[11.31970418  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 39)\n",
      "act action : 19\n",
      "reward: 29.313062079132163\n",
      "current reward: 29.313062079132163; current state: [20.444444444444443, 15.22539854802048]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (83, 63)\n",
      "act action : 19\n",
      "reward: 27.602214760943166\n",
      "current reward: 27.602214760943166; current state: [24.925925925925927, 4.6775330577753556]\n",
      "maximizing action\n",
      "[11.2114533  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (101, 21)\n",
      "act action : 19\n",
      "reward: 27.74661270093752\n",
      "current reward: 27.74661270093752; current state: [30.814814814814813, 2.8269710481082124]\n",
      "maximizing action\n",
      "[5.52153922 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 13)\n",
      "act action : 19\n",
      "reward: 27.82289166773118\n",
      "current reward: 27.82289166773118; current state: [24.925925925925927, 11.809643407602586]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 49)\n",
      "act action : 19\n",
      "reward: 27.7995501738349\n",
      "current reward: 27.7995501738349; current state: [27.88888888888889, 7.156649891599833]\n",
      "maximizing action\n",
      "[5.63415972 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 29.238607048407758\n",
      "current reward: 29.238607048407758; current state: [29.962962962962962, 4.166291723413339]\n",
      "maximizing action\n",
      "[40.50766837  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 27.790960624100006\n",
      "current reward: 27.790960624100006; current state: [29.11111111111111, 4.976196535151457]\n",
      "maximizing action\n",
      "[6.29524585 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 27.661131919858693\n",
      "current reward: 27.661131919858693; current state: [29.11111111111111, 3.2937037672979708]\n",
      "maximizing action\n",
      "[16.81382137  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 29.42287899654889\n",
      "current reward: 29.42287899654889; current state: [27.88888888888889, 4.829853555479811]\n",
      "maximizing action\n",
      "[11.3356851  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 27.170951452489238\n",
      "current reward: 27.170951452489238; current state: [24.925925925925927, 8.434276135572802]\n",
      "maximizing action\n",
      "[11.45571632  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 35)\n",
      "act action : 19\n",
      "reward: 28.74640923968175\n",
      "current reward: 28.74640923968175; current state: [26.185185185185187, 4.921354964795166]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 27.725402091852704\n",
      "current reward: 27.725402091852704; current state: [28.703703703703702, 4.1470602116213655]\n",
      "maximizing action\n",
      "[5.71986252 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 27.982333718667444\n",
      "current reward: 27.982333718667444; current state: [23.666666666666668, 8.041069194622798]\n",
      "maximizing action\n",
      "[5.65819371 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 35)\n",
      "act action : 19\n",
      "reward: 26.29539831836185\n",
      "current reward: 26.29539831836185; current state: [28.703703703703702, 4.275751543250284]\n",
      "maximizing action\n",
      "[11.31632926  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 27.616501170247698\n",
      "current reward: 27.616501170247698; current state: [30.333333333333332, 6.5265968504573255]\n",
      "maximizing action\n",
      "[5.54203006 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 29)\n",
      "act action : 19\n",
      "reward: 27.793699457155626\n",
      "current reward: 27.793699457155626; current state: [26.925925925925927, 6.444168512848677]\n",
      "maximizing action\n",
      "[16.98612574  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 28.3449201025478\n",
      "current reward: 28.3449201025478; current state: [29.51851851851852, 3.3668527369750274]\n",
      "maximizing action\n",
      "[5.92150422 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 15)\n",
      "act action : 19\n",
      "reward: 28.220151947390047\n",
      "current reward: 28.220151947390047; current state: [31.22222222222222, 4.45277011329318]\n",
      "maximizing action\n",
      "[11.48681275  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 19)\n",
      "act action : 19\n",
      "reward: 29.3842629763939\n",
      "current reward: 29.3842629763939; current state: [27.444444444444443, 8.318232197382688]\n",
      "maximizing action\n",
      "[11.37802484  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 28.07075331046725\n",
      "current reward: 28.07075331046725; current state: [26.925925925925927, 5.580536634782984]\n",
      "maximizing action\n",
      "[34.30427735  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.750493474133762\n",
      "current reward: 29.750493474133762; current state: [33.74074074074074, 2.0950671046092184]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (137, 11)\n",
      "act action : 19\n",
      "reward: 28.123571162220326\n",
      "current reward: 28.123571162220326; current state: [26.925925925925927, 12.18737963244356]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 51)\n",
      "act action : 19\n",
      "reward: 28.27798107955608\n",
      "current reward: 28.27798107955608; current state: [24.333333333333332, 7.424352850189553]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 31)\n",
      "act action : 19\n",
      "reward: 29.569293788358703\n",
      "current reward: 29.569293788358703; current state: [27.444444444444443, 9.754696913640192]\n",
      "maximizing action\n",
      "[17.21254487  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 41)\n",
      "act action : 19\n",
      "reward: 27.869123301513998\n",
      "current reward: 27.869123301513998; current state: [21.74074074074074, 7.923775778888922]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 33)\n",
      "act action : 19\n",
      "reward: 27.845169536391236\n",
      "current reward: 27.845169536391236; current state: [23.666666666666668, 4.060499817773611]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 19)\n",
      "act action : 19\n",
      "reward: 29.578776735979243\n",
      "current reward: 29.578776735979243; current state: [25.62962962962963, 5.352771313321903]\n",
      "maximizing action\n",
      "[6.04512356 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 27.91374498319939\n",
      "current reward: 27.91374498319939; current state: [27.444444444444443, 3.2772526917779485]\n",
      "maximizing action\n",
      "[11.28122121  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 27.962397622143357\n",
      "current reward: 27.962397622143357; current state: [26.666666666666668, 7.580921254975679]\n",
      "maximizing action\n",
      "[17.29719541  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 29.2690997985958\n",
      "current reward: 29.2690997985958; current state: [24.703703703703702, 3.900204665866795]\n",
      "maximizing action\n",
      "[11.08209618  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 17)\n",
      "act action : 19\n",
      "reward: 27.558568783936874\n",
      "current reward: 27.558568783936874; current state: [27.074074074074073, 3.8109643378879934]\n",
      "maximizing action\n",
      "[23.1354507  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 27.05673892011977\n",
      "current reward: 27.05673892011977; current state: [30.333333333333332, 3.628520858738616]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         18.37947051]\n",
      "Current action = 33, current state (123, 17)\n",
      "act action : 33\n",
      "reward: 27.291920269793092\n",
      "current reward: 27.291920269793092; current state: [30.333333333333332, 2.0726636300071988]\n",
      "maximizing action\n",
      "[6.4270836 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 28.861945997877413\n",
      "current reward: 28.861945997877413; current state: [24.925925925925927, 10.842946695739169]\n",
      "maximizing action\n",
      "[5.57049889 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 45)\n",
      "act action : 19\n",
      "reward: 28.981832254521038\n",
      "current reward: 28.981832254521038; current state: [27.444444444444443, 5.940121937108186]\n",
      "maximizing action\n",
      "[17.03596689  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.795209177376908\n",
      "current reward: 28.795209177376908; current state: [30.333333333333332, 3.545194029023651]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         23.83785457]\n",
      "Current action = 33, current state (123, 17)\n",
      "act action : 33\n",
      "reward: 26.946575535594054\n",
      "current reward: 26.946575535594054; current state: [23.666666666666668, 16.269924805506683]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 67)\n",
      "act action : 19\n",
      "reward: 27.155401551996032\n",
      "current reward: 27.155401551996032; current state: [27.444444444444443, 6.153202343411034]\n",
      "maximizing action\n",
      "[22.78454851  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.674076352556643\n",
      "current reward: 28.674076352556643; current state: [30.814814814814813, 2.7737861933499923]\n",
      "maximizing action\n",
      "[11.08611756  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 13)\n",
      "act action : 19\n",
      "reward: 27.216601933405173\n",
      "current reward: 27.216601933405173; current state: [27.88888888888889, 7.4663074712818505]\n",
      "maximizing action\n",
      "[11.48188113  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 27.68974942681265\n",
      "current reward: 27.68974942681265; current state: [29.11111111111111, 3.1573634209366683]\n",
      "maximizing action\n",
      "[22.69839717  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 27.3813156296828\n",
      "current reward: 27.3813156296828; current state: [29.11111111111111, 3.8010516696003784]\n",
      "maximizing action\n",
      "[22.68207066  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.39973989676594\n",
      "current reward: 28.39973989676594; current state: [30.62962962962963, 2.1578456806482853]\n",
      "maximizing action\n",
      "[11.08269634  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 11)\n",
      "act action : 19\n",
      "reward: 27.548189300357034\n",
      "current reward: 27.548189300357034; current state: [28.25925925925926, 6.052032714132001]\n",
      "maximizing action\n",
      "[11.41621615  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 28.57310015834599\n",
      "current reward: 28.57310015834599; current state: [24.703703703703702, 6.455673641312536]\n",
      "maximizing action\n",
      "[11.23092851  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 27)\n",
      "act action : 19\n",
      "reward: 28.390046276655593\n",
      "current reward: 28.390046276655593; current state: [25.444444444444443, 5.580393724879197]\n",
      "maximizing action\n",
      "[5.59682053 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 25)\n",
      "act action : 19\n",
      "reward: 27.913295052023745\n",
      "current reward: 27.913295052023745; current state: [27.074074074074073, 2.4530736542705225]\n",
      "maximizing action\n",
      "[11.22176358  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 28.068633707139124\n",
      "current reward: 28.068633707139124; current state: [24.703703703703702, 5.111990048811294]\n",
      "maximizing action\n",
      "[11.34651051  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 23)\n",
      "act action : 19\n",
      "reward: 27.613531568486987\n",
      "current reward: 27.613531568486987; current state: [24.22222222222222, 6.580134942805659]\n",
      "maximizing action\n",
      "[5.58692602 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 29)\n",
      "act action : 19\n",
      "reward: 29.00892301960791\n",
      "current reward: 29.00892301960791; current state: [22.333333333333332, 6.447962046646351]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 27)\n",
      "act action : 19\n",
      "reward: 28.029941947848467\n",
      "current reward: 28.029941947848467; current state: [27.88888888888889, 2.149314072100107]\n",
      "maximizing action\n",
      "[11.09605104  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 11)\n",
      "act action : 19\n",
      "reward: 28.280697807189288\n",
      "current reward: 28.280697807189288; current state: [26.666666666666668, 6.1268879292535185]\n",
      "maximizing action\n",
      "[22.65510977  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 29.262561160543154\n",
      "current reward: 29.262561160543154; current state: [23.51851851851852, 5.672321307760091]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 25)\n",
      "act action : 19\n",
      "reward: 27.99252272142252\n",
      "current reward: 27.99252272142252; current state: [30.333333333333332, 0.9345931550287482]\n",
      "maximizing action\n",
      "[11.7326223  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (123, 5)\n",
      "act action : 19\n",
      "reward: 28.260803003671896\n",
      "current reward: 28.260803003671896; current state: [27.88888888888889, 6.747903953067764]\n",
      "maximizing action\n",
      "[11.33996393  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 29)\n",
      "act action : 19\n",
      "reward: 27.946195094005645\n",
      "current reward: 27.946195094005645; current state: [28.703703703703702, 3.5435720654939]\n",
      "maximizing action\n",
      "[16.18390945  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 29.02981416641312\n",
      "current reward: 29.02981416641312; current state: [24.925925925925927, 5.023095813056445]\n",
      "maximizing action\n",
      "[16.86921682  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 23)\n",
      "act action : 19\n",
      "reward: 27.839647392476238\n",
      "current reward: 27.839647392476238; current state: [28.22222222222222, 2.580473183637734]\n",
      "maximizing action\n",
      "[16.9808979  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 28.802076723761214\n",
      "current reward: 28.802076723761214; current state: [26.925925925925927, 7.876597331563956]\n",
      "maximizing action\n",
      "[23.15101537  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 29.03443809599263\n",
      "current reward: 29.03443809599263; current state: [28.703703703703702, 4.291697148591196]\n",
      "maximizing action\n",
      "[16.8396295  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 27.684964883962774\n",
      "current reward: 27.684964883962774; current state: [30.814814814814813, 5.7387110138396515]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 27.798960806166438\n",
      "current reward: 27.798960806166438; current state: [31.22222222222222, 4.083876227470677]\n",
      "maximizing action\n",
      "[17.36366535  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 19)\n",
      "act action : 19\n",
      "reward: 27.403672438370975\n",
      "current reward: 27.403672438370975; current state: [26.185185185185187, 10.68958468580419]\n",
      "maximizing action\n",
      "[6.01989413 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 45)\n",
      "act action : 19\n",
      "reward: 29.27314096067343\n",
      "current reward: 29.27314096067343; current state: [27.444444444444443, 2.2191694138323945]\n",
      "maximizing action\n",
      "[16.83549032  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 27.601939306223112\n",
      "current reward: 27.601939306223112; current state: [24.22222222222222, 11.333776829096623]\n",
      "maximizing action\n",
      "[5.94424457 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 47)\n",
      "act action : 19\n",
      "reward: 29.39370333104908\n",
      "current reward: 29.39370333104908; current state: [28.703703703703702, 5.760692307733673]\n",
      "maximizing action\n",
      "[5.93252901 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 28.414939517635815\n",
      "current reward: 28.414939517635815; current state: [31.22222222222222, 3.663686038637019]\n",
      "maximizing action\n",
      "[5.32393188 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 17)\n",
      "act action : 19\n",
      "reward: 28.06926752875205\n",
      "current reward: 28.06926752875205; current state: [32.48148148148148, 4.334778330026451]\n",
      "maximizing action\n",
      "[16.89917243  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 28.183577555055546\n",
      "current reward: 28.183577555055546; current state: [22.40740740740741, 13.538307039096523]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 57)\n",
      "act action : 19\n",
      "reward: 29.821643457767166\n",
      "current reward: 29.821643457767166; current state: [21.74074074074074, 5.3770299242598805]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 23)\n",
      "act action : 19\n",
      "reward: 28.18726379374505\n",
      "current reward: 28.18726379374505; current state: [27.444444444444443, 2.6135132174900093]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 13)\n",
      "act action : 19\n",
      "reward: 28.32071628044115\n",
      "current reward: 28.32071628044115; current state: [31.22222222222222, 1.8495905753301551]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 9)\n",
      "act action : 19\n",
      "reward: 31.235131251852355\n",
      "current reward: 31.235131251852355; current state: [32.111111111111114, 4.464837400451592]\n",
      "maximizing action\n",
      "[22.53588794  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 28.641290802815764\n",
      "current reward: 28.641290802815764; current state: [31.22222222222222, 2.436147993470794]\n",
      "maximizing action\n",
      "[17.26676116  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 11)\n",
      "act action : 19\n",
      "reward: 28.2991607005448\n",
      "current reward: 28.2991607005448; current state: [30.814814814814813, 5.617247555785228]\n",
      "maximizing action\n",
      "[5.55979216 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 28.35324605275464\n",
      "current reward: 28.35324605275464; current state: [26.185185185185187, 6.220899110921142]\n",
      "maximizing action\n",
      "[11.55151864  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 28.607200498585467\n",
      "current reward: 28.607200498585467; current state: [23.666666666666668, 7.410919406504139]\n",
      "maximizing action\n",
      "[11.29272385  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 28.878392675715805\n",
      "current reward: 28.878392675715805; current state: [26.666666666666668, 8.799932652253451]\n",
      "maximizing action\n",
      "[17.24226391  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 28.982273188796352\n",
      "current reward: 28.982273188796352; current state: [27.88888888888889, 3.00399155562023]\n",
      "maximizing action\n",
      "[5.53458708 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 15)\n",
      "act action : 19\n",
      "reward: 28.92931477993559\n",
      "current reward: 28.92931477993559; current state: [26.185185185185187, 5.209771382532757]\n",
      "maximizing action\n",
      "[5.51546371 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 29.714292850710052\n",
      "current reward: 29.714292850710052; current state: [25.444444444444443, 8.19863810920608]\n",
      "maximizing action\n",
      "[11.14325315  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 28.382912831136252\n",
      "current reward: 28.382912831136252; current state: [26.185185185185187, 6.293505288049259]\n",
      "maximizing action\n",
      "[17.27295874  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 28.818994473326246\n",
      "current reward: 28.818994473326246; current state: [23.666666666666668, 9.759425486085421]\n",
      "maximizing action\n",
      "[11.61165093  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 28.670734589382253\n",
      "current reward: 28.670734589382253; current state: [29.962962962962962, 1.497041217978216]\n",
      "maximizing action\n",
      "[16.6658131  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 7)\n",
      "act action : 19\n",
      "reward: 28.2553854701339\n",
      "current reward: 28.2553854701339; current state: [32.111111111111114, 2.254486893990373]\n",
      "maximizing action\n",
      "[11.64555749  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 28.661029991765968\n",
      "current reward: 28.661029991765968; current state: [28.22222222222222, 9.36857341453845]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 39)\n",
      "act action : 19\n",
      "reward: 27.415396326349992\n",
      "current reward: 27.415396326349992; current state: [26.333333333333332, 5.6831424886206285]\n",
      "maximizing action\n",
      "[35.32889457  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 28.278585583541158\n",
      "current reward: 28.278585583541158; current state: [23.037037037037038, 8.459329083705462]\n",
      "maximizing action\n",
      "[11.10602756  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (95, 35)\n",
      "act action : 19\n",
      "reward: 28.41786606115477\n",
      "current reward: 28.41786606115477; current state: [25.62962962962963, 5.3332656535495175]\n",
      "maximizing action\n",
      "[11.62787255  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 27.990930616375532\n",
      "current reward: 27.990930616375532; current state: [29.51851851851852, 6.501249813172721]\n",
      "maximizing action\n",
      "[11.2699856  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 28.31559522526331\n",
      "current reward: 28.31559522526331; current state: [27.444444444444443, 7.97595665005239]\n",
      "maximizing action\n",
      "[5.89810675 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 33)\n",
      "act action : 19\n",
      "reward: 28.423358062196854\n",
      "current reward: 28.423358062196854; current state: [25.444444444444443, 4.287255994646713]\n",
      "maximizing action\n",
      "[11.16507546  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 28.304825772556274\n",
      "current reward: 28.304825772556274; current state: [27.444444444444443, 11.574644227438414]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 49)\n",
      "act action : 19\n",
      "reward: 28.03031488192212\n",
      "current reward: 28.03031488192212; current state: [24.925925925925927, 8.752151429712955]\n",
      "maximizing action\n",
      "[16.66680123  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 28.445379522494942\n",
      "current reward: 28.445379522494942; current state: [27.444444444444443, 5.048994987982756]\n",
      "maximizing action\n",
      "[16.88039944  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 23)\n",
      "act action : 19\n",
      "reward: 29.94443853075789\n",
      "current reward: 29.94443853075789; current state: [28.703703703703702, 5.9682435908679246]\n",
      "maximizing action\n",
      "[11.61551691  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 28.105301075080817\n",
      "current reward: 28.105301075080817; current state: [31.22222222222222, 0.20439595767932822]\n",
      "maximizing action\n",
      "[5.94741148 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 3)\n",
      "act action : 19\n",
      "reward: 28.320573416090316\n",
      "current reward: 28.320573416090316; current state: [27.444444444444443, 6.645730903622327]\n",
      "maximizing action\n",
      "[28.07562082  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 29.59275759826245\n",
      "current reward: 29.59275759826245; current state: [28.22222222222222, 3.120980027667355]\n",
      "maximizing action\n",
      "[11.54101753  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 15)\n",
      "act action : 19\n",
      "reward: 28.548662647299093\n",
      "current reward: 28.548662647299093; current state: [26.925925925925927, 6.745428558140819]\n",
      "maximizing action\n",
      "[22.68566109  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 29.525131347437938\n",
      "current reward: 29.525131347437938; current state: [26.185185185185187, 3.501534017773804]\n",
      "maximizing action\n",
      "[11.34663401  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 17)\n",
      "act action : 19\n",
      "reward: 29.615391361039883\n",
      "current reward: 29.615391361039883; current state: [27.444444444444443, 3.9016259730471785]\n",
      "maximizing action\n",
      "[28.54679848  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 29.18467572581034\n",
      "current reward: 29.18467572581034; current state: [24.925925925925927, 5.723338825970818]\n",
      "maximizing action\n",
      "[17.33012592  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 25)\n",
      "act action : 19\n",
      "reward: 29.678624941570835\n",
      "current reward: 29.678624941570835; current state: [25.444444444444443, 3.0647317037286594]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 15)\n",
      "act action : 19\n",
      "reward: 28.54317833578723\n",
      "current reward: 28.54317833578723; current state: [23.51851851851852, 5.711610656057068]\n",
      "maximizing action\n",
      "[5.59850454 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 25)\n",
      "act action : 19\n",
      "reward: 27.97660168004691\n",
      "current reward: 27.97660168004691; current state: [26.185185185185187, 3.0810202230218584]\n",
      "maximizing action\n",
      "[11.02545402  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 15)\n",
      "act action : 19\n",
      "reward: 28.945628145807536\n",
      "current reward: 28.945628145807536; current state: [29.11111111111111, 0.9290590355657444]\n",
      "maximizing action\n",
      "[5.79400196 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 5)\n",
      "act action : 19\n",
      "reward: 28.385045949016227\n",
      "current reward: 28.385045949016227; current state: [29.11111111111111, 4.273340688074402]\n",
      "maximizing action\n",
      "[28.67223391  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 29.482366992934157\n",
      "current reward: 29.482366992934157; current state: [32.48148148148148, 1.946888015308711]\n",
      "maximizing action\n",
      "[22.60843927  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 28.845635177806642\n",
      "current reward: 28.845635177806642; current state: [29.962962962962962, 5.568751792616393]\n",
      "maximizing action\n",
      "[5.478072 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 30.00404525280221\n",
      "current reward: 30.00404525280221; current state: [29.962962962962962, 4.052067431625172]\n",
      "maximizing action\n",
      "[46.06586049  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 30.332912745343133\n",
      "current reward: 30.332912745343133; current state: [29.11111111111111, 6.37691440273033]\n",
      "maximizing action\n",
      "[11.39934676  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 27)\n",
      "act action : 19\n",
      "reward: 29.465163728869403\n",
      "current reward: 29.465163728869403; current state: [25.444444444444443, 7.933037481858142]\n",
      "maximizing action\n",
      "[17.13058746  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 30.161640832569088\n",
      "current reward: 30.161640832569088; current state: [23.0, 7.214575097827301]\n",
      "maximizing action\n",
      "[5.45539856 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 31)\n",
      "act action : 19\n",
      "reward: 29.36916483870584\n",
      "current reward: 29.36916483870584; current state: [30.62962962962963, 1.5662032909265216]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 9)\n",
      "act action : 19\n",
      "reward: 29.416336884444302\n",
      "current reward: 29.416336884444302; current state: [26.666666666666668, 7.272791146742399]\n",
      "maximizing action\n",
      "[5.68398194 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 29.62586455640975\n",
      "current reward: 29.62586455640975; current state: [23.0, 9.339160346907288]\n",
      "maximizing action\n",
      "[5.99838104 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 39)\n",
      "act action : 19\n",
      "reward: 29.292422769770855\n",
      "current reward: 29.292422769770855; current state: [28.703703703703702, 2.8608786609722734]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 13)\n",
      "act action : 19\n",
      "reward: 29.375143901589308\n",
      "current reward: 29.375143901589308; current state: [23.666666666666668, 6.693491444678387]\n",
      "maximizing action\n",
      "[5.77223731 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 29)\n",
      "act action : 19\n",
      "reward: 29.626953799624477\n",
      "current reward: 29.626953799624477; current state: [27.444444444444443, 2.7533880660759995]\n",
      "maximizing action\n",
      "[5.66414326 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 13)\n",
      "act action : 19\n",
      "reward: 29.75481690957137\n",
      "current reward: 29.75481690957137; current state: [30.814814814814813, 4.383935739323979]\n",
      "maximizing action\n",
      "[11.50749722  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 29.870953911493803\n",
      "current reward: 29.870953911493803; current state: [30.814814814814813, 4.3325889461809926]\n",
      "maximizing action\n",
      "[17.481688  0.        0.        0.        0.        0.      ]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 29.662918251088588\n",
      "current reward: 29.662918251088588; current state: [30.333333333333332, 2.4729730820583886]\n",
      "maximizing action\n",
      "[12.1994728  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 30.788889970028972\n",
      "current reward: 30.788889970028972; current state: [22.40740740740741, 12.944175967443165]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 53)\n",
      "act action : 19\n",
      "reward: 29.80691954404324\n",
      "current reward: 29.80691954404324; current state: [26.666666666666668, 7.133796322359671]\n",
      "maximizing action\n",
      "[11.60042833  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 30.134410870463878\n",
      "current reward: 30.134410870463878; current state: [30.333333333333332, 2.120581288840029]\n",
      "maximizing action\n",
      "[18.35725079  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 29.045199308313627\n",
      "current reward: 29.045199308313627; current state: [27.88888888888889, 3.102663330911427]\n",
      "maximizing action\n",
      "[11.32045003  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 15)\n",
      "act action : 19\n",
      "reward: 29.821469281019574\n",
      "current reward: 29.821469281019574; current state: [26.185185185185187, 6.763977625971436]\n",
      "maximizing action\n",
      "[29.07046613  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 30.159729167487484\n",
      "current reward: 30.159729167487484; current state: [29.962962962962962, 3.987204788745546]\n",
      "maximizing action\n",
      "[40.41392184  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.007104019814033\n",
      "current reward: 29.007104019814033; current state: [26.925925925925927, 5.177387351910109]\n",
      "maximizing action\n",
      "[22.98915866  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.92871610609484\n",
      "current reward: 29.92871610609484; current state: [24.333333333333332, 8.879171496689569]\n",
      "maximizing action\n",
      "[11.5450031  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (99, 37)\n",
      "act action : 19\n",
      "reward: 30.398841545884483\n",
      "current reward: 30.398841545884483; current state: [30.814814814814813, 2.1843805495451]\n",
      "maximizing action\n",
      "[16.5923342  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (125, 11)\n",
      "act action : 19\n",
      "reward: 28.863625409224124\n",
      "current reward: 28.863625409224124; current state: [29.962962962962962, 1.8367429840464402]\n",
      "maximizing action\n",
      "[17.0473076  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 9)\n",
      "act action : 19\n",
      "reward: 28.99568457874771\n",
      "current reward: 28.99568457874771; current state: [28.703703703703702, 5.0343936787085175]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 23)\n",
      "act action : 19\n",
      "reward: 30.066802729590012\n",
      "current reward: 30.066802729590012; current state: [29.51851851851852, 1.676848252149224]\n",
      "maximizing action\n",
      "[22.84644452  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 9)\n",
      "act action : 19\n",
      "reward: 29.09510216479084\n",
      "current reward: 29.09510216479084; current state: [26.925925925925927, 5.525062551973123]\n",
      "maximizing action\n",
      "[40.25437604  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.23529519913377\n",
      "current reward: 29.23529519913377; current state: [28.703703703703702, 5.157151530683432]\n",
      "maximizing action\n",
      "[6.01336055 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 23)\n",
      "act action : 19\n",
      "reward: 29.082139338759134\n",
      "current reward: 29.082139338759134; current state: [26.925925925925927, 5.823723676276135]\n",
      "maximizing action\n",
      "[46.10143508  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 30.368288873218194\n",
      "current reward: 30.368288873218194; current state: [26.925925925925927, 9.688812796555341]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 41)\n",
      "act action : 19\n",
      "reward: 28.63417526981286\n",
      "current reward: 28.63417526981286; current state: [30.333333333333332, 5.51021902594545]\n",
      "maximizing action\n",
      "[5.74866229 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 25)\n",
      "act action : 19\n",
      "reward: 28.679953591217345\n",
      "current reward: 28.679953591217345; current state: [32.111111111111114, 2.636600231384428]\n",
      "maximizing action\n",
      "[17.45424574  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 13)\n",
      "act action : 19\n",
      "reward: 28.776273696111385\n",
      "current reward: 28.776273696111385; current state: [26.185185185185187, 9.847907594091643]\n",
      "maximizing action\n",
      "[23.0181333  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 41)\n",
      "act action : 19\n",
      "reward: 28.766476060966905\n",
      "current reward: 28.766476060966905; current state: [25.444444444444443, 3.5436059783855143]\n",
      "maximizing action\n",
      "[11.0853833  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (103, 17)\n",
      "act action : 19\n",
      "reward: 28.917261659415498\n",
      "current reward: 28.917261659415498; current state: [26.666666666666668, 2.459211116615089]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 11)\n",
      "act action : 19\n",
      "reward: 28.35488416888043\n",
      "current reward: 28.35488416888043; current state: [28.703703703703702, 8.075643515958697]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 35)\n",
      "act action : 19\n",
      "reward: 28.645456500081355\n",
      "current reward: 28.645456500081355; current state: [29.444444444444443, 3.6428128065965035]\n",
      "maximizing action\n",
      "[28.36201864  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.02864671884429\n",
      "current reward: 28.02864671884429; current state: [25.88888888888889, 8.622735114708421]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 37)\n",
      "act action : 19\n",
      "reward: 28.414254166561793\n",
      "current reward: 28.414254166561793; current state: [22.333333333333332, 10.328566415079457]\n",
      "maximizing action\n",
      "[11.17851044  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (91, 43)\n",
      "act action : 19\n",
      "reward: 28.323982499242074\n",
      "current reward: 28.323982499242074; current state: [25.88888888888889, 7.40516740653775]\n",
      "maximizing action\n",
      "[5.63591498 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 27.87078280741569\n",
      "current reward: 27.87078280741569; current state: [24.22222222222222, 6.275741279820198]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 27)\n",
      "act action : 19\n",
      "reward: 28.230948597436836\n",
      "current reward: 28.230948597436836; current state: [23.962962962962962, 5.1010201767495]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 23)\n",
      "act action : 19\n",
      "reward: 28.141667647083427\n",
      "current reward: 28.141667647083427; current state: [25.11111111111111, 4.75509839776386]\n",
      "maximizing action\n",
      "[11.86587091  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 28.317820438645683\n",
      "current reward: 28.317820438645683; current state: [25.11111111111111, 3.7416081479466956]\n",
      "maximizing action\n",
      "[16.86883563  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 17)\n",
      "act action : 19\n",
      "reward: 27.388463755124963\n",
      "current reward: 27.388463755124963; current state: [23.22222222222222, 6.9974740502824275]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 29)\n",
      "act action : 19\n",
      "reward: 27.606238271857432\n",
      "current reward: 27.606238271857432; current state: [21.0, 11.684029313103688]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 49)\n",
      "act action : 19\n",
      "reward: 29.456956617436827\n",
      "current reward: 29.456956617436827; current state: [23.22222222222222, 1.9301199368324131]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 9)\n",
      "act action : 19\n",
      "reward: 26.39929237005376\n",
      "current reward: 26.39929237005376; current state: [25.11111111111111, 9.03483119003388]\n",
      "maximizing action\n",
      "[11.42123771  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 39)\n",
      "act action : 19\n",
      "reward: 26.611221406679817\n",
      "current reward: 26.611221406679817; current state: [25.11111111111111, 7.769399767157219]\n",
      "maximizing action\n",
      "[23.16291563  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 27.91974054094138\n",
      "current reward: 27.91974054094138; current state: [28.25925925925926, 1.953236764109102]\n",
      "maximizing action\n",
      "[16.76276938  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 9)\n",
      "act action : 19\n",
      "reward: 28.723413418943494\n",
      "current reward: 28.723413418943494; current state: [25.88888888888889, 10.390722328732018]\n",
      "maximizing action\n",
      "[5.77266592 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 43)\n",
      "act action : 19\n",
      "reward: 26.971247650288515\n",
      "current reward: 26.971247650288515; current state: [25.88888888888889, 9.388066380890802]\n",
      "maximizing action\n",
      "[16.87375374  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 39)\n",
      "act action : 19\n",
      "reward: 26.658292163689037\n",
      "current reward: 26.658292163689037; current state: [25.444444444444443, 6.946445256106769]\n",
      "maximizing action\n",
      "[5.49043921 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 29)\n",
      "act action : 19\n",
      "reward: 26.839642733805164\n",
      "current reward: 26.839642733805164; current state: [26.666666666666668, 7.969808523577928]\n",
      "maximizing action\n",
      "[28.95790299  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 26.562038482757234\n",
      "current reward: 26.562038482757234; current state: [26.185185185185187, 7.950932475094173]\n",
      "maximizing action\n",
      "[11.27964378  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 26.53672861034674\n",
      "current reward: 26.53672861034674; current state: [24.22222222222222, 5.5660368252599834]\n",
      "maximizing action\n",
      "[22.93156588  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 28.13853064235357\n",
      "current reward: 28.13853064235357; current state: [28.703703703703702, 2.328448730075937]\n",
      "maximizing action\n",
      "[5.20110439 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 26.20779722902294\n",
      "current reward: 26.20779722902294; current state: [24.22222222222222, 12.949676655376106]\n",
      "maximizing action\n",
      "[16.83506085  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 53)\n",
      "act action : 19\n",
      "reward: 26.398097780188134\n",
      "current reward: 26.398097780188134; current state: [25.444444444444443, 3.1908838530503636]\n",
      "maximizing action\n",
      "[5.70863567 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 15)\n",
      "act action : 19\n",
      "reward: 26.269190678538063\n",
      "current reward: 26.269190678538063; current state: [26.185185185185187, 6.0405403611149335]\n",
      "maximizing action\n",
      "[23.03675764  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 26.370790008416993\n",
      "current reward: 26.370790008416993; current state: [27.88888888888889, 3.808132527254618]\n",
      "maximizing action\n",
      "[23.27082157  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 25.823823851839112\n",
      "current reward: 25.823823851839112; current state: [29.11111111111111, 4.947375140076696]\n",
      "maximizing action\n",
      "[11.82747223  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 26.866937139941598\n",
      "current reward: 26.866937139941598; current state: [25.444444444444443, 9.425112990020423]\n",
      "maximizing action\n",
      "[16.74348199  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 39)\n",
      "act action : 19\n",
      "reward: 28.50444120490874\n",
      "current reward: 28.50444120490874; current state: [25.444444444444443, 6.476207978006739]\n",
      "maximizing action\n",
      "[11.3960373  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 26.25360934780719\n",
      "current reward: 26.25360934780719; current state: [25.88888888888889, 2.0066804045249085]\n",
      "maximizing action\n",
      "[11.2330547  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (105, 11)\n",
      "act action : 19\n",
      "reward: 26.559948934361554\n",
      "current reward: 26.559948934361554; current state: [22.333333333333332, 12.13617692894765]\n",
      "maximizing action\n",
      "[5.45341601 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (91, 51)\n",
      "act action : 19\n",
      "reward: 29.315689455852123\n",
      "current reward: 29.315689455852123; current state: [25.444444444444443, 8.409973594321901]\n",
      "maximizing action\n",
      "[16.81983572  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 26.29759837584594\n",
      "current reward: 26.29759837584594; current state: [29.444444444444443, 4.598036252491597]\n",
      "maximizing action\n",
      "[17.20085966  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 25.956790598118715\n",
      "current reward: 25.956790598118715; current state: [27.074074074074073, 5.764242132721738]\n",
      "maximizing action\n",
      "[22.79500873  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.68530591267334\n",
      "current reward: 28.68530591267334; current state: [24.22222222222222, 7.63895063266098]\n",
      "maximizing action\n",
      "[17.1242916  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 26.703211972633635\n",
      "current reward: 26.703211972633635; current state: [27.074074074074073, 5.400132552817672]\n",
      "maximizing action\n",
      "[22.86928715  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 23)\n",
      "act action : 19\n",
      "reward: 26.681156299995777\n",
      "current reward: 26.681156299995777; current state: [27.88888888888889, 5.551048520490224]\n",
      "maximizing action\n",
      "[11.89236309  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 25)\n",
      "act action : 19\n",
      "reward: 26.844244519092133\n",
      "current reward: 26.844244519092133; current state: [24.703703703703702, 8.850605747944753]\n",
      "maximizing action\n",
      "[22.35587713  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 26.658416670206247\n",
      "current reward: 26.658416670206247; current state: [27.88888888888889, 2.4548555907752165]\n",
      "maximizing action\n",
      "[16.7521906  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (113, 11)\n",
      "act action : 19\n",
      "reward: 26.92467860150934\n",
      "current reward: 26.92467860150934; current state: [25.444444444444443, 8.432263383696169]\n",
      "maximizing action\n",
      "[22.0793554  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 27.797488371372935\n",
      "current reward: 27.797488371372935; current state: [21.77777777777778, 9.158356135166635]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 39)\n",
      "act action : 19\n",
      "reward: 26.794937499964018\n",
      "current reward: 26.794937499964018; current state: [27.444444444444443, 3.8833887245142753]\n",
      "maximizing action\n",
      "[34.38373363  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 27.03542519433363\n",
      "current reward: 27.03542519433363; current state: [26.185185185185187, 8.04912977425541]\n",
      "maximizing action\n",
      "[23.20664157  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 26.532379474075697\n",
      "current reward: 26.532379474075697; current state: [32.111111111111114, 2.794232840414353]\n",
      "maximizing action\n",
      "[23.20950048  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 13)\n",
      "act action : 19\n",
      "reward: 26.632182778518395\n",
      "current reward: 26.632182778518395; current state: [29.51851851851852, 3.3099543372240223]\n",
      "maximizing action\n",
      "[11.56553461  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 15)\n",
      "act action : 19\n",
      "reward: 26.46588994167637\n",
      "current reward: 26.46588994167637; current state: [27.666666666666668, 9.34930609646422]\n",
      "maximizing action\n",
      "[5.81373643 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 39)\n",
      "act action : 19\n",
      "reward: 26.729717689948874\n",
      "current reward: 26.729717689948874; current state: [34.333333333333336, 3.435777904436076]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 15)\n",
      "act action : 19\n",
      "reward: 27.643604108506363\n",
      "current reward: 27.643604108506363; current state: [27.666666666666668, 10.631949913076616]\n",
      "maximizing action\n",
      "[5.90342499 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 45)\n",
      "act action : 19\n",
      "reward: 26.80032416395592\n",
      "current reward: 26.80032416395592; current state: [27.666666666666668, 6.097291202298958]\n",
      "maximizing action\n",
      "[22.70914991  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 26.96734912709333\n",
      "current reward: 26.96734912709333; current state: [34.7037037037037, 2.1141574568744295]\n",
      "maximizing action\n",
      "[5.55687751 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (141, 11)\n",
      "act action : 19\n",
      "reward: 26.916702212022173\n",
      "current reward: 26.916702212022173; current state: [24.333333333333332, 14.116104179153934]\n",
      "maximizing action\n",
      "[5.74813501 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 59)\n",
      "act action : 19\n",
      "reward: 28.784960852874395\n",
      "current reward: 28.784960852874395; current state: [25.62962962962963, 5.2993838368504]\n",
      "maximizing action\n",
      "[17.22605868  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 28.109629804808293\n",
      "current reward: 28.109629804808293; current state: [29.962962962962962, 2.184629226381781]\n",
      "maximizing action\n",
      "[17.13726718  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 28.059560017517395\n",
      "current reward: 28.059560017517395; current state: [28.703703703703702, 4.456801651372437]\n",
      "maximizing action\n",
      "[22.37662247  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 27.457102708004573\n",
      "current reward: 27.457102708004573; current state: [21.14814814814815, 12.642755498584327]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 53)\n",
      "act action : 19\n",
      "reward: 29.211155779749646\n",
      "current reward: 29.211155779749646; current state: [28.703703703703702, 3.7273789612555612]\n",
      "maximizing action\n",
      "[21.98987228  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 27.655081563223547\n",
      "current reward: 27.655081563223547; current state: [28.703703703703702, 5.894673249913091]\n",
      "maximizing action\n",
      "[17.23657712  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 27.817468467000054\n",
      "current reward: 27.817468467000054; current state: [26.666666666666668, 6.482748591366759]\n",
      "maximizing action\n",
      "[28.507622  0.        0.        0.        0.        0.      ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 28.15647162997949\n",
      "current reward: 28.15647162997949; current state: [29.11111111111111, 3.8851708530591527]\n",
      "maximizing action\n",
      "[33.96774798  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.42756311212302\n",
      "current reward: 28.42756311212302; current state: [30.333333333333332, 4.895348281921208]\n",
      "maximizing action\n",
      "[6.61648238 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 21)\n",
      "act action : 19\n",
      "reward: 27.272663359374864\n",
      "current reward: 27.272663359374864; current state: [23.51851851851852, 7.336202736793971]\n",
      "maximizing action\n",
      "[17.06840239  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 28.47854109490935\n",
      "current reward: 28.47854109490935; current state: [18.77777777777778, 8.331823795999638]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 35)\n",
      "act action : 19\n",
      "reward: 28.114685055789536\n",
      "current reward: 28.114685055789536; current state: [30.333333333333332, 0.5293155115025404]\n",
      "maximizing action\n",
      "[17.3847829  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (123, 5)\n",
      "act action : 19\n",
      "reward: 28.76720944775663\n",
      "current reward: 28.76720944775663; current state: [29.444444444444443, 3.51895846920327]\n",
      "maximizing action\n",
      "[39.6532606  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.188660768797572\n",
      "current reward: 28.188660768797572; current state: [28.25925925925926, 3.5521459875697796]\n",
      "maximizing action\n",
      "[5.48923217 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 17)\n",
      "act action : 19\n",
      "reward: 27.947341201868955\n",
      "current reward: 27.947341201868955; current state: [25.444444444444443, 5.893159446697124]\n",
      "maximizing action\n",
      "[11.17947954  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 25)\n",
      "act action : 19\n",
      "reward: 27.217099335373234\n",
      "current reward: 27.217099335373234; current state: [25.444444444444443, 5.277651718787439]\n",
      "maximizing action\n",
      "[5.57859276 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 28.057818632832934\n",
      "current reward: 28.057818632832934; current state: [31.22222222222222, 1.6529786550777823]\n",
      "maximizing action\n",
      "[6.24702625 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 9)\n",
      "act action : 19\n",
      "reward: 28.34446142615552\n",
      "current reward: 28.34446142615552; current state: [29.962962962962962, 5.425934764234598]\n",
      "maximizing action\n",
      "[23.14431678  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 28.5744775294154\n",
      "current reward: 28.5744775294154; current state: [29.962962962962962, 2.7917804340755255]\n",
      "maximizing action\n",
      "[23.30942673  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 28.23399536779097\n",
      "current reward: 28.23399536779097; current state: [29.962962962962962, 1.7334740480299131]\n",
      "maximizing action\n",
      "[28.66546495  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 9)\n",
      "act action : 19\n",
      "reward: 29.32354526075348\n",
      "current reward: 29.32354526075348; current state: [18.62962962962963, 17.343937378342066]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 71)\n",
      "act action : 19\n",
      "reward: 28.712974221174232\n",
      "current reward: 28.712974221174232; current state: [26.185185185185187, 2.3127930403355736]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 11)\n",
      "act action : 19\n",
      "reward: 29.100180717228273\n",
      "current reward: 29.100180717228273; current state: [29.962962962962962, 6.590182681408318]\n",
      "maximizing action\n",
      "[16.93310465  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 29.531387344032524\n",
      "current reward: 29.531387344032524; current state: [28.22222222222222, 7.3138558518136865]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 31)\n",
      "act action : 19\n",
      "reward: 28.563516341695905\n",
      "current reward: 28.563516341695905; current state: [25.444444444444443, 4.648480662765691]\n",
      "maximizing action\n",
      "[17.529435  0.        0.        0.        0.        0.      ]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 28.698357378392334\n",
      "current reward: 28.698357378392334; current state: [27.88888888888889, 0.04835039817974972]\n",
      "maximizing action\n",
      "[16.32535551  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 3)\n",
      "act action : 19\n",
      "reward: 29.578562168231997\n",
      "current reward: 29.578562168231997; current state: [32.77777777777778, 0.5232937096997643]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 5)\n",
      "act action : 19\n",
      "reward: 29.68044489608633\n",
      "current reward: 29.68044489608633; current state: [26.666666666666668, 5.763403016093993]\n",
      "maximizing action\n",
      "[52.17509286  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.132968176416643\n",
      "current reward: 29.132968176416643; current state: [27.444444444444443, 3.3969107954406104]\n",
      "maximizing action\n",
      "[16.87370073  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 29.53735192543016\n",
      "current reward: 29.53735192543016; current state: [26.185185185185187, 8.345303657221047]\n",
      "maximizing action\n",
      "[28.51311746  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 28.292347974516087\n",
      "current reward: 28.292347974516087; current state: [24.333333333333332, 7.899762306800415]\n",
      "maximizing action\n",
      "[22.46493399  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 29.598119339624663\n",
      "current reward: 29.598119339624663; current state: [29.51851851851852, 4.393453504928646]\n",
      "maximizing action\n",
      "[52.13244304  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.41071415504683\n",
      "current reward: 28.41071415504683; current state: [26.925925925925927, 4.974185708657576]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 21)\n",
      "act action : 19\n",
      "reward: 27.876413052066155\n",
      "current reward: 27.876413052066155; current state: [27.666666666666668, 5.24982648418534]\n",
      "maximizing action\n",
      "[11.55079334  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 23)\n",
      "act action : 19\n",
      "reward: 27.94279628065227\n",
      "current reward: 27.94279628065227; current state: [31.666666666666668, 4.2506750933197495]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 19)\n",
      "act action : 19\n",
      "reward: 28.00802223260828\n",
      "current reward: 28.00802223260828; current state: [29.51851851851852, 7.961914082482496]\n",
      "maximizing action\n",
      "[5.77300384 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 33)\n",
      "act action : 19\n",
      "reward: 28.154692636000096\n",
      "current reward: 28.154692636000096; current state: [29.51851851851852, 3.4566102312979816]\n",
      "maximizing action\n",
      "[16.8587126  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 15)\n",
      "act action : 19\n",
      "reward: 29.661324986915123\n",
      "current reward: 29.661324986915123; current state: [29.51851851851852, 5.545484530939278]\n",
      "maximizing action\n",
      "[11.47888105  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 27.562415676967188\n",
      "current reward: 27.562415676967188; current state: [30.333333333333332, 4.286639196564373]\n",
      "maximizing action\n",
      "[5.83536993 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 19)\n",
      "act action : 19\n",
      "reward: 28.68627745662134\n",
      "current reward: 28.68627745662134; current state: [27.666666666666668, 8.040862369129671]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 35)\n",
      "act action : 19\n",
      "reward: 27.451699705219283\n",
      "current reward: 27.451699705219283; current state: [24.296296296296298, 13.445285265341468]\n",
      "maximizing action\n",
      "[5.80067047 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 55)\n",
      "act action : 19\n",
      "reward: 27.21539803398826\n",
      "current reward: 27.21539803398826; current state: [26.333333333333332, 5.237988456839749]\n",
      "maximizing action\n",
      "[11.45832228  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 27.246818990744526\n",
      "current reward: 27.246818990744526; current state: [29.51851851851852, 3.6751849542190675]\n",
      "maximizing action\n",
      "[46.21534264  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 28.54175000909927\n",
      "current reward: 28.54175000909927; current state: [29.0, 4.0844759280826715]\n",
      "maximizing action\n",
      "[34.56870731  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 27.449172777390757\n",
      "current reward: 27.449172777390757; current state: [23.666666666666668, 8.331825028812506]\n",
      "maximizing action\n",
      "[10.91727337  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 35)\n",
      "act action : 19\n",
      "reward: 26.541531377404496\n",
      "current reward: 26.541531377404496; current state: [29.962962962962962, 2.302334629704406]\n",
      "maximizing action\n",
      "[22.74917918  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 27.03191783984136\n",
      "current reward: 27.03191783984136; current state: [29.962962962962962, 6.367391990280497]\n",
      "maximizing action\n",
      "[22.58297759  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 26.353092610739193\n",
      "current reward: 26.353092610739193; current state: [33.407407407407405, 3.705130661223404]\n",
      "maximizing action\n",
      "[5.73869555 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 17)\n",
      "act action : 19\n",
      "reward: 26.42990858106768\n",
      "current reward: 26.42990858106768; current state: [29.51851851851852, 6.3242765214146255]\n",
      "maximizing action\n",
      "[27.85359611  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 27.957281213977442\n",
      "current reward: 27.957281213977442; current state: [25.62962962962963, 10.407269127572915]\n",
      "maximizing action\n",
      "[11.16691545  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 43)\n",
      "act action : 19\n",
      "reward: 27.187014298238797\n",
      "current reward: 27.187014298238797; current state: [31.666666666666668, 0.67110379855754]\n",
      "maximizing action\n",
      "[11.35302249  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (129, 5)\n",
      "act action : 19\n",
      "reward: 26.65746584962064\n",
      "current reward: 26.65746584962064; current state: [29.0, 9.383148920317137]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 39)\n",
      "act action : 19\n",
      "reward: 27.3942560953827\n",
      "current reward: 27.3942560953827; current state: [32.51851851851852, 3.7546907423216576]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 17)\n",
      "act action : 19\n",
      "reward: 26.581365267288486\n",
      "current reward: 26.581365267288486; current state: [32.51851851851852, 4.003232319760856]\n",
      "maximizing action\n",
      "[5.66004081 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (133, 19)\n",
      "act action : 19\n",
      "reward: 26.80515301161044\n",
      "current reward: 26.80515301161044; current state: [25.666666666666668, 9.561243762225692]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 41)\n",
      "act action : 19\n",
      "reward: 26.73028267352053\n",
      "current reward: 26.73028267352053; current state: [31.962962962962962, 4.786091004197408]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 21)\n",
      "act action : 19\n",
      "reward: 27.763134756580467\n",
      "current reward: 27.763134756580467; current state: [30.333333333333332, 7.222139223697866]\n",
      "maximizing action\n",
      "[11.16668439  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (123, 31)\n",
      "act action : 19\n",
      "reward: 26.73492186933738\n",
      "current reward: 26.73492186933738; current state: [32.51851851851852, 2.785358530235405]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 13)\n",
      "act action : 19\n",
      "reward: 28.904861327094086\n",
      "current reward: 28.904861327094086; current state: [27.666666666666668, 7.030043185460215]\n",
      "maximizing action\n",
      "[17.01983101  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 26.96824906342209\n",
      "current reward: 26.96824906342209; current state: [25.666666666666668, 5.979566965485027]\n",
      "maximizing action\n",
      "[5.62370186 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 27.22065813516403\n",
      "current reward: 27.22065813516403; current state: [28.40740740740741, 3.695442905781329]\n",
      "maximizing action\n",
      "[11.07870041  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 17)\n",
      "act action : 19\n",
      "reward: 27.382574878434156\n",
      "current reward: 27.382574878434156; current state: [29.0, 4.7827987730490475]\n",
      "maximizing action\n",
      "[22.39221778  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 29.098991382184888\n",
      "current reward: 29.098991382184888; current state: [25.666666666666668, 5.231554291234717]\n",
      "maximizing action\n",
      "[22.84798464  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 27.699432751437048\n",
      "current reward: 27.699432751437048; current state: [27.037037037037038, 3.822870505697824]\n",
      "maximizing action\n",
      "[39.79081867  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 27.694459067636426\n",
      "current reward: 27.694459067636426; current state: [33.0, 6.078302586295474]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 27)\n",
      "act action : 19\n",
      "reward: 28.01101633976505\n",
      "current reward: 28.01101633976505; current state: [29.0, 8.659330195884982]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 37)\n",
      "act action : 19\n",
      "reward: 28.073284187361434\n",
      "current reward: 28.073284187361434; current state: [26.333333333333332, 7.108515998774282]\n",
      "maximizing action\n",
      "[16.6736196  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 28.539087331576713\n",
      "current reward: 28.539087331576713; current state: [30.814814814814813, 2.098602173994764]\n",
      "maximizing action\n",
      "[22.36505928  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 11)\n",
      "act action : 19\n",
      "reward: 30.17640113089529\n",
      "current reward: 30.17640113089529; current state: [30.814814814814813, 5.011130528157895]\n",
      "maximizing action\n",
      "[5.75574749 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 23)\n",
      "act action : 19\n",
      "reward: 28.451978086093845\n",
      "current reward: 28.451978086093845; current state: [25.62962962962963, 8.857209829326669]\n",
      "maximizing action\n",
      "[5.68285083 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 37)\n",
      "act action : 19\n",
      "reward: 30.096205382694663\n",
      "current reward: 30.096205382694663; current state: [26.925925925925927, 6.221494641876762]\n",
      "maximizing action\n",
      "[34.13891632  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 28.929716057506393\n",
      "current reward: 28.929716057506393; current state: [29.11111111111111, 6.5322908167457845]\n",
      "maximizing action\n",
      "[11.17302592  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 28.856862648095575\n",
      "current reward: 28.856862648095575; current state: [31.22222222222222, 5.113014223227367]\n",
      "maximizing action\n",
      "[5.66273037 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 23)\n",
      "act action : 19\n",
      "reward: 28.913337247001923\n",
      "current reward: 28.913337247001923; current state: [29.11111111111111, 4.541769850013835]\n",
      "maximizing action\n",
      "[28.21201606  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 29.83749591895392\n",
      "current reward: 29.83749591895392; current state: [25.444444444444443, 7.417852902902602]\n",
      "maximizing action\n",
      "[11.17802848  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 31)\n",
      "act action : 19\n",
      "reward: 28.627782588475284\n",
      "current reward: 28.627782588475284; current state: [21.77777777777778, 10.209912505420263]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 43)\n",
      "act action : 19\n",
      "reward: 27.97158312949614\n",
      "current reward: 27.97158312949614; current state: [29.962962962962962, 0.56384450304639]\n",
      "maximizing action\n",
      "[5.83104542 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 5)\n",
      "act action : 19\n",
      "reward: 28.150913862999705\n",
      "current reward: 28.150913862999705; current state: [29.11111111111111, 2.4821743377689915]\n",
      "maximizing action\n",
      "[23.3984735  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 29.594723323146052\n",
      "current reward: 29.594723323146052; current state: [27.88888888888889, 7.345917548419538]\n",
      "maximizing action\n",
      "[22.41348082  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 28.19863158718214\n",
      "current reward: 28.19863158718214; current state: [23.0, 7.4665798684213245]\n",
      "maximizing action\n",
      "[11.32923153  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (95, 31)\n",
      "act action : 19\n",
      "reward: 29.661661669963916\n",
      "current reward: 29.661661669963916; current state: [21.77777777777778, 5.748114539362281]\n",
      "maximizing action\n",
      "[5.43202665 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (89, 25)\n",
      "act action : 19\n",
      "reward: 28.381379657175177\n",
      "current reward: 28.381379657175177; current state: [32.48148148148148, 2.046254949959331]\n",
      "maximizing action\n",
      "[17.37776349  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 28.492700161664185\n",
      "current reward: 28.492700161664185; current state: [28.703703703703702, 8.43056364198269]\n",
      "maximizing action\n",
      "[5.7290913 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (117, 35)\n",
      "act action : 19\n",
      "reward: 29.744398355253065\n",
      "current reward: 29.744398355253065; current state: [31.22222222222222, 1.758547680030949]\n",
      "maximizing action\n",
      "[11.91591854  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 9)\n",
      "act action : 19\n",
      "reward: 28.40327877175135\n",
      "current reward: 28.40327877175135; current state: [29.962962962962962, 6.297599790197813]\n",
      "maximizing action\n",
      "[33.44505235  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 29.49698663662203\n",
      "current reward: 29.49698663662203; current state: [27.88888888888889, 7.668506752516851]\n",
      "maximizing action\n",
      "[5.60923741 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 33)\n",
      "act action : 19\n",
      "reward: 27.823412016330607\n",
      "current reward: 27.823412016330607; current state: [28.25925925925926, 4.4394541660171365]\n",
      "maximizing action\n",
      "[22.65807336  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 29.507513057560896\n",
      "current reward: 29.507513057560896; current state: [25.88888888888889, 8.18269302640372]\n",
      "maximizing action\n",
      "[10.74743581  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 35)\n",
      "act action : 19\n",
      "reward: 29.315756025547557\n",
      "current reward: 29.315756025547557; current state: [24.22222222222222, 9.767612597706862]\n",
      "maximizing action\n",
      "[5.59899225 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 41)\n",
      "act action : 19\n",
      "reward: 29.654523360623354\n",
      "current reward: 29.654523360623354; current state: [24.22222222222222, 2.6476904009183593]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 13)\n",
      "act action : 19\n",
      "reward: 27.48512004244701\n",
      "current reward: 27.48512004244701; current state: [28.703703703703702, 0.049772468714448244]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 3)\n",
      "act action : 19\n",
      "reward: 27.80310246884731\n",
      "current reward: 27.80310246884731; current state: [31.22222222222222, 1.4876307048269686]\n",
      "maximizing action\n",
      "[5.9432068 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (127, 7)\n",
      "act action : 19\n",
      "reward: 28.0468551473171\n",
      "current reward: 28.0468551473171; current state: [26.185185185185187, 5.9571850615048225]\n",
      "maximizing action\n",
      "[40.98461169  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 29.60837405638432\n",
      "current reward: 29.60837405638432; current state: [26.666666666666668, 5.119385888405147]\n",
      "maximizing action\n",
      "[28.97490188  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 27.85281275392475\n",
      "current reward: 27.85281275392475; current state: [30.333333333333332, 0.04835039817974972]\n",
      "maximizing action\n",
      "[11.49789316  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (123, 3)\n",
      "act action : 19\n",
      "reward: 27.643563216444196\n",
      "current reward: 27.643563216444196; current state: [29.962962962962962, 6.443886622604338]\n",
      "maximizing action\n",
      "[39.34444968  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 27.789339964257625\n",
      "current reward: 27.789339964257625; current state: [26.666666666666668, 5.8621704483129955]\n",
      "maximizing action\n",
      "[58.00168649  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.552364991021175\n",
      "current reward: 29.552364991021175; current state: [25.11111111111111, 2.0768400959383557]\n",
      "maximizing action\n",
      "[11.22956613  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 11)\n",
      "act action : 19\n",
      "reward: 27.760119182303026\n",
      "current reward: 27.760119182303026; current state: [23.51851851851852, 4.669814664270693]\n",
      "maximizing action\n",
      "[5.9297245 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (97, 21)\n",
      "act action : 19\n",
      "reward: 27.659006430224775\n",
      "current reward: 27.659006430224775; current state: [20.51851851851852, 5.888147265431103]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 25)\n",
      "act action : 19\n",
      "reward: 27.68570354005436\n",
      "current reward: 27.68570354005436; current state: [27.074074074074073, 0.046928327645051185]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 3)\n",
      "act action : 19\n",
      "reward: 27.5453519507561\n",
      "current reward: 27.5453519507561; current state: [27.40740740740741, 8.134459689247963]\n",
      "maximizing action\n",
      "[16.9921755  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 29.07030780493857\n",
      "current reward: 29.07030780493857; current state: [30.62962962962963, 0.5224678442400954]\n",
      "maximizing action\n",
      "[5.57700066 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 5)\n",
      "act action : 19\n",
      "reward: 27.36374766693895\n",
      "current reward: 27.36374766693895; current state: [27.074074074074073, 4.109590788287741]\n",
      "maximizing action\n",
      "[22.35132242  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 25.57832175346778\n",
      "current reward: 25.57832175346778; current state: [19.37037037037037, 11.004285462245154]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (79, 47)\n",
      "act action : 19\n",
      "reward: 27.14815687703062\n",
      "current reward: 27.14815687703062; current state: [23.51851851851852, 1.2692313404422708]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 7)\n",
      "act action : 19\n",
      "reward: 27.42564217231637\n",
      "current reward: 27.42564217231637; current state: [28.25925925925926, 2.57761940622485]\n",
      "maximizing action\n",
      "[22.74131324  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 26.843614955756795\n",
      "current reward: 26.843614955756795; current state: [26.666666666666668, 7.37782452913674]\n",
      "maximizing action\n",
      "[17.6273105  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 27.193705179588715\n",
      "current reward: 27.193705179588715; current state: [25.444444444444443, 4.566056909537232]\n",
      "maximizing action\n",
      "[23.26910648  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 29.130346551182296\n",
      "current reward: 29.130346551182296; current state: [24.703703703703702, 6.461438193739365]\n",
      "maximizing action\n",
      "[16.90893776  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 27)\n",
      "act action : 19\n",
      "reward: 27.750740098058383\n",
      "current reward: 27.750740098058383; current state: [23.0, 8.51191631501229]\n",
      "maximizing action\n",
      "[5.44310424 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 37)\n",
      "act action : 19\n",
      "reward: 29.537430677727787\n",
      "current reward: 29.537430677727787; current state: [27.074074074074073, 2.1096667559104794]\n",
      "maximizing action\n",
      "[22.35587818  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 28.475554638485605\n",
      "current reward: 28.475554638485605; current state: [31.555555555555557, 3.2488604231740674]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 15)\n",
      "act action : 19\n",
      "reward: 27.937173286526217\n",
      "current reward: 27.937173286526217; current state: [25.444444444444443, 9.26662067188232]\n",
      "maximizing action\n",
      "[22.44437023  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 39)\n",
      "act action : 19\n",
      "reward: 27.704240936571555\n",
      "current reward: 27.704240936571555; current state: [29.962962962962962, 3.80536461265782]\n",
      "maximizing action\n",
      "[51.92369264  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 27.60230625455419\n",
      "current reward: 27.60230625455419; current state: [26.666666666666668, 8.029031143428032]\n",
      "maximizing action\n",
      "[11.2496579  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 35)\n",
      "act action : 19\n",
      "reward: 27.87659537503224\n",
      "current reward: 27.87659537503224; current state: [23.0, 7.948327049612328]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 33)\n",
      "act action : 19\n",
      "reward: 27.93510871426562\n",
      "current reward: 27.93510871426562; current state: [27.444444444444443, 3.8806386884711523]\n",
      "maximizing action\n",
      "[45.32971048  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 28.36680269581707\n",
      "current reward: 28.36680269581707; current state: [26.185185185185187, 9.275342067377121]\n",
      "maximizing action\n",
      "[11.77185443  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 39)\n",
      "act action : 19\n",
      "reward: 28.060776578941518\n",
      "current reward: 28.060776578941518; current state: [28.703703703703702, 3.6859224781577913]\n",
      "maximizing action\n",
      "[27.52088859  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 27.92699546999314\n",
      "current reward: 27.92699546999314; current state: [31.22222222222222, 4.612706284700285]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 21)\n",
      "act action : 19\n",
      "reward: 28.479987530596247\n",
      "current reward: 28.479987530596247; current state: [27.444444444444443, 3.7214584867248885]\n",
      "maximizing action\n",
      "[51.00307102  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 28.199661464673508\n",
      "current reward: 28.199661464673508; current state: [23.666666666666668, 9.959561303830014]\n",
      "maximizing action\n",
      "[17.34579785  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 28.62028540831569\n",
      "current reward: 28.62028540831569; current state: [26.185185185185187, 1.8273973750167811]\n",
      "maximizing action\n",
      "[5.36705296 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 9)\n",
      "act action : 19\n",
      "reward: 29.022025528140727\n",
      "current reward: 29.022025528140727; current state: [27.444444444444443, 8.024871426171929]\n",
      "maximizing action\n",
      "[22.80623706  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 28.192940892911242\n",
      "current reward: 28.192940892911242; current state: [29.962962962962962, 6.350487449118613]\n",
      "maximizing action\n",
      "[44.90231767  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 27.510599693450207\n",
      "current reward: 27.510599693450207; current state: [29.51851851851852, 5.5628301823758255]\n",
      "maximizing action\n",
      "[16.99136419  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 28.65575405618039\n",
      "current reward: 28.65575405618039; current state: [28.703703703703702, 6.484343886119361]\n",
      "maximizing action\n",
      "[6.01167392 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 27)\n",
      "act action : 19\n",
      "reward: 27.72994273209335\n",
      "current reward: 27.72994273209335; current state: [26.666666666666668, 9.433830695456878]\n",
      "maximizing action\n",
      "[10.8796222  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 29.37563216311629\n",
      "current reward: 29.37563216311629; current state: [28.703703703703702, 7.328433404652752]\n",
      "maximizing action\n",
      "[5.87675031 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 31)\n",
      "act action : 19\n",
      "reward: 28.017643702723692\n",
      "current reward: 28.017643702723692; current state: [27.88888888888889, 7.164727059210484]\n",
      "maximizing action\n",
      "[28.05320714  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 28.03740847791661\n",
      "current reward: 28.03740847791661; current state: [29.11111111111111, 3.6127483093530746]\n",
      "maximizing action\n",
      "[45.29099276  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.431794349433346\n",
      "current reward: 28.431794349433346; current state: [29.11111111111111, 5.713274006926739]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 25)\n",
      "act action : 19\n",
      "reward: 28.68768634705256\n",
      "current reward: 28.68768634705256; current state: [27.88888888888889, 4.885978282228956]\n",
      "maximizing action\n",
      "[16.76987539  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 28.175319834599335\n",
      "current reward: 28.175319834599335; current state: [25.444444444444443, 9.020863566149295]\n",
      "maximizing action\n",
      "[27.98521842  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 39)\n",
      "act action : 19\n",
      "reward: 29.843691430405254\n",
      "current reward: 29.843691430405254; current state: [27.88888888888889, 6.038902430739859]\n",
      "maximizing action\n",
      "[28.10261973  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 27.95894953400015\n",
      "current reward: 27.95894953400015; current state: [28.703703703703702, 6.528726889234872]\n",
      "maximizing action\n",
      "[17.79149049  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 29.65808768251202\n",
      "current reward: 29.65808768251202; current state: [29.962962962962962, 3.9907181616794296]\n",
      "maximizing action\n",
      "[57.44415389  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.9649889633808\n",
      "current reward: 29.9649889633808; current state: [26.185185185185187, 5.290451803790012]\n",
      "maximizing action\n",
      "[16.90768607  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 28.163460912064902\n",
      "current reward: 28.163460912064902; current state: [26.185185185185187, 8.681158870106254]\n",
      "maximizing action\n",
      "[5.80410647 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 37)\n",
      "act action : 19\n",
      "reward: 28.325743639649147\n",
      "current reward: 28.325743639649147; current state: [27.444444444444443, 7.072172347288602]\n",
      "maximizing action\n",
      "[5.94040291 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 27.80582516875067\n",
      "current reward: 27.80582516875067; current state: [27.444444444444443, 6.570593950397978]\n",
      "maximizing action\n",
      "[33.98512097  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 28.39932778744314\n",
      "current reward: 28.39932778744314; current state: [27.444444444444443, 2.0075240217313675]\n",
      "maximizing action\n",
      "[28.05098911  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 27.85136479711753\n",
      "current reward: 27.85136479711753; current state: [26.25925925925926, 5.662197466693725]\n",
      "maximizing action\n",
      "[46.9062865  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 28.103143381717633\n",
      "current reward: 28.103143381717633; current state: [23.962962962962962, 6.823435360523903]\n",
      "maximizing action\n",
      "[11.69762807  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 29)\n",
      "act action : 19\n",
      "reward: 28.452640157082765\n",
      "current reward: 28.452640157082765; current state: [28.25925925925926, 2.8578633860844995]\n",
      "maximizing action\n",
      "[28.11003623  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 28.48129779730608\n",
      "current reward: 28.48129779730608; current state: [25.444444444444443, 5.795846664903194]\n",
      "maximizing action\n",
      "[16.62289941  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 25)\n",
      "act action : 19\n",
      "reward: 27.768548986006063\n",
      "current reward: 27.768548986006063; current state: [25.444444444444443, 4.108189328147087]\n",
      "maximizing action\n",
      "[16.82604062  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 27.856805811936795\n",
      "current reward: 27.856805811936795; current state: [28.703703703703702, 7.243312992955246]\n",
      "maximizing action\n",
      "[11.48027905  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 31)\n",
      "act action : 19\n",
      "reward: 27.451244110540657\n",
      "current reward: 27.451244110540657; current state: [27.444444444444443, 2.154506332792905]\n",
      "maximizing action\n",
      "[33.62126207  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 27.010876036692355\n",
      "current reward: 27.010876036692355; current state: [27.444444444444443, 7.129335952769431]\n",
      "maximizing action\n",
      "[11.50156794  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 28.99776452821907\n",
      "current reward: 28.99776452821907; current state: [26.185185185185187, 4.7410662183360515]\n",
      "maximizing action\n",
      "[5.54508042 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 29.043907476390842\n",
      "current reward: 29.043907476390842; current state: [23.0, 7.132577740286128]\n",
      "maximizing action\n",
      "[17.26156386  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (95, 31)\n",
      "act action : 19\n",
      "reward: 26.783726927873875\n",
      "current reward: 26.783726927873875; current state: [29.11111111111111, 4.9312920853737765]\n",
      "maximizing action\n",
      "[34.17951524  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 21)\n",
      "act action : 19\n",
      "reward: 30.65708835470571\n",
      "current reward: 30.65708835470571; current state: [26.666666666666668, 7.055759761018858]\n",
      "maximizing action\n",
      "[23.06605154  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 27.066979810716834\n",
      "current reward: 27.066979810716834; current state: [29.962962962962962, 0.049772468714448244]\n",
      "maximizing action\n",
      "[5.82449243 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 3)\n",
      "act action : 19\n",
      "reward: 27.265653620330408\n",
      "current reward: 27.265653620330408; current state: [28.703703703703702, 10.170218270481348]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 43)\n",
      "act action : 19\n",
      "reward: 28.4680857441611\n",
      "current reward: 28.4680857441611; current state: [29.962962962962962, 4.996348435726934]\n",
      "maximizing action\n",
      "[17.14664246  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 28.961876053432437\n",
      "current reward: 28.961876053432437; current state: [29.51851851851852, 4.3265690701351405]\n",
      "maximizing action\n",
      "[57.81458587  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 27.55083678427036\n",
      "current reward: 27.55083678427036; current state: [33.407407407407405, 1.9759167671992535]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 9)\n",
      "act action : 19\n",
      "reward: 27.062563016998325\n",
      "current reward: 27.062563016998325; current state: [27.666666666666668, 9.786118919448617]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 41)\n",
      "act action : 19\n",
      "reward: 28.492330547468374\n",
      "current reward: 28.492330547468374; current state: [29.0, 7.878720772905979]\n",
      "maximizing action\n",
      "[16.82565453  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 33)\n",
      "act action : 19\n",
      "reward: 27.663869214790466\n",
      "current reward: 27.663869214790466; current state: [27.666666666666668, 6.170090199416734]\n",
      "maximizing action\n",
      "[33.69440964  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 27.300770844475448\n",
      "current reward: 27.300770844475448; current state: [24.296296296296298, 10.56587388594349]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 45)\n",
      "act action : 19\n",
      "reward: 30.191305632344925\n",
      "current reward: 30.191305632344925; current state: [23.666666666666668, 9.038154610115011]\n",
      "maximizing action\n",
      "[5.57581825 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 39)\n",
      "act action : 19\n",
      "reward: 27.862096296162054\n",
      "current reward: 27.862096296162054; current state: [26.333333333333332, 7.491325585410956]\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "action_space= np.array([19, 22, 25, 28, 31, 33])\n",
    "try:\n",
    "    for i in range(1):#episodes\n",
    "        print(f\"episode: {i}\")\n",
    "        initial_states = env.reset()\n",
    "        #print(env.observation_space)\n",
    "        action_space_size = len(env.action_space)\n",
    "        state_grid= create_uniform_grid(env.observation_space.low, env.observation_space.high, bins= (400,400))\n",
    "        ql_agents = QLAgent.QLAgent(starting_state=initial_states,\n",
    "                                    state_space=env.observation_space,\n",
    "                                    state_grid = state_grid,\n",
    "                                    action_space=env.action_space,\n",
    "                                    alpha=0.2,\n",
    "                                    gamma=0.99,\n",
    "                                    exploration_strategy=EpsilonGreedy.EpsilonGreedy())\n",
    "        #print(f\"action_space_size{action_space_size}\")\n",
    "        for t in range(1000):#time steps\n",
    "            actions =ql_agents.act()\n",
    "            print(f\"act action : {actions}\")\n",
    "            s, r, done, _ = env.step(action=actions)\n",
    "            print(f\"current reward: {r}; current state: {s}\")\n",
    "            ql_agents.learn(next_state=s, reward=r)\n",
    "            if done:\n",
    "                break\n",
    "        env.close()\n",
    "except ValueError:\n",
    "    print(traceback.format_exc())\n",
    "    env.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88117a4c4f7db09762e85aecb2e581e7c8f40331f8439cb18f9752f946649d6e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
