{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <h1>\n",
    "        VSL RL : SUMO Simulation\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmae/opt/anaconda3/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('C:\\PHD\\Workspace\\gym_sumo_vsl_maroc\\gym_sumo\\envs')\n",
    "from utils import plot_policy, plot_action_values, test_agent\n",
    "import SUMOInitializeEnv\n",
    "import gym\n",
    "import sumo_env as env\n",
    "import ql_agent as QLAgent\n",
    "import epsilon_greedy as EpsilonGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from gym.envs.registration import register\n",
    "from SUMOInitializeEnv import SUMOEnv_Initializer\n",
    "register(\n",
    "    id='SumoGUI-v0',\n",
    "    entry_point='SUMOInitializeEnv:SUMOEnv_Initializer'\n",
    ")\n",
    "env = gym.make('SumoGUI-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_grid(low,high, bins=(500,500)):\n",
    "        grid= []\n",
    "        for i, lower_upper in enumerate(zip(low,high)):\n",
    "            grid_column= np.linspace(lower_upper[0], lower_upper[1], bins[i]+1)\n",
    "            grid.append(grid_column)\n",
    "        return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 1.4768161273095757\n",
      "current reward: 1.4768161273095757; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 2.722562823508633\n",
      "current reward: 2.722562823508633; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 3.964789875836908\n",
      "current reward: 3.964789875836908; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 4.546895874150576\n",
      "current reward: 4.546895874150576; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 5.03974258053987\n",
      "current reward: 5.03974258053987; current state: [3.0, 0.004266211604095562]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 5.903140686850697\n",
      "current reward: 5.903140686850697; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 6.944795291384385\n",
      "current reward: 6.944795291384385; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 6.366294713859337\n",
      "current reward: 6.366294713859337; current state: [4.0, 0.005688282138794083]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 7.253754909393326\n",
      "current reward: 7.253754909393326; current state: [4.0, 0.005688282138794083]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 7.029425311635005\n",
      "current reward: 7.029425311635005; current state: [5.0, 0.007110352673492605]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 9.448040535393512\n",
      "current reward: 9.448040535393512; current state: [6.0, 0.008532423208191125]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 10.635281425659576\n",
      "current reward: 10.635281425659576; current state: [6.0, 0.008532423208191125]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 11.194149908145688\n",
      "current reward: 11.194149908145688; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 12.116535006225709\n",
      "current reward: 12.116535006225709; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 12.689547913067509\n",
      "current reward: 12.689547913067509; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 13.627097287202607\n",
      "current reward: 13.627097287202607; current state: [7.7407407407407405, 1.954535269056401]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 14.378857084191816\n",
      "current reward: 14.378857084191816; current state: [8.0, 0.011376564277588165]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 14.962586673870375\n",
      "current reward: 14.962586673870375; current state: [9.0, 0.012798634812286692]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 15.45736816593142\n",
      "current reward: 15.45736816593142; current state: [9.0, 0.012798634812286692]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 16.031356792556227\n",
      "current reward: 16.031356792556227; current state: [8.703703703703704, 0.36359120741490103]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 15.147686379367665\n",
      "current reward: 15.147686379367665; current state: [9.666666666666666, 0.01422070534698521]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 15.877036100710006\n",
      "current reward: 15.877036100710006; current state: [10.0, 0.01422070534698521]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 15.903083670462172\n",
      "current reward: 15.903083670462172; current state: [10.25925925925926, 3.901103506734207]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 16.897209424871384\n",
      "current reward: 16.897209424871384; current state: [10.25925925925926, 4.311919434394989]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 18.106284399614278\n",
      "current reward: 18.106284399614278; current state: [12.0, 0.01706484641638225]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 18.9272817127211\n",
      "current reward: 18.9272817127211; current state: [11.592592592592593, 0.20715586294982144]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 19.823179363944405\n",
      "current reward: 19.823179363944405; current state: [11.592592592592593, 0.01706484641638225]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 19.375487872153364\n",
      "current reward: 19.375487872153364; current state: [12.555555555555555, 2.3336707069063314]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 20.362323312247195\n",
      "current reward: 20.362323312247195; current state: [13.0, 0.018486916951080776]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 20.972410561784237\n",
      "current reward: 20.972410561784237; current state: [14.0, 0.019908987485779295]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 21.74328424881467\n",
      "current reward: 21.74328424881467; current state: [13.518518518518519, 2.222329578188728]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 22.627263860006455\n",
      "current reward: 22.627263860006455; current state: [13.037037037037036, 0.7042092452590604]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 23.371488281065897\n",
      "current reward: 23.371488281065897; current state: [12.925925925925926, 3.633288001338996]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.259225455041285\n",
      "current reward: 24.259225455041285; current state: [14.481481481481481, 0.021331058020477817]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.072762967801747\n",
      "current reward: 24.072762967801747; current state: [13.222222222222221, 4.51210607249987]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.508472470787822\n",
      "current reward: 24.508472470787822; current state: [12.666666666666666, 2.244916154639757]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 24.002270702027243\n",
      "current reward: 24.002270702027243; current state: [16.40740740740741, 1.6143177070975132]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.505161499330907\n",
      "current reward: 24.505161499330907; current state: [15.814814814814815, 0.5706088978086251]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.73532883424887\n",
      "current reward: 24.73532883424887; current state: [16.40740740740741, 0.02417519908987486]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.263976125526497\n",
      "current reward: 24.263976125526497; current state: [17.37037037037037, 0.9997481136257428]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 24.655953179771995\n",
      "current reward: 24.655953179771995; current state: [17.37037037037037, 0.025597269624573385]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.04449980101747\n",
      "current reward: 25.04449980101747; current state: [18.333333333333332, 2.0298632706513824]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.570242385152614\n",
      "current reward: 25.570242385152614; current state: [19.0, 0.0270193401592719]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.267209986650396\n",
      "current reward: 28.267209986650396; current state: [16.333333333333332, 6.934513260343959]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.264974307080802\n",
      "current reward: 26.264974307080802; current state: [17.88888888888889, 3.1516414387342677]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.61654403463898\n",
      "current reward: 26.61654403463898; current state: [18.59259259259259, 0.916222109783951]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.31580125342582\n",
      "current reward: 28.31580125342582; current state: [18.77777777777778, 2.323914047145187]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.396006209747963\n",
      "current reward: 26.396006209747963; current state: [16.555555555555557, 8.916935258064054]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.893359316856557\n",
      "current reward: 27.893359316856557; current state: [22.0, 0.03128555176336746]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.123910610334104\n",
      "current reward: 28.123910610334104; current state: [21.22222222222222, 1.8097390941165754]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.21737789081308\n",
      "current reward: 26.21737789081308; current state: [18.88888888888889, 7.427174711246442]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.737870969204423\n",
      "current reward: 25.737870969204423; current state: [22.185185185185187, 0.4646666568790648]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.20006565091248\n",
      "current reward: 30.20006565091248; current state: [20.555555555555557, 4.1122132111930245]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.60856063695567\n",
      "current reward: 26.60856063695567; current state: [20.555555555555557, 4.353727762499391]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.9037114845886\n",
      "current reward: 27.9037114845886; current state: [21.444444444444443, 0.0341296928327645]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.456828877186968\n",
      "current reward: 26.456828877186968; current state: [23.14814814814815, 2.0670158714916367]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.71266346354305\n",
      "current reward: 28.71266346354305; current state: [22.333333333333332, 2.589896391939981]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.29119476068091\n",
      "current reward: 26.29119476068091; current state: [23.22222222222222, 2.2110095795423526]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.768716539903547\n",
      "current reward: 25.768716539903547; current state: [22.296296296296298, 5.240542347272084]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.355516582466226\n",
      "current reward: 28.355516582466226; current state: [22.296296296296298, 2.3441244699606436]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.532090147850948\n",
      "current reward: 25.532090147850948; current state: [24.11111111111111, 7.1039536902711005]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.867227664192722\n",
      "current reward: 25.867227664192722; current state: [24.11111111111111, 1.456334552414175]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.225647400493514\n",
      "current reward: 26.225647400493514; current state: [21.22222222222222, 4.139024617293784]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.768493555497006\n",
      "current reward: 25.768493555497006; current state: [25.0, 2.1922972670526315]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.035088289413597\n",
      "current reward: 26.035088289413597; current state: [25.0, 1.7048857217943743]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.948564360486753\n",
      "current reward: 26.948564360486753; current state: [24.85185185185185, 2.2156479311989377]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.839516970553092\n",
      "current reward: 25.839516970553092; current state: [29.0, 0.041240045506257116]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.388581366002544\n",
      "current reward: 28.388581366002544; current state: [25.88888888888889, 2.491568073325307]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.39277148185752\n",
      "current reward: 27.39277148185752; current state: [25.703703703703702, 3.682003864318568]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 25.905800053053657\n",
      "current reward: 25.905800053053657; current state: [26.77777777777778, 4.087528311158378]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.242349055086237\n",
      "current reward: 28.242349055086237; current state: [28.77777777777778, 3.6208691908409607]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.24261533598352\n",
      "current reward: 26.24261533598352; current state: [26.555555555555557, 5.555717189666211]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.1286162788453\n",
      "current reward: 26.1286162788453; current state: [29.703703703703702, 1.9699874617948165]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.644239905218523\n",
      "current reward: 27.644239905218523; current state: [27.40740740740741, 6.621254757932906]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.76087889402221\n",
      "current reward: 26.76087889402221; current state: [26.25925925925926, 4.375942800940708]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.64764191646842\n",
      "current reward: 26.64764191646842; current state: [28.25925925925926, 4.255103555588269]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.999660838594313\n",
      "current reward: 27.999660838594313; current state: [31.814814814814813, 0.6167527719526573]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.658948229500684\n",
      "current reward: 26.658948229500684; current state: [30.333333333333332, 2.9550576322473807]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.93472352917364\n",
      "current reward: 27.93472352917364; current state: [31.555555555555557, 1.8279174595981955]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.33427662234908\n",
      "current reward: 27.33427662234908; current state: [29.11111111111111, 4.3913354259653055]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.691849098652852\n",
      "current reward: 28.691849098652852; current state: [28.703703703703702, 7.061630801503343]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 29.6685356678931\n",
      "current reward: 29.6685356678931; current state: [31.22222222222222, 0.049772468714448244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.504600948055238\n",
      "current reward: 27.504600948055238; current state: [33.407407407407405, 2.4453753077760747]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.884255445062916\n",
      "current reward: 27.884255445062916; current state: [32.111111111111114, 4.299084340059242]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.498406528182226\n",
      "current reward: 27.498406528182226; current state: [33.407407407407405, 2.0814175969014923]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.459863870367446\n",
      "current reward: 29.459863870367446; current state: [30.814814814814813, 5.156501438018453]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.160044368985407\n",
      "current reward: 28.160044368985407; current state: [28.22222222222222, 6.710960293192579]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.972252380347914\n",
      "current reward: 27.972252380347914; current state: [34.333333333333336, 3.037995026092961]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.153612268006118\n",
      "current reward: 28.153612268006118; current state: [33.407407407407405, 1.1105609193387578]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.95528051676462\n",
      "current reward: 27.95528051676462; current state: [25.0, 14.036466334350402]\n",
      "exploring action\n",
      "Current action = 25, current state (3, 3)\n",
      "act action : 25\n",
      "reward: 27.886964366184525\n",
      "current reward: 27.886964366184525; current state: [24.925925925925927, 4.30520127571814]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.329430922109267\n",
      "current reward: 29.329430922109267; current state: [31.22222222222222, 1.0052448945716976]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.880874511358318\n",
      "current reward: 27.880874511358318; current state: [29.51851851851852, 6.511299109325966]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.96602949570418\n",
      "current reward: 27.96602949570418; current state: [30.814814814814813, 2.221527336279578]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.34892886396103\n",
      "current reward: 29.34892886396103; current state: [31.22222222222222, 2.7514611322370124]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.0918920736303\n",
      "current reward: 28.0918920736303; current state: [24.925925925925927, 11.137135667376105]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.99705000268112\n",
      "current reward: 27.99705000268112; current state: [30.814814814814813, 2.5748213959903286]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 27.870505971098268\n",
      "current reward: 27.870505971098268; current state: [29.11111111111111, 4.826796303300394]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.992670578809737\n",
      "current reward: 27.992670578809737; current state: [27.88888888888889, 6.846148800986127]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.451500711313205\n",
      "current reward: 29.451500711313205; current state: [33.74074074074074, 0.049772468714448244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.03352988963323\n",
      "current reward: 28.03352988963323; current state: [29.11111111111111, 5.1684777822905446]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.95365047552086\n",
      "current reward: 27.95365047552086; current state: [24.925925925925927, 7.761871523290192]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.744589969747096\n",
      "current reward: 29.744589969747096; current state: [28.703703703703702, 3.783546843236118]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.720965697986838\n",
      "current reward: 29.720965697986838; current state: [31.22222222222222, 2.371790164564077]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.870537663591744\n",
      "current reward: 27.870537663591744; current state: [27.444444444444443, 6.4729955435907085]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.014015598717105\n",
      "current reward: 31.014015598717105; current state: [28.703703703703702, 2.511182091262199]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.75610677944202\n",
      "current reward: 27.75610677944202; current state: [25.62962962962963, 8.138195855865964]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.068013344737494\n",
      "current reward: 28.068013344737494; current state: [30.814814814814813, 1.7596524914457943]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.73334273531526\n",
      "current reward: 27.73334273531526; current state: [25.62962962962963, 8.124468984466201]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.118458765390333\n",
      "current reward: 28.118458765390333; current state: [28.22222222222222, 2.792786916810847]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.42060333427192\n",
      "current reward: 28.42060333427192; current state: [28.703703703703702, 5.308069164483504]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.63105754574413\n",
      "current reward: 27.63105754574413; current state: [24.22222222222222, 5.516285949605615]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.057181182416567\n",
      "current reward: 28.057181182416567; current state: [23.0, 3.2458780344475704]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.742140577175917\n",
      "current reward: 27.742140577175917; current state: [27.444444444444443, 3.3005804191561396]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.874679745512115\n",
      "current reward: 27.874679745512115; current state: [28.703703703703702, 5.724201962436537]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.097358478496687\n",
      "current reward: 28.097358478496687; current state: [28.703703703703702, 2.0667553221781763]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.70534717421002\n",
      "current reward: 27.70534717421002; current state: [32.111111111111114, 5.574922317032516]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.809017257131632\n",
      "current reward: 27.809017257131632; current state: [29.51851851851852, 6.0817416694834785]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.817804128964564\n",
      "current reward: 27.817804128964564; current state: [31.22222222222222, 4.535623871067555]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.808079961318025\n",
      "current reward: 27.808079961318025; current state: [25.62962962962963, 12.141096443859958]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.20456327671735\n",
      "current reward: 27.20456327671735; current state: [29.51851851851852, 2.1704942121064046]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.353784302380944\n",
      "current reward: 27.353784302380944; current state: [32.111111111111114, 4.984561711488099]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.3264364919313\n",
      "current reward: 28.3264364919313; current state: [23.666666666666668, 11.900854299270842]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.242915816492673\n",
      "current reward: 27.242915816492673; current state: [27.88888888888889, 2.4794659958877725]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.037307591612755\n",
      "current reward: 27.037307591612755; current state: [27.88888888888889, 5.313476738185124]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.71665286416169\n",
      "current reward: 27.71665286416169; current state: [30.333333333333332, 4.001211198127835]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.797627154436924\n",
      "current reward: 28.797627154436924; current state: [27.88888888888889, 7.207482894875988]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.200797558157813\n",
      "current reward: 28.200797558157813; current state: [25.444444444444443, 8.596225532893055]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.938019845833495\n",
      "current reward: 27.938019845833495; current state: [26.666666666666668, 3.6263656380536107]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.3727452930748\n",
      "current reward: 28.3727452930748; current state: [24.22222222222222, 4.885159104383162]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.480033013807827\n",
      "current reward: 26.480033013807827; current state: [27.444444444444443, 4.6753605518271435]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.67798816592041\n",
      "current reward: 27.67798816592041; current state: [27.444444444444443, 3.6455392323338174]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.589005192703983\n",
      "current reward: 26.589005192703983; current state: [25.62962962962963, 1.4534860192397931]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.327555991016464\n",
      "current reward: 28.327555991016464; current state: [27.444444444444443, 6.020194652701651]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.99052406253593\n",
      "current reward: 26.99052406253593; current state: [24.925925925925927, 11.799425578217972]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.10041785560802\n",
      "current reward: 28.10041785560802; current state: [29.962962962962962, 3.560463876982802]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.88516651847409\n",
      "current reward: 26.88516651847409; current state: [29.962962962962962, 3.249041776527641]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.3430863846511\n",
      "current reward: 26.3430863846511; current state: [25.62962962962963, 9.581054965143288]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.553812711395015\n",
      "current reward: 26.553812711395015; current state: [28.22222222222222, 6.279462533836555]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.647430959808194\n",
      "current reward: 27.647430959808194; current state: [30.814814814814813, 3.4240206418170747]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.426189629092107\n",
      "current reward: 26.426189629092107; current state: [25.62962962962963, 9.083646326663823]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.72870588380761\n",
      "current reward: 26.72870588380761; current state: [28.22222222222222, 9.030802294274842]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.334020360400444\n",
      "current reward: 26.334020360400444; current state: [31.666666666666668, 2.6561822208354475]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.410527984444425\n",
      "current reward: 26.410527984444425; current state: [25.62962962962963, 10.406746241524207]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.147515322711552\n",
      "current reward: 26.147515322711552; current state: [24.333333333333332, 10.80316491475999]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.464733996220772\n",
      "current reward: 26.464733996220772; current state: [24.333333333333332, 7.912424757549238]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.517366153703506\n",
      "current reward: 28.517366153703506; current state: [23.0, 4.271044949703217]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.53455461336056\n",
      "current reward: 28.53455461336056; current state: [28.703703703703702, 4.481063765137738]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.621113971591658\n",
      "current reward: 26.621113971591658; current state: [31.22222222222222, 4.168509528678648]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.89410771486845\n",
      "current reward: 28.89410771486845; current state: [32.111111111111114, 3.1287023060372117]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.05696347191825\n",
      "current reward: 27.05696347191825; current state: [29.51851851851852, 3.7189404843153984]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.121142052904943\n",
      "current reward: 27.121142052904943; current state: [26.925925925925927, 4.285952698639884]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.782747565149368\n",
      "current reward: 26.782747565149368; current state: [30.333333333333332, 2.1109413038955203]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.490890799631682\n",
      "current reward: 28.490890799631682; current state: [30.333333333333332, 6.454598563636468]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.580046454104536\n",
      "current reward: 26.580046454104536; current state: [32.51851851851852, 5.979312540801357]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.789190688479277\n",
      "current reward: 26.789190688479277; current state: [31.14814814814815, 8.337351235412505]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.625160612507603\n",
      "current reward: 26.625160612507603; current state: [26.333333333333332, 11.915816647801838]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.744714352740335\n",
      "current reward: 28.744714352740335; current state: [24.925925925925927, 6.197321596114877]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.024738564285855\n",
      "current reward: 27.024738564285855; current state: [29.14814814814815, 6.63100877338238]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.068205563646575\n",
      "current reward: 28.068205563646575; current state: [31.333333333333332, 4.625876883942933]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.11830299570477\n",
      "current reward: 27.11830299570477; current state: [30.333333333333332, 6.9207273641585365]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.703190825323233\n",
      "current reward: 26.703190825323233; current state: [31.14814814814815, 3.734392639717896]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.611241431465924\n",
      "current reward: 28.611241431465924; current state: [28.40740740740741, 7.263620536526571]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.057346616510262\n",
      "current reward: 27.057346616510262; current state: [27.037037037037038, 6.065471581069169]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.92776178188107\n",
      "current reward: 26.92776178188107; current state: [32.51851851851852, 2.193326533665248]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.688186412418077\n",
      "current reward: 27.688186412418077; current state: [30.333333333333332, 1.7949861697819356]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 29.483686500303225\n",
      "current reward: 29.483686500303225; current state: [25.0, 10.733761820032973]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.226822712960484\n",
      "current reward: 27.226822712960484; current state: [26.333333333333332, 8.187883178531965]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.797862245034555\n",
      "current reward: 26.797862245034555; current state: [24.296296296296298, 8.43918775539024]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.086064977637346\n",
      "current reward: 27.086064977637346; current state: [27.666666666666668, 6.280673188755139]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.51644971448565\n",
      "current reward: 27.51644971448565; current state: [30.333333333333332, 4.451044023961395]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.688121390445403\n",
      "current reward: 27.688121390445403; current state: [27.666666666666668, 7.093962678254729]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.995161633392144\n",
      "current reward: 27.995161633392144; current state: [28.22222222222222, 2.553332601936305]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.3514168426187\n",
      "current reward: 27.3514168426187; current state: [34.333333333333336, 1.205124642559036]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.2265779471992\n",
      "current reward: 28.2265779471992; current state: [28.703703703703702, 6.856841935426537]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.519038648184516\n",
      "current reward: 27.519038648184516; current state: [29.11111111111111, 3.3028745112088735]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.550908531854947\n",
      "current reward: 27.550908531854947; current state: [32.48148148148148, 1.1161364311865487]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.037866325486714\n",
      "current reward: 28.037866325486714; current state: [24.703703703703702, 9.835908749689585]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.90981848464531\n",
      "current reward: 27.90981848464531; current state: [27.88888888888889, 3.222117945688073]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.73983711897476\n",
      "current reward: 28.73983711897476; current state: [25.444444444444443, 9.309052886464563]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.793797961850306\n",
      "current reward: 27.793797961850306; current state: [24.22222222222222, 7.365140631245435]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.949502406450524\n",
      "current reward: 27.949502406450524; current state: [24.22222222222222, 7.5818461556381]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.248063543702216\n",
      "current reward: 29.248063543702216; current state: [26.666666666666668, 3.0648451265749115]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.030254383954993\n",
      "current reward: 28.030254383954993; current state: [26.185185185185187, 6.943091537727561]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.151167179285526\n",
      "current reward: 28.151167179285526; current state: [25.444444444444443, 1.784068384955815]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.34351256197893\n",
      "current reward: 30.34351256197893; current state: [27.444444444444443, 4.207568164187901]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.937692353686003\n",
      "current reward: 27.937692353686003; current state: [28.703703703703702, 5.082590852462884]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.995071980333574\n",
      "current reward: 28.995071980333574; current state: [32.77777777777778, 0.04835039817974972]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.791953865931177\n",
      "current reward: 27.791953865931177; current state: [29.962962962962962, 6.6774431285767255]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.770901918406626\n",
      "current reward: 27.770901918406626; current state: [23.0, 3.9813776809098536]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.558144840762168\n",
      "current reward: 28.558144840762168; current state: [24.22222222222222, 2.8110832212562227]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.26511926817463\n",
      "current reward: 27.26511926817463; current state: [26.666666666666668, 8.905264795331766]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 28.436342584346235\n",
      "current reward: 28.436342584346235; current state: [22.40740740740741, 13.55099292892708]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.6634265004521\n",
      "current reward: 28.6634265004521; current state: [28.703703703703702, 2.156962923950644]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.78613662793732\n",
      "current reward: 28.78613662793732; current state: [32.48148148148148, 4.183089570030245]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.79663198061486\n",
      "current reward: 26.79663198061486; current state: [29.962962962962962, 4.886999765807746]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.792186538771315\n",
      "current reward: 28.792186538771315; current state: [27.444444444444443, 8.051232544584657]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.79135076395615\n",
      "current reward: 26.79135076395615; current state: [26.925925925925927, 9.845183887814047]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.927457783453573\n",
      "current reward: 26.927457783453573; current state: [28.703703703703702, 7.259723422666923]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 27.173118881193535\n",
      "current reward: 27.173118881193535; current state: [29.962962962962962, 6.289847212425041]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.233104165169284\n",
      "current reward: 27.233104165169284; current state: [26.925925925925927, 5.796459548098021]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.552489508068252\n",
      "current reward: 27.552489508068252; current state: [28.22222222222222, 2.9728969738272935]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.295865173541767\n",
      "current reward: 27.295865173541767; current state: [27.666666666666668, 9.406072167768876]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.219971874162226\n",
      "current reward: 29.219971874162226; current state: [26.185185185185187, 5.385868131195699]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.94817476400675\n",
      "current reward: 26.94817476400675; current state: [25.62962962962963, 8.624893791784984]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.197704656842088\n",
      "current reward: 27.197704656842088; current state: [30.814814814814813, 6.035159327832831]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.711246211191213\n",
      "current reward: 27.711246211191213; current state: [36.0, 0.05119453924914677]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.052535178843044\n",
      "current reward: 27.052535178843044; current state: [30.814814814814813, 6.8020478216592055]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.453432647983746\n",
      "current reward: 27.453432647983746; current state: [25.62962962962963, 8.484143989256733]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.193581566394723\n",
      "current reward: 27.193581566394723; current state: [31.666666666666668, 1.3095291006791117]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.428221016089168\n",
      "current reward: 27.428221016089168; current state: [29.0, 6.092095137396206]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.651709319616142\n",
      "current reward: 27.651709319616142; current state: [24.333333333333332, 5.6130455625381295]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.42873703477459\n",
      "current reward: 27.42873703477459; current state: [30.814814814814813, 0.39380290383921085]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.69873049578763\n",
      "current reward: 27.69873049578763; current state: [28.22222222222222, 7.523958024684136]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.260189633063334\n",
      "current reward: 29.260189633063334; current state: [26.333333333333332, 7.7451058488060935]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.824530915473925\n",
      "current reward: 27.824530915473925; current state: [26.333333333333332, 6.699631710975106]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.646109043386243\n",
      "current reward: 29.646109043386243; current state: [24.296296296296298, 9.689802103120313]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.566387114604698\n",
      "current reward: 28.566387114604698; current state: [31.14814814814815, 3.2439599362896496]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.788142541236265\n",
      "current reward: 28.788142541236265; current state: [29.0, 5.985862265867002]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.250877365966364\n",
      "current reward: 28.250877365966364; current state: [32.51851851851852, 3.981182824951166]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.119287246673853\n",
      "current reward: 29.119287246673853; current state: [28.40740740740741, 8.99831142318227]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.015487270162996\n",
      "current reward: 28.015487270162996; current state: [24.296296296296298, 6.231435996517094]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.318816083574863\n",
      "current reward: 28.318816083574863; current state: [27.037037037037038, 3.9885542309787207]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.353322509609686\n",
      "current reward: 29.353322509609686; current state: [28.40740740740741, 7.502585385719412]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.79858804962569\n",
      "current reward: 28.79858804962569; current state: [31.14814814814815, 4.533304136949955]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.108449218173785\n",
      "current reward: 29.108449218173785; current state: [28.22222222222222, 4.04414286683317]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.7442397712191\n",
      "current reward: 28.7442397712191; current state: [31.666666666666668, 6.418480580024251]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 28.493559803101437\n",
      "current reward: 28.493559803101437; current state: [29.51851851851852, 5.3696876214927505]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.036769349208743\n",
      "current reward: 28.036769349208743; current state: [26.925925925925927, 9.05752366832779]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.164378490885298\n",
      "current reward: 28.164378490885298; current state: [29.51851851851852, 0.35232720280134516]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.76473691357244\n",
      "current reward: 29.76473691357244; current state: [28.703703703703702, 5.304837943248224]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.378529038982162\n",
      "current reward: 28.378529038982162; current state: [29.51851851851852, 6.513906775786251]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.11299194983356\n",
      "current reward: 29.11299194983356; current state: [28.703703703703702, 4.043195892678162]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.18609770531474\n",
      "current reward: 28.18609770531474; current state: [29.51851851851852, 7.237849997788599]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.288972497619593\n",
      "current reward: 28.288972497619593; current state: [26.185185185185187, 9.471775228915316]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.427085934461164\n",
      "current reward: 28.427085934461164; current state: [24.22222222222222, 8.293435473751414]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.33118951659044\n",
      "current reward: 29.33118951659044; current state: [29.444444444444443, 0.046928327645051185]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.4070185453496\n",
      "current reward: 29.4070185453496; current state: [30.62962962962963, 4.465989693221201]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.698138053628863\n",
      "current reward: 27.698138053628863; current state: [28.25925925925926, 6.026457814803423]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.447600141349103\n",
      "current reward: 29.447600141349103; current state: [22.333333333333332, 11.015260085011152]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.81266151770841\n",
      "current reward: 27.81266151770841; current state: [29.11111111111111, 3.36328236253024]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.40061622287907\n",
      "current reward: 28.40061622287907; current state: [20.555555555555557, 8.064800902865557]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.227095617578232\n",
      "current reward: 28.227095617578232; current state: [23.0, 4.94435662990536]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.25336685831091\n",
      "current reward: 28.25336685831091; current state: [27.444444444444443, 7.30969331726274]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.82016546358854\n",
      "current reward: 28.82016546358854; current state: [30.333333333333332, 1.8365113129769142]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.13758152739521\n",
      "current reward: 28.13758152739521; current state: [27.444444444444443, 11.536672502715454]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.368836798709008\n",
      "current reward: 28.368836798709008; current state: [27.444444444444443, 4.026636610733659]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.258746796782336\n",
      "current reward: 29.258746796782336; current state: [24.925925925925927, 7.040629242874659]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.678423580871108\n",
      "current reward: 28.678423580871108; current state: [32.111111111111114, 2.1401331398448438]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.685960962229803\n",
      "current reward: 28.685960962229803; current state: [31.22222222222222, 3.554045703654856]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.615830059827307\n",
      "current reward: 29.615830059827307; current state: [24.333333333333332, 12.518173565192816]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.838572625574752\n",
      "current reward: 28.838572625574752; current state: [26.925925925925927, 5.262806163588816]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.44715657247285\n",
      "current reward: 28.44715657247285; current state: [24.333333333333332, 7.474904340480456]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.251662391133937\n",
      "current reward: 29.251662391133937; current state: [23.037037037037038, 8.387313055595898]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.931767094843888\n",
      "current reward: 28.931767094843888; current state: [28.703703703703702, 1.8609798416912242]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.439211206884867\n",
      "current reward: 28.439211206884867; current state: [32.48148148148148, 3.811707400323539]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.70341514362667\n",
      "current reward: 28.70341514362667; current state: [29.962962962962962, 3.544863822238681]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.99856241345458\n",
      "current reward: 29.99856241345458; current state: [27.444444444444443, 7.715010335674549]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.94832706108139\n",
      "current reward: 28.94832706108139; current state: [26.185185185185187, 10.347414465282666]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.06949579071228\n",
      "current reward: 29.06949579071228; current state: [27.88888888888889, 3.3750367341404406]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.070013056505033\n",
      "current reward: 30.070013056505033; current state: [28.703703703703702, 5.241119106289638]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.04925108542111\n",
      "current reward: 30.04925108542111; current state: [31.22222222222222, 1.0901507267006216]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.56070228527227\n",
      "current reward: 28.56070228527227; current state: [28.22222222222222, 6.226974150700863]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.929486574056465\n",
      "current reward: 29.929486574056465; current state: [25.62962962962963, 8.932064391292172]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.794995609195993\n",
      "current reward: 29.794995609195993; current state: [25.62962962962963, 7.898364902699939]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.22617499695841\n",
      "current reward: 28.22617499695841; current state: [28.22222222222222, 2.9346499998782574]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.256837642701893\n",
      "current reward: 28.256837642701893; current state: [29.962962962962962, 2.8051400360900294]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.031744716529136\n",
      "current reward: 29.031744716529136; current state: [30.814814814814813, 4.141287107478381]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.014347167934805\n",
      "current reward: 28.014347167934805; current state: [29.51851851851852, 8.096272731069206]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.388063861539123\n",
      "current reward: 27.388063861539123; current state: [28.703703703703702, 4.290332222705651]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.46321140934876\n",
      "current reward: 27.46321140934876; current state: [29.11111111111111, 4.17760937500482]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.483848056376313\n",
      "current reward: 27.483848056376313; current state: [28.25925925925926, 6.489112666240747]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.094654956932867\n",
      "current reward: 27.094654956932867; current state: [29.11111111111111, 2.031874162214016]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.372246259736375\n",
      "current reward: 27.372246259736375; current state: [25.444444444444443, 10.857359419420652]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.062193110410135\n",
      "current reward: 29.062193110410135; current state: [24.925925925925927, 7.101800028482127]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.466190260856305\n",
      "current reward: 27.466190260856305; current state: [21.14814814814815, 6.493509536307302]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.742006824438423\n",
      "current reward: 28.742006824438423; current state: [28.703703703703702, 0.7774959455378267]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.480833046048275\n",
      "current reward: 28.480833046048275; current state: [26.185185185185187, 9.841920014490265]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.325865101687594\n",
      "current reward: 27.325865101687594; current state: [20.555555555555557, 7.8361714965612554]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.090992772882316\n",
      "current reward: 28.090992772882316; current state: [24.22222222222222, 0.38068080484956796]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.586127276301927\n",
      "current reward: 28.586127276301927; current state: [29.444444444444443, 0.18578714942807545]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.903140685167852\n",
      "current reward: 26.903140685167852; current state: [29.11111111111111, 4.4023287923411845]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.100861196084736\n",
      "current reward: 30.100861196084736; current state: [29.11111111111111, 2.3332943042414827]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.086331806827292\n",
      "current reward: 29.086331806827292; current state: [27.88888888888889, 7.998475761575319]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.032623573959857\n",
      "current reward: 27.032623573959857; current state: [26.185185185185187, 5.225139434757428]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.226273776164646\n",
      "current reward: 27.226273776164646; current state: [24.925925925925927, 4.8607036100177945]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.02276860286766\n",
      "current reward: 27.02276860286766; current state: [25.62962962962963, 8.788130516210401]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.134365170629625\n",
      "current reward: 27.134365170629625; current state: [28.703703703703702, 4.3209727604417845]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.64742616975451\n",
      "current reward: 26.64742616975451; current state: [28.703703703703702, 4.6837868963388685]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.83427375712674\n",
      "current reward: 26.83427375712674; current state: [28.703703703703702, 8.622428008158769]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.081093895383493\n",
      "current reward: 27.081093895383493; current state: [26.185185185185187, 12.884335601121709]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.91637569564374\n",
      "current reward: 26.91637569564374; current state: [28.703703703703702, 2.540914562354877]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.111993512448922\n",
      "current reward: 27.111993512448922; current state: [27.88888888888889, 3.7956660451954822]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.82995492358482\n",
      "current reward: 26.82995492358482; current state: [28.703703703703702, 3.8562380510213927]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.933081548242868\n",
      "current reward: 26.933081548242868; current state: [27.88888888888889, 8.2747961528416]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.066883777860806\n",
      "current reward: 29.066883777860806; current state: [26.666666666666668, 2.793633238357621]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.890925161902658\n",
      "current reward: 28.890925161902658; current state: [26.185185185185187, 8.609946419763109]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.198699895252876\n",
      "current reward: 27.198699895252876; current state: [24.22222222222222, 8.270027273863422]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.74630121050684\n",
      "current reward: 26.74630121050684; current state: [25.444444444444443, 3.4380616188111826]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.876445459837537\n",
      "current reward: 28.876445459837537; current state: [25.444444444444443, 6.318598102295992]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.587862201616076\n",
      "current reward: 28.587862201616076; current state: [29.962962962962962, 1.7376593423321671]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.764128010412296\n",
      "current reward: 26.764128010412296; current state: [27.88888888888889, 4.9144677600877404]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.079979755758576\n",
      "current reward: 27.079979755758576; current state: [25.444444444444443, 5.774589633091817]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.203919069299953\n",
      "current reward: 27.203919069299953; current state: [25.444444444444443, 9.77068499082254]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.361317171199335\n",
      "current reward: 27.361317171199335; current state: [23.51851851851852, 11.42253218838147]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.973528860415687\n",
      "current reward: 26.973528860415687; current state: [27.88888888888889, 1.6041665275938224]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.25169793317488\n",
      "current reward: 27.25169793317488; current state: [27.88888888888889, 6.889883696840524]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.50468452437249\n",
      "current reward: 27.50468452437249; current state: [18.77777777777778, 11.974496037245112]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.77030128452962\n",
      "current reward: 26.77030128452962; current state: [24.703703703703702, 1.9233277983936117]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.767930124855734\n",
      "current reward: 27.767930124855734; current state: [27.074074074074073, 5.585563558175634]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.215278391476563\n",
      "current reward: 28.215278391476563; current state: [22.333333333333332, 8.80296310108463]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.747272551959885\n",
      "current reward: 27.747272551959885; current state: [25.88888888888889, 4.409649624234153]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.3688324300451\n",
      "current reward: 27.3688324300451; current state: [27.88888888888889, 2.934604749658871]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.510920893192687\n",
      "current reward: 28.510920893192687; current state: [25.444444444444443, 5.061161832520177]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.6455537547217\n",
      "current reward: 26.6455537547217; current state: [24.22222222222222, 10.447058981845366]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.29688949521356\n",
      "current reward: 28.29688949521356; current state: [27.444444444444443, 4.199533064936011]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.390078904697308\n",
      "current reward: 28.390078904697308; current state: [24.22222222222222, 8.715112868102773]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.093463787261445\n",
      "current reward: 27.093463787261445; current state: [30.333333333333332, 0.8168090977497369]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.37051082656842\n",
      "current reward: 28.37051082656842; current state: [27.88888888888889, 5.771303266544257]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.65738877529751\n",
      "current reward: 27.65738877529751; current state: [26.666666666666668, 6.496036828395454]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.149303023211033\n",
      "current reward: 27.149303023211033; current state: [29.11111111111111, 6.263782760195382]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.388473128262348\n",
      "current reward: 27.388473128262348; current state: [29.11111111111111, 5.863130997055212]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.98268964590598\n",
      "current reward: 26.98268964590598; current state: [29.962962962962962, 2.3877470447702542]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.09755399508153\n",
      "current reward: 27.09755399508153; current state: [30.333333333333332, 5.874415149894784]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.148405865990657\n",
      "current reward: 27.148405865990657; current state: [29.444444444444443, 2.4451878040004016]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.517199275916266\n",
      "current reward: 26.517199275916266; current state: [24.703703703703702, 8.4040837376981]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.786862744015593\n",
      "current reward: 27.786862744015593; current state: [19.88888888888889, 6.835198902569539]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.163152823965007\n",
      "current reward: 26.163152823965007; current state: [20.51851851851852, 7.873111329767661]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.90193769667709\n",
      "current reward: 27.90193769667709; current state: [23.962962962962962, 7.033650522821641]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.840677351021743\n",
      "current reward: 27.840677351021743; current state: [24.703703703703702, 6.80744593638246]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.234008980280564\n",
      "current reward: 26.234008980280564; current state: [24.703703703703702, 2.0907862845078307]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.774702463876068\n",
      "current reward: 27.774702463876068; current state: [25.88888888888889, 7.206137543642062]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.681168382224516\n",
      "current reward: 29.681168382224516; current state: [29.11111111111111, 4.64656637472262]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.714083492821484\n",
      "current reward: 26.714083492821484; current state: [27.88888888888889, 3.1764991431798495]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.338994158302686\n",
      "current reward: 28.338994158302686; current state: [28.703703703703702, 5.727125786449848]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 26.630187371669745\n",
      "current reward: 26.630187371669745; current state: [28.703703703703702, 2.6443245747605992]\n",
      "exploring action\n",
      "Current action = 25, current state (3, 3)\n",
      "act action : 25\n",
      "reward: 28.015157848060003\n",
      "current reward: 28.015157848060003; current state: [24.925925925925927, 9.816451025419703]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.333369070389978\n",
      "current reward: 26.333369070389978; current state: [23.0, 10.829362158904335]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.72139146247636\n",
      "current reward: 28.72139146247636; current state: [25.444444444444443, 3.1829461634744955]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.513996893596055\n",
      "current reward: 26.513996893596055; current state: [27.444444444444443, 6.4813244642027135]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.692903420345232\n",
      "current reward: 26.692903420345232; current state: [25.444444444444443, 7.2774685985385155]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.37904764713656\n",
      "current reward: 26.37904764713656; current state: [25.444444444444443, 4.063419709242482]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.112193933968552\n",
      "current reward: 28.112193933968552; current state: [31.555555555555557, 2.024346927867381]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.91563631320793\n",
      "current reward: 26.91563631320793; current state: [23.0, 14.780872981088814]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.02549849305493\n",
      "current reward: 27.02549849305493; current state: [27.444444444444443, 0.37057992581555765]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.825563541374834\n",
      "current reward: 26.825563541374834; current state: [32.48148148148148, 2.3992859672695244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.03242008883579\n",
      "current reward: 27.03242008883579; current state: [35.0, 0.049772468714448244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.00254091615878\n",
      "current reward: 27.00254091615878; current state: [29.51851851851852, 9.603336051690503]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.843847382202924\n",
      "current reward: 26.843847382202924; current state: [27.666666666666668, 9.866847133236115]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.141737303603815\n",
      "current reward: 27.141737303603815; current state: [30.333333333333332, 4.739057516762404]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.348561655397514\n",
      "current reward: 27.348561655397514; current state: [29.0, 9.20030506323526]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.676419941854103\n",
      "current reward: 29.676419941854103; current state: [27.037037037037038, 9.252268254968666]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.525519236069602\n",
      "current reward: 27.525519236069602; current state: [27.037037037037038, 3.8051241321569678]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.33881874703307\n",
      "current reward: 27.33881874703307; current state: [31.962962962962962, 6.232988073987651]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.62551865165716\n",
      "current reward: 27.62551865165716; current state: [30.555555555555557, 7.517261729627027]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.87177062276808\n",
      "current reward: 27.87177062276808; current state: [29.77777777777778, 3.9194719088589953]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.458172847551584\n",
      "current reward: 29.458172847551584; current state: [32.51851851851852, 5.946699884290744]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.01190868838191\n",
      "current reward: 28.01190868838191; current state: [32.51851851851852, 1.9041602028075757]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.377749834175134\n",
      "current reward: 28.377749834175134; current state: [34.77777777777778, 4.0278439963272215]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.730874908425005\n",
      "current reward: 27.730874908425005; current state: [31.14814814814815, 6.83009049242823]\n",
      "exploring action\n",
      "Current action = 31, current state (3, 3)\n",
      "act action : 31\n",
      "reward: 29.510643939889267\n",
      "current reward: 29.510643939889267; current state: [30.555555555555557, 6.025568088618541]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 28.676744415779307\n",
      "current reward: 28.676744415779307; current state: [31.666666666666668, 2.1010607405726125]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.199026834422096\n",
      "current reward: 28.199026834422096; current state: [25.62962962962963, 13.130239513006368]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.881803579750255\n",
      "current reward: 27.881803579750255; current state: [22.333333333333332, 10.518140985960065]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.036214655029088\n",
      "current reward: 28.036214655029088; current state: [29.0, 2.3970227447331474]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.296861904938734\n",
      "current reward: 28.296861904938734; current state: [27.666666666666668, 10.22789787704979]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.0593606637115\n",
      "current reward: 30.0593606637115; current state: [29.77777777777778, 2.9577987227723264]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.107372527327566\n",
      "current reward: 28.107372527327566; current state: [32.51851851851852, 2.620221205880018]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.573338129507835\n",
      "current reward: 27.573338129507835; current state: [33.370370370370374, 4.00776976115626]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.156979077946772\n",
      "current reward: 29.156979077946772; current state: [28.40740740740741, 9.228898799463193]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.68167960669847\n",
      "current reward: 27.68167960669847; current state: [27.037037037037038, 6.9972879108375645]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.684365821510557\n",
      "current reward: 27.684365821510557; current state: [25.0, 4.8565363522405685]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.525436525575856\n",
      "current reward: 28.525436525575856; current state: [26.333333333333332, 7.9380518155604864]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.439691103227457\n",
      "current reward: 27.439691103227457; current state: [30.333333333333332, 3.7543715501622206]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.57530814265561\n",
      "current reward: 27.57530814265561; current state: [25.62962962962963, 7.498630110200345]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.556042045083597\n",
      "current reward: 28.556042045083597; current state: [20.444444444444443, 8.295657790909459]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.74851270255982\n",
      "current reward: 28.74851270255982; current state: [23.037037037037038, 7.158496687088216]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.865901361977905\n",
      "current reward: 28.865901361977905; current state: [32.111111111111114, 1.5537164783458135]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.81338355271731\n",
      "current reward: 28.81338355271731; current state: [25.444444444444443, 6.184778090473447]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.123754026325685\n",
      "current reward: 27.123754026325685; current state: [27.88888888888889, 2.171204981914961]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.318644142312962\n",
      "current reward: 26.318644142312962; current state: [29.444444444444443, 5.90798621299377]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.570399958379124\n",
      "current reward: 26.570399958379124; current state: [27.074074074074073, 7.824738756526206]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.77903357573591\n",
      "current reward: 27.77903357573591; current state: [27.88888888888889, 6.51716779589297]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.896979072260176\n",
      "current reward: 26.896979072260176; current state: [29.11111111111111, 3.2476597085765833]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.416009246500618\n",
      "current reward: 26.416009246500618; current state: [27.444444444444443, 8.32537444040962]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.52009068175254\n",
      "current reward: 27.52009068175254; current state: [26.666666666666668, 5.676076218287129]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.98648817098667\n",
      "current reward: 27.98648817098667; current state: [19.333333333333332, 14.830546104778671]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.759889724075666\n",
      "current reward: 26.759889724075666; current state: [24.925925925925927, 6.288001836605339]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.219182658816806\n",
      "current reward: 28.219182658816806; current state: [32.48148148148148, 3.8816654728568527]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.329393844087235\n",
      "current reward: 27.329393844087235; current state: [29.51851851851852, 8.422016924010757]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.327169000069045\n",
      "current reward: 29.327169000069045; current state: [30.814814814814813, 4.915941335930319]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.341977993695497\n",
      "current reward: 29.341977993695497; current state: [26.925925925925927, 3.5919838728307467]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.151433616207637\n",
      "current reward: 27.151433616207637; current state: [26.185185185185187, 5.195792243716892]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.03820532630955\n",
      "current reward: 29.03820532630955; current state: [28.703703703703702, 2.988818609574043]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.44788176607979\n",
      "current reward: 27.44788176607979; current state: [27.444444444444443, 6.497395806293253]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.049680365110714\n",
      "current reward: 27.049680365110714; current state: [29.51851851851852, 2.8639098750365153]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.13737348205707\n",
      "current reward: 27.13737348205707; current state: [25.0, 15.316992953184307]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.02012456683202\n",
      "current reward: 28.02012456683202; current state: [24.925925925925927, 9.810408268666357]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.393663778551225\n",
      "current reward: 27.393663778551225; current state: [29.962962962962962, 0.049772468714448244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.50471005054978\n",
      "current reward: 27.50471005054978; current state: [29.51851851851852, 7.454759667090484]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.77729624620316\n",
      "current reward: 27.77729624620316; current state: [29.51851851851852, 5.191080732862051]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.466634973631248\n",
      "current reward: 27.466634973631248; current state: [28.22222222222222, 4.078498574674858]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.77091516816338\n",
      "current reward: 27.77091516816338; current state: [26.925925925925927, 5.342084486772414]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.98690082660885\n",
      "current reward: 27.98690082660885; current state: [31.22222222222222, 2.387662165505376]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.026856394373766\n",
      "current reward: 28.026856394373766; current state: [28.703703703703702, 7.992014226141111]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.271211168572886\n",
      "current reward: 28.271211168572886; current state: [32.48148148148148, 3.038208175908]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.196842331124458\n",
      "current reward: 29.196842331124458; current state: [28.22222222222222, 4.911888370606545]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.755727806620616\n",
      "current reward: 27.755727806620616; current state: [23.666666666666668, 11.53856132060264]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.01897468453654\n",
      "current reward: 28.01897468453654; current state: [27.444444444444443, 3.7764133992417857]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.773085780162617\n",
      "current reward: 27.773085780162617; current state: [25.62962962962963, 9.741345095282387]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.19153963443483\n",
      "current reward: 28.19153963443483; current state: [26.925925925925927, 6.1799784479541975]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.598413775170744\n",
      "current reward: 28.598413775170744; current state: [29.51851851851852, 4.005283375665817]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.06778524339195\n",
      "current reward: 28.06778524339195; current state: [28.703703703703702, 7.152100064492028]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.868953627092278\n",
      "current reward: 27.868953627092278; current state: [32.111111111111114, 2.721492265637938]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.005795944741568\n",
      "current reward: 28.005795944741568; current state: [29.962962962962962, 1.8957387714616085]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.879824390179625\n",
      "current reward: 29.879824390179625; current state: [26.185185185185187, 5.751040703768247]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.108852828124608\n",
      "current reward: 29.108852828124608; current state: [25.62962962962963, 5.958337917783644]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.88807234715901\n",
      "current reward: 27.88807234715901; current state: [28.703703703703702, 8.164512403262183]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.6962694131313\n",
      "current reward: 29.6962694131313; current state: [29.11111111111111, 2.1795638342108696]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.267208504661955\n",
      "current reward: 29.267208504661955; current state: [27.88888888888889, 5.266004939148746]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.89096457345815\n",
      "current reward: 27.89096457345815; current state: [24.22222222222222, 5.009189288831424]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.99731195666207\n",
      "current reward: 27.99731195666207; current state: [23.0, 13.254074556319292]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.08577698924351\n",
      "current reward: 28.08577698924351; current state: [23.0, 4.600108609514973]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.731859693698908\n",
      "current reward: 28.731859693698908; current state: [26.185185185185187, 4.113956348695485]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.861026549664142\n",
      "current reward: 27.861026549664142; current state: [31.22222222222222, 1.744533477746935]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.481092414011627\n",
      "current reward: 27.481092414011627; current state: [30.814814814814813, 5.010549683217497]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.99047122659879\n",
      "current reward: 28.99047122659879; current state: [26.925925925925927, 9.878238214967864]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.96682291857154\n",
      "current reward: 27.96682291857154; current state: [23.666666666666668, 8.688422276921106]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.283899470323956\n",
      "current reward: 28.283899470323956; current state: [23.037037037037038, 8.756209471882878]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.385210755461742\n",
      "current reward: 28.385210755461742; current state: [29.51851851851852, 4.050428194699889]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.042596259728082\n",
      "current reward: 29.042596259728082; current state: [32.48148148148148, 3.9182838093273453]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.503798264783494\n",
      "current reward: 27.503798264783494; current state: [27.88888888888889, 6.247335188777877]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.38208246271115\n",
      "current reward: 27.38208246271115; current state: [27.444444444444443, 4.219908881720001]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.11069630670582\n",
      "current reward: 29.11069630670582; current state: [22.333333333333332, 12.250126428240604]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.48201223385945\n",
      "current reward: 28.48201223385945; current state: [25.11111111111111, 4.396459426898592]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.064009293937957\n",
      "current reward: 27.064009293937957; current state: [28.25925925925926, 0.0469283276450512]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.366543687296815\n",
      "current reward: 28.366543687296815; current state: [28.25925925925926, 3.554455410239438]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.907917527204052\n",
      "current reward: 26.907917527204052; current state: [25.444444444444443, 6.514404472147171]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.529426159222783\n",
      "current reward: 28.529426159222783; current state: [24.22222222222222, 8.655046453499056]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.338710585537978\n",
      "current reward: 27.338710585537978; current state: [24.22222222222222, 10.864524940522752]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.703223115580176\n",
      "current reward: 28.703223115580176; current state: [22.40740740740741, 8.022669575939087]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.904117537790686\n",
      "current reward: 28.904117537790686; current state: [27.444444444444443, 1.1655201149944308]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.878275772309753\n",
      "current reward: 26.878275772309753; current state: [28.703703703703702, 3.685903032697236]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.108241303661643\n",
      "current reward: 27.108241303661643; current state: [23.666666666666668, 9.151187734552089]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.85962412901039\n",
      "current reward: 26.85962412901039; current state: [23.037037037037038, 0.9320982629836388]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.130705625447945\n",
      "current reward: 27.130705625447945; current state: [30.814814814814813, 2.081244195195659]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.416665445205567\n",
      "current reward: 27.416665445205567; current state: [30.814814814814813, 8.376406669979026]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.01068277592758\n",
      "current reward: 28.01068277592758; current state: [29.51851851851852, 5.8145108647712975]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.13300789998429\n",
      "current reward: 27.13300789998429; current state: [28.22222222222222, 4.606186695544962]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.010618557577203\n",
      "current reward: 29.010618557577203; current state: [29.0, 7.141075005749205]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 27.460468284051718\n",
      "current reward: 27.460468284051718; current state: [30.333333333333332, 2.6471658873729296]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.991896798643296\n",
      "current reward: 28.991896798643296; current state: [27.666666666666668, 4.867451643790331]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.80554733932227\n",
      "current reward: 27.80554733932227; current state: [25.666666666666668, 8.310088332283108]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.109673251471122\n",
      "current reward: 28.109673251471122; current state: [29.77777777777778, 7.271772914864975]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.6810517265389\n",
      "current reward: 27.6810517265389; current state: [31.962962962962962, 5.828474108386007]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.991684275884015\n",
      "current reward: 27.991684275884015; current state: [30.555555555555557, 6.536378011528971]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.29085744417721\n",
      "current reward: 27.29085744417721; current state: [29.0, 8.778323956236653]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.604453896627422\n",
      "current reward: 27.604453896627422; current state: [30.333333333333332, 5.723987667756591]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.86555319192\n",
      "current reward: 27.86555319192; current state: [31.666666666666668, 4.883958314964614]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.306114478277205\n",
      "current reward: 27.306114478277205; current state: [24.925925925925927, 8.01638968357085]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.47687466553864\n",
      "current reward: 27.47687466553864; current state: [28.703703703703702, 2.3341887230415046]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.07785497430874\n",
      "current reward: 27.07785497430874; current state: [31.22222222222222, 1.7547457969069198]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.033944320194866\n",
      "current reward: 29.033944320194866; current state: [32.48148148148148, 2.0417271513438715]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.39068951964394\n",
      "current reward: 27.39068951964394; current state: [27.444444444444443, 5.117862078487783]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.711791237319872\n",
      "current reward: 27.711791237319872; current state: [25.62962962962963, 6.1381179099173835]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.876875046089776\n",
      "current reward: 27.876875046089776; current state: [29.51851851851852, 6.070214611626548]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.278252594184078\n",
      "current reward: 28.278252594184078; current state: [34.333333333333336, 3.6742451926775765]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.87502611083578\n",
      "current reward: 27.87502611083578; current state: [29.51851851851852, 9.40111419616646]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.038185553197675\n",
      "current reward: 29.038185553197675; current state: [30.814814814814813, 2.497032474013007]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.59399086893593\n",
      "current reward: 27.59399086893593; current state: [26.925925925925927, 8.424160481797447]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.71249099619496\n",
      "current reward: 28.71249099619496; current state: [26.925925925925927, 6.335219548820167]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.087444973438114\n",
      "current reward: 27.087444973438114; current state: [33.407407407407405, 1.4008656524411103]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.185710555652765\n",
      "current reward: 27.185710555652765; current state: [24.925925925925927, 7.359864019469075]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.14575313567308\n",
      "current reward: 28.14575313567308; current state: [26.666666666666668, 1.854873034014606]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.79651973757481\n",
      "current reward: 26.79651973757481; current state: [30.333333333333332, 2.4909646817392117]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.04193304836066\n",
      "current reward: 27.04193304836066; current state: [20.555555555555557, 9.274627164489216]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.19068669010218\n",
      "current reward: 27.19068669010218; current state: [21.77777777777778, 6.433828318562151]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.260263487066727\n",
      "current reward: 27.260263487066727; current state: [28.703703703703702, 7.754756586831739]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.794836765534882\n",
      "current reward: 26.794836765534882; current state: [28.703703703703702, 1.156773613533159]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.64738520625563\n",
      "current reward: 28.64738520625563; current state: [29.962962962962962, 3.987663841433639]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.151071319890253\n",
      "current reward: 27.151071319890253; current state: [27.444444444444443, 9.154087563509718]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.706821391986328\n",
      "current reward: 26.706821391986328; current state: [27.074074074074073, 6.087733763826969]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.932305756785144\n",
      "current reward: 26.932305756785144; current state: [29.444444444444443, 2.120359773352663]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.362847916490352\n",
      "current reward: 26.362847916490352; current state: [25.88888888888889, 6.693252682266609]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.030307189830932\n",
      "current reward: 27.030307189830932; current state: [29.444444444444443, 3.9151897302211864]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.329048054441063\n",
      "current reward: 27.329048054441063; current state: [30.333333333333332, 5.2030706941035465]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.455081939696928\n",
      "current reward: 27.455081939696928; current state: [27.88888888888889, 5.893500485936113]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.838047267578304\n",
      "current reward: 27.838047267578304; current state: [26.666666666666668, 5.414170427240206]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.013472230462497\n",
      "current reward: 28.013472230462497; current state: [26.185185185185187, 6.971797506379274]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.2169499559741\n",
      "current reward: 28.2169499559741; current state: [31.22222222222222, 3.8746838906409855]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.372553189345705\n",
      "current reward: 28.372553189345705; current state: [26.185185185185187, 6.5812738045792765]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.876694241179028\n",
      "current reward: 28.876694241179028; current state: [26.185185185185187, 2.1518266747207826]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.12198626773998\n",
      "current reward: 28.12198626773998; current state: [31.22222222222222, 4.106890305774967]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.032559595788296\n",
      "current reward: 29.032559595788296; current state: [26.666666666666668, 5.853195093765883]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 28.576152685861548\n",
      "current reward: 28.576152685861548; current state: [30.333333333333332, 1.8968014760671426]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.370995356759906\n",
      "current reward: 30.370995356759906; current state: [27.444444444444443, 6.580113380534374]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.557421602239533\n",
      "current reward: 28.557421602239533; current state: [24.925925925925927, 4.358073607507093]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.231094004665195\n",
      "current reward: 28.231094004665195; current state: [28.22222222222222, 4.495965927677574]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.10613514636979\n",
      "current reward: 30.10613514636979; current state: [32.111111111111114, 2.214317114210016]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.636485564608993\n",
      "current reward: 29.636485564608993; current state: [26.925925925925927, 7.954373317554155]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.66205605013492\n",
      "current reward: 28.66205605013492; current state: [26.333333333333332, 3.5936002381211574]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.949983585582256\n",
      "current reward: 28.949983585582256; current state: [30.333333333333332, 8.14498461163421]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.851430689792082\n",
      "current reward: 28.851430689792082; current state: [26.925925925925927, 9.207641448944655]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.343471937929323\n",
      "current reward: 30.343471937929323; current state: [23.037037037037038, 6.1538790722277215]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.076879007185948\n",
      "current reward: 29.076879007185948; current state: [29.51851851851852, 3.3394128798660914]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.172730818061524\n",
      "current reward: 29.172730818061524; current state: [28.703703703703702, 5.687918001876924]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.3965289291249\n",
      "current reward: 30.3965289291249; current state: [33.74074074074074, 1.897192071270865]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.184595275211716\n",
      "current reward: 29.184595275211716; current state: [26.925925925925927, 5.245742462182044]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.2947185525735\n",
      "current reward: 29.2947185525735; current state: [23.037037037037038, 5.35731383647622]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.027492302503806\n",
      "current reward: 27.027492302503806; current state: [27.666666666666668, 5.971864411088764]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.055791338119274\n",
      "current reward: 30.055791338119274; current state: [33.407407407407405, 0.05119453924914677]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.261931579427483\n",
      "current reward: 29.261931579427483; current state: [29.51851851851852, 6.760671909906008]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.752567082014767\n",
      "current reward: 28.752567082014767; current state: [24.925925925925927, 5.940372066503778]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.894194324153954\n",
      "current reward: 28.894194324153954; current state: [24.22222222222222, 11.038743409938602]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.890849749523255\n",
      "current reward: 29.890849749523255; current state: [27.444444444444443, 6.850902249351379]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.819287412563245\n",
      "current reward: 28.819287412563245; current state: [27.444444444444443, 7.318397620353373]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.675239402517807\n",
      "current reward: 29.675239402517807; current state: [23.666666666666668, 13.191658248723726]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.278053255943536\n",
      "current reward: 31.278053255943536; current state: [27.444444444444443, 0.049772468714448244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.46753275847276\n",
      "current reward: 28.46753275847276; current state: [31.22222222222222, 3.4229076405321357]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.63330833608465\n",
      "current reward: 29.63330833608465; current state: [27.444444444444443, 4.906062923315152]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.931926432790544\n",
      "current reward: 28.931926432790544; current state: [28.22222222222222, 5.636036298119715]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.50505658839654\n",
      "current reward: 29.50505658839654; current state: [30.814814814814813, 6.502063305231962]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.815241029791448\n",
      "current reward: 28.815241029791448; current state: [32.111111111111114, 2.7565124312523626]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.149577158767197\n",
      "current reward: 30.149577158767197; current state: [28.22222222222222, 4.546517322320285]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.50535291993481\n",
      "current reward: 28.50535291993481; current state: [26.333333333333332, 10.52110964746922]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.648981194675628\n",
      "current reward: 28.648981194675628; current state: [29.0, 5.187180518776445]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.45145671087839\n",
      "current reward: 28.45145671087839; current state: [31.14814814814815, 5.463984835728307]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.077770378968225\n",
      "current reward: 29.077770378968225; current state: [31.14814814814815, 3.51392659590013]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.739551734137525\n",
      "current reward: 28.739551734137525; current state: [33.370370370370374, 3.008388799113288]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.89366254756054\n",
      "current reward: 28.89366254756054; current state: [29.77777777777778, 9.87903735771946]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.983147406662322\n",
      "current reward: 28.983147406662322; current state: [31.14814814814815, 4.86700854499524]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.447157169749733\n",
      "current reward: 29.447157169749733; current state: [32.51851851851852, 4.075276464840826]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.537886763989814\n",
      "current reward: 28.537886763989814; current state: [29.77777777777778, 10.515023573667724]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.564070749269778\n",
      "current reward: 29.564070749269778; current state: [31.962962962962962, 2.591527696972938]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.903650082387745\n",
      "current reward: 27.903650082387745; current state: [27.037037037037038, 11.620563918612374]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.701575674909126\n",
      "current reward: 28.701575674909126; current state: [32.111111111111114, 1.5735328120933432]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.88991966065372\n",
      "current reward: 27.88991966065372; current state: [29.0, 7.599683352522159]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.878038165819273\n",
      "current reward: 28.878038165819273; current state: [26.333333333333332, 9.22858338968464]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.007961460124534\n",
      "current reward: 29.007961460124534; current state: [34.333333333333336, 0.05588874939243627]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.84094712842037\n",
      "current reward: 27.84094712842037; current state: [29.51851851851852, 7.0719964365517605]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.927115837753675\n",
      "current reward: 27.927115837753675; current state: [29.51851851851852, 2.1628817262964692]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.12097460918669\n",
      "current reward: 29.12097460918669; current state: [27.444444444444443, 5.125994585396914]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.32622017758089\n",
      "current reward: 28.32622017758089; current state: [27.88888888888889, 3.9148945749374118]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.831138656951158\n",
      "current reward: 27.831138656951158; current state: [27.444444444444443, 3.282513651243791]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.810913745869357\n",
      "current reward: 28.810913745869357; current state: [23.0, 6.028984690465632]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.24166510550766\n",
      "current reward: 27.24166510550766; current state: [26.666666666666668, 3.670015197649124]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.457214427307225\n",
      "current reward: 27.457214427307225; current state: [27.88888888888889, 5.418084340193137]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.54965987232084\n",
      "current reward: 27.54965987232084; current state: [21.14814814814815, 13.099818737513429]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 27.601951698614652\n",
      "current reward: 27.601951698614652; current state: [26.666666666666668, 3.795883840499473]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.47831899907621\n",
      "current reward: 27.47831899907621; current state: [27.88888888888889, 6.201337735188226]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 29.57796669782634\n",
      "current reward: 29.57796669782634; current state: [29.962962962962962, 4.305531818700466]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 27.999116302153016\n",
      "current reward: 27.999116302153016; current state: [27.88888888888889, 2.45935473555125]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.435711869098267\n",
      "current reward: 27.435711869098267; current state: [29.962962962962962, 5.260099085018997]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.67649686391241\n",
      "current reward: 27.67649686391241; current state: [24.925925925925927, 8.291162494395694]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.70647586151915\n",
      "current reward: 27.70647586151915; current state: [26.185185185185187, 6.2760742278868165]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.329127144915322\n",
      "current reward: 29.329127144915322; current state: [31.22222222222222, 1.148443042848527]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.17689427182009\n",
      "current reward: 28.17689427182009; current state: [29.962962962962962, 4.4875264168862445]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.798807997659676\n",
      "current reward: 27.798807997659676; current state: [29.51851851851852, 7.796497353791812]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.780628878428853\n",
      "current reward: 27.780628878428853; current state: [25.444444444444443, 9.474755529790043]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.033206482397656\n",
      "current reward: 28.033206482397656; current state: [25.444444444444443, 5.365677182627185]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.50766753835444\n",
      "current reward: 29.50766753835444; current state: [28.703703703703702, 6.24660365892966]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.04019620973312\n",
      "current reward: 28.04019620973312; current state: [26.666666666666668, 9.32992468682076]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.80955896888705\n",
      "current reward: 27.80955896888705; current state: [27.444444444444443, 1.062984175741848]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.649925467419894\n",
      "current reward: 29.649925467419894; current state: [27.444444444444443, 4.406757464348531]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.00174741712172\n",
      "current reward: 31.00174741712172; current state: [24.925925925925927, 6.391666028186705]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.577819016819337\n",
      "current reward: 29.577819016819337; current state: [26.185185185185187, 3.8759290896459797]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.844698969569027\n",
      "current reward: 27.844698969569027; current state: [22.814814814814813, 6.634057782610067]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.872658220966105\n",
      "current reward: 27.872658220966105; current state: [28.25925925925926, 4.662635254215327]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.063930950439612\n",
      "current reward: 28.063930950439612; current state: [29.444444444444443, 4.3341739916486866]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.3878579060665\n",
      "current reward: 28.3878579060665; current state: [27.88888888888889, 9.186756338185731]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.644971770943666\n",
      "current reward: 27.644971770943666; current state: [30.333333333333332, 2.142300760508899]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.539570780209505\n",
      "current reward: 28.539570780209505; current state: [21.77777777777778, 8.18791449767714]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.572912857229337\n",
      "current reward: 27.572912857229337; current state: [26.666666666666668, 2.0055080533164915]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 27.9444864177696\n",
      "current reward: 27.9444864177696; current state: [26.666666666666668, 9.454727068852726]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.630950531064077\n",
      "current reward: 27.630950531064077; current state: [28.703703703703702, 5.602357717936102]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.337790105178872\n",
      "current reward: 29.337790105178872; current state: [28.25925925925926, 4.924674551941989]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.364455735540712\n",
      "current reward: 27.364455735540712; current state: [25.444444444444443, 9.852775773838268]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.60354545475592\n",
      "current reward: 27.60354545475592; current state: [25.444444444444443, 6.0440762078788515]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.70656743450259\n",
      "current reward: 30.70656743450259; current state: [30.333333333333332, 0.18845474811414176]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.03039234288282\n",
      "current reward: 28.03039234288282; current state: [26.666666666666668, 7.703560999517663]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.440810282065524\n",
      "current reward: 28.440810282065524; current state: [25.444444444444443, 5.898652081400612]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.25352610891566\n",
      "current reward: 28.25352610891566; current state: [29.444444444444443, 1.847710139737699]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.523618251797377\n",
      "current reward: 28.523618251797377; current state: [22.333333333333332, 11.780031102448323]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.301189653293715\n",
      "current reward: 29.301189653293715; current state: [22.333333333333332, 9.939498186920005]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.5868413044639\n",
      "current reward: 28.5868413044639; current state: [28.25925925925926, 2.231181559454098]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.816012773701118\n",
      "current reward: 28.816012773701118; current state: [24.703703703703702, 6.654992384704157]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.80438899347399\n",
      "current reward: 28.80438899347399; current state: [26.666666666666668, 7.9667740874998225]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.083543661966274\n",
      "current reward: 30.083543661966274; current state: [25.88888888888889, 9.178151863411987]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.886247672204576\n",
      "current reward: 29.886247672204576; current state: [25.444444444444443, 9.034065327288456]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.013222012706603\n",
      "current reward: 30.013222012706603; current state: [30.333333333333332, 0.9883492416537017]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.920910587694834\n",
      "current reward: 28.920910587694834; current state: [27.88888888888889, 5.459744695073801]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.006143166442655\n",
      "current reward: 30.006143166442655; current state: [28.703703703703702, 5.170091630329528]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.757989077361618\n",
      "current reward: 28.757989077361618; current state: [30.333333333333332, 1.937202779946013]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.468156268708622\n",
      "current reward: 28.468156268708622; current state: [24.925925925925927, 11.616405982522704]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.724591517556906\n",
      "current reward: 28.724591517556906; current state: [23.666666666666668, 6.3598707017383616]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.04876402640532\n",
      "current reward: 29.04876402640532; current state: [29.11111111111111, 1.3724724136371318]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.82153334691722\n",
      "current reward: 28.82153334691722; current state: [26.666666666666668, 6.7804086547766795]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.04189998360612\n",
      "current reward: 30.04189998360612; current state: [24.22222222222222, 4.9114686884437155]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.684064358063342\n",
      "current reward: 28.684064358063342; current state: [28.703703703703702, 4.932258748769197]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.18573649440479\n",
      "current reward: 31.18573649440479; current state: [24.925925925925927, 14.69645496668727]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.004924326473812\n",
      "current reward: 29.004924326473812; current state: [32.111111111111114, 3.901314625459381]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.298882496584792\n",
      "current reward: 30.298882496584792; current state: [28.703703703703702, 3.637782105701988]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.472830787150997\n",
      "current reward: 29.472830787150997; current state: [28.703703703703702, 3.717146479428614]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.462019791283954\n",
      "current reward: 31.462019791283954; current state: [32.111111111111114, 4.101106756518787]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.214186696450454\n",
      "current reward: 29.214186696450454; current state: [29.11111111111111, 3.706361195321073]\n",
      "exploring action\n",
      "Current action = 25, current state (3, 3)\n",
      "act action : 25\n",
      "reward: 29.34019874493497\n",
      "current reward: 29.34019874493497; current state: [24.703703703703702, 4.573223327322468]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.21509675412518\n",
      "current reward: 29.21509675412518; current state: [26.666666666666668, 6.641091986831821]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.32980257956149\n",
      "current reward: 29.32980257956149; current state: [27.40740740740741, 1.7991033913878889]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.779668573512208\n",
      "current reward: 28.779668573512208; current state: [24.703703703703702, 8.439431240074923]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.979674710653388\n",
      "current reward: 28.979674710653388; current state: [25.88888888888889, 6.087693334642161]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.14966867459542\n",
      "current reward: 29.14966867459542; current state: [28.25925925925926, 2.5507986373910905]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.832743161108368\n",
      "current reward: 29.832743161108368; current state: [29.11111111111111, 2.1186439871217657]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.656054694196555\n",
      "current reward: 28.656054694196555; current state: [26.666666666666668, 9.995680566303392]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.199101144036188\n",
      "current reward: 30.199101144036188; current state: [26.185185185185187, 8.454794743048309]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.0392922479494\n",
      "current reward: 29.0392922479494; current state: [25.444444444444443, 4.540022291842051]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.371494503649643\n",
      "current reward: 30.371494503649643; current state: [24.22222222222222, 8.014962765974186]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.18455814396775\n",
      "current reward: 30.18455814396775; current state: [25.88888888888889, 5.033780979827298]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.735494644064612\n",
      "current reward: 29.735494644064612; current state: [29.11111111111111, 2.8790870790481145]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.837759839566473\n",
      "current reward: 29.837759839566473; current state: [21.77777777777778, 13.844467499999542]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.47757656965092\n",
      "current reward: 28.47757656965092; current state: [24.703703703703702, 3.81573126254943]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.15977838896403\n",
      "current reward: 29.15977838896403; current state: [22.333333333333332, 7.683111220297957]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.54905512654098\n",
      "current reward: 29.54905512654098; current state: [23.51851851851852, 6.69553685712436]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.082419740461663\n",
      "current reward: 28.082419740461663; current state: [29.11111111111111, 4.122959066487876]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.298236794152228\n",
      "current reward: 28.298236794152228; current state: [31.555555555555557, 1.8809396900008994]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.16732400126509\n",
      "current reward: 29.16732400126509; current state: [26.185185185185187, 8.788120042372462]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.029464172608012\n",
      "current reward: 28.029464172608012; current state: [23.666666666666668, 4.286488957444267]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.230404406768695\n",
      "current reward: 28.230404406768695; current state: [26.185185185185187, 5.498832631934264]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.374341857564882\n",
      "current reward: 28.374341857564882; current state: [21.77777777777778, 7.181573875139204]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.87188187498992\n",
      "current reward: 27.87188187498992; current state: [28.703703703703702, 2.679870894170002]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.39089484946251\n",
      "current reward: 27.39089484946251; current state: [31.22222222222222, 3.0359004590668466]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.49735442311245\n",
      "current reward: 27.49735442311245; current state: [26.666666666666668, 6.871674875188507]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.679721353104842\n",
      "current reward: 27.679721353104842; current state: [25.88888888888889, 7.7880782751664475]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.607617352456003\n",
      "current reward: 28.607617352456003; current state: [24.703703703703702, 5.257515645562983]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.186809779187513\n",
      "current reward: 27.186809779187513; current state: [24.703703703703702, 6.398576814644977]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.485999879456283\n",
      "current reward: 28.485999879456283; current state: [26.666666666666668, 6.388054666658663]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.663197267166066\n",
      "current reward: 27.663197267166066; current state: [26.666666666666668, 5.309860446691205]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.148751803132836\n",
      "current reward: 27.148751803132836; current state: [27.444444444444443, 3.9222487696173762]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.471892558602985\n",
      "current reward: 27.471892558602985; current state: [24.925925925925927, 8.676951715462259]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.709367047446026\n",
      "current reward: 27.709367047446026; current state: [23.666666666666668, 6.181288167128099]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.4274783377537\n",
      "current reward: 27.4274783377537; current state: [31.22222222222222, 3.1334543829278707]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.30656221864997\n",
      "current reward: 29.30656221864997; current state: [31.22222222222222, 2.854912987172067]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.48638416592072\n",
      "current reward: 27.48638416592072; current state: [29.11111111111111, 4.0687605317392075]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.56333070406127\n",
      "current reward: 27.56333070406127; current state: [23.51851851851852, 8.274946452180542]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 29.538018762791207\n",
      "current reward: 29.538018762791207; current state: [22.333333333333332, 4.14780465724509]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.158960938198145\n",
      "current reward: 29.158960938198145; current state: [24.22222222222222, 5.149832109151462]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.56170698490077\n",
      "current reward: 27.56170698490077; current state: [21.666666666666668, 10.268540160874947]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.828100112721597\n",
      "current reward: 28.828100112721597; current state: [25.88888888888889, 4.380622756318899]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.817615485395834\n",
      "current reward: 27.817615485395834; current state: [25.88888888888889, 3.684539797125117]\n",
      "exploring action\n",
      "Current action = 25, current state (3, 3)\n",
      "act action : 25\n",
      "reward: 28.11190740214956\n",
      "current reward: 28.11190740214956; current state: [24.22222222222222, 6.477721507826559]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.374276509044677\n",
      "current reward: 28.374276509044677; current state: [29.11111111111111, 0.04835039817974972]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.645135342882266\n",
      "current reward: 28.645135342882266; current state: [31.555555555555557, 2.115490176370287]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.398598908953016\n",
      "current reward: 28.398598908953016; current state: [28.703703703703702, 3.2002504957206983]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.487131247927138\n",
      "current reward: 28.487131247927138; current state: [27.88888888888889, 1.8313085235898983]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.478698739689847\n",
      "current reward: 28.478698739689847; current state: [27.444444444444443, 9.485524426802803]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.060971139248593\n",
      "current reward: 30.060971139248593; current state: [26.185185185185187, 7.883324880092876]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.78717238044445\n",
      "current reward: 28.78717238044445; current state: [20.555555555555557, 13.913635768306701]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.31543913810661\n",
      "current reward: 28.31543913810661; current state: [26.666666666666668, 3.7218740531119128]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.73707911182683\n",
      "current reward: 28.73707911182683; current state: [26.666666666666668, 3.8584017914573514]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.767408675362386\n",
      "current reward: 29.767408675362386; current state: [21.77777777777778, 8.306956334854252]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.00636354872786\n",
      "current reward: 30.00636354872786; current state: [23.962962962962962, 5.323669799889761]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.243796348210413\n",
      "current reward: 28.243796348210413; current state: [29.444444444444443, 3.1699228516036166]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.628704458057225\n",
      "current reward: 28.628704458057225; current state: [25.88888888888889, 5.411779586856592]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.171510490844515\n",
      "current reward: 30.171510490844515; current state: [26.25925925925926, 2.447171560630789]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.36498447639794\n",
      "current reward: 28.36498447639794; current state: [29.703703703703702, 0.9949456940662906]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.669088054439413\n",
      "current reward: 29.669088054439413; current state: [26.25925925925926, 5.683525059285166]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.48098080973762\n",
      "current reward: 28.48098080973762; current state: [21.14814814814815, 11.554909861743464]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.449453010312876\n",
      "current reward: 28.449453010312876; current state: [25.11111111111111, 4.296271869077979]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.591831749033116\n",
      "current reward: 28.591831749033116; current state: [23.962962962962962, 7.553510331879495]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.488795374852128\n",
      "current reward: 28.488795374852128; current state: [24.703703703703702, 8.951865297106398]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.616360564283855\n",
      "current reward: 28.616360564283855; current state: [25.88888888888889, 7.855975769994393]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.66264825596814\n",
      "current reward: 28.66264825596814; current state: [26.666666666666668, 5.108249393155906]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.856939699450063\n",
      "current reward: 28.856939699450063; current state: [29.11111111111111, 6.6910028004991]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.436832888814347\n",
      "current reward: 29.436832888814347; current state: [32.48148148148148, 3.6661957239349467]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.150000586505808\n",
      "current reward: 30.150000586505808; current state: [32.48148148148148, 2.4361676867236013]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.978317120678724\n",
      "current reward: 29.978317120678724; current state: [28.703703703703702, 6.838514932810283]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.035494480518953\n",
      "current reward: 29.035494480518953; current state: [28.703703703703702, 4.754250086540101]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 30.356204918051986\n",
      "current reward: 30.356204918051986; current state: [28.703703703703702, 4.584658888034]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.981889621819263\n",
      "current reward: 29.981889621819263; current state: [27.444444444444443, 6.517548390883821]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.318663852466262\n",
      "current reward: 31.318663852466262; current state: [22.40740740740741, 10.997769190161826]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.27272587057342\n",
      "current reward: 29.27272587057342; current state: [28.703703703703702, 3.804101884612527]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.227241965218298\n",
      "current reward: 29.227241965218298; current state: [29.962962962962962, 6.550592173356278]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.49824995983431\n",
      "current reward: 30.49824995983431; current state: [27.444444444444443, 6.566497191871447]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 29.5059553412573\n",
      "current reward: 29.5059553412573; current state: [22.40740740740741, 11.402734626415175]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.609551998716388\n",
      "current reward: 29.609551998716388; current state: [29.11111111111111, 4.226217863488597]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.95299627906371\n",
      "current reward: 28.95299627906371; current state: [29.962962962962962, 4.383825780308745]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.10178277466356\n",
      "current reward: 29.10178277466356; current state: [26.666666666666668, 10.566863319595571]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.495614961947144\n",
      "current reward: 30.495614961947144; current state: [23.51851851851852, 8.366445273002702]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.012289382308523\n",
      "current reward: 29.012289382308523; current state: [27.88888888888889, 2.9184702274128997]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.204423764985275\n",
      "current reward: 29.204423764985275; current state: [25.444444444444443, 8.660005388797677]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 28.992495987846308\n",
      "current reward: 28.992495987846308; current state: [27.88888888888889, 4.163698540588489]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.306283389723536\n",
      "current reward: 29.306283389723536; current state: [23.0, 8.106178305424512]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.34762860593354\n",
      "current reward: 30.34762860593354; current state: [26.666666666666668, 2.103139235059293]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.775777686292532\n",
      "current reward: 28.775777686292532; current state: [29.962962962962962, 6.520577447598668]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.005890505151182\n",
      "current reward: 29.005890505151182; current state: [28.703703703703702, 1.6669917104539669]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.949368390457654\n",
      "current reward: 28.949368390457654; current state: [26.925925925925927, 8.354472185409834]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.00147883568916\n",
      "current reward: 29.00147883568916; current state: [26.185185185185187, 6.470033828048445]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.46068600062989\n",
      "current reward: 29.46068600062989; current state: [26.925925925925927, 6.829649518416102]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.968211286296967\n",
      "current reward: 28.968211286296967; current state: [28.22222222222222, 8.196267854839421]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.853638284658757\n",
      "current reward: 29.853638284658757; current state: [26.925925925925927, 5.242106394501615]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.484758837649053\n",
      "current reward: 28.484758837649053; current state: [26.333333333333332, 6.906097967246813]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.4827390139952\n",
      "current reward: 28.4827390139952; current state: [24.925925925925927, 5.079517609021104]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.48730040320417\n",
      "current reward: 29.48730040320417; current state: [29.51851851851852, 5.313291430606642]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.76821787888208\n",
      "current reward: 28.76821787888208; current state: [28.703703703703702, 4.409482246020499]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.07816767273417\n",
      "current reward: 30.07816767273417; current state: [27.444444444444443, 5.907551205119659]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.740310733780664\n",
      "current reward: 29.740310733780664; current state: [28.703703703703702, 3.6179483226249967]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.305635503190683\n",
      "current reward: 30.305635503190683; current state: [28.703703703703702, 2.525160526501376]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.026687953679097\n",
      "current reward: 30.026687953679097; current state: [24.925925925925927, 7.1147720051661665]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.100123305870017\n",
      "current reward: 29.100123305870017; current state: [29.962962962962962, 1.6493039593200605]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.90055116287211\n",
      "current reward: 29.90055116287211; current state: [26.925925925925927, 8.219728196235407]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.052665373021124\n",
      "current reward: 30.052665373021124; current state: [28.22222222222222, 7.261551703388959]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.162163080365712\n",
      "current reward: 29.162163080365712; current state: [25.62962962962963, 6.055314135000607]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.852810891331643\n",
      "current reward: 28.852810891331643; current state: [27.666666666666668, 4.140675719312867]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.04081891174251\n",
      "current reward: 29.04081891174251; current state: [27.666666666666668, 9.503192746096538]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.091485648795054\n",
      "current reward: 30.091485648795054; current state: [30.333333333333332, 2.8403052584845025]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.714751903270596\n",
      "current reward: 28.714751903270596; current state: [29.51851851851852, 3.9970703482409244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.781105336545025\n",
      "current reward: 28.781105336545025; current state: [29.51851851851852, 3.7535617660814857]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.132465993015515\n",
      "current reward: 29.132465993015515; current state: [32.111111111111114, 3.6200781549341055]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.485640379866286\n",
      "current reward: 28.485640379866286; current state: [29.962962962962962, 4.58142898777427]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.49453171837874\n",
      "current reward: 28.49453171837874; current state: [26.925925925925927, 8.727153124127065]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.540938593301338\n",
      "current reward: 28.540938593301338; current state: [29.962962962962962, 1.4268540791764492]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.31072920143465\n",
      "current reward: 28.31072920143465; current state: [24.925925925925927, 8.529824722776361]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.430153393997433\n",
      "current reward: 28.430153393997433; current state: [29.444444444444443, 2.2640083655317405]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.59805246499573\n",
      "current reward: 28.59805246499573; current state: [25.11111111111111, 8.887908771468433]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.099415623265756\n",
      "current reward: 28.099415623265756; current state: [23.51851851851852, 5.587225105743373]\n",
      "exploring action\n",
      "Current action = 33, current state (3, 3)\n",
      "act action : 33\n",
      "reward: 28.380244338161727\n",
      "current reward: 28.380244338161727; current state: [25.88888888888889, 4.129088957714459]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.546138039035664\n",
      "current reward: 28.546138039035664; current state: [29.444444444444443, 5.074734850443883]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.97795904384402\n",
      "current reward: 27.97795904384402; current state: [30.62962962962963, 1.9871142044562875]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.897233529333832\n",
      "current reward: 27.897233529333832; current state: [26.555555555555557, 5.862868174498138]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.916721777724906\n",
      "current reward: 27.916721777724906; current state: [27.666666666666668, 3.9065515248167775]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.21259416551187\n",
      "current reward: 28.21259416551187; current state: [26.25925925925926, 7.46105628705122]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 27.987890786762136\n",
      "current reward: 27.987890786762136; current state: [27.074074074074073, 6.1536952758885715]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.094907316146685\n",
      "current reward: 28.094907316146685; current state: [27.074074074074073, 9.792873432739974]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.360480895591603\n",
      "current reward: 28.360480895591603; current state: [27.074074074074073, 7.207837695646124]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.219858461807064\n",
      "current reward: 28.219858461807064; current state: [28.25925925925926, 5.754002194223044]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.120603874158093\n",
      "current reward: 28.120603874158093; current state: [28.25925925925926, 7.43802009422408]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.36519417633652\n",
      "current reward: 28.36519417633652; current state: [26.666666666666668, 6.073675139485747]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.287049396023473\n",
      "current reward: 28.287049396023473; current state: [24.22222222222222, 11.137909363356313]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.321753110873505\n",
      "current reward: 28.321753110873505; current state: [29.962962962962962, 6.774378674485199]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.527611551448746\n",
      "current reward: 28.527611551448746; current state: [28.703703703703702, 2.8477502812651285]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.39945496024336\n",
      "current reward: 28.39945496024336; current state: [27.444444444444443, 9.151244064928237]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.284874679734042\n",
      "current reward: 28.284874679734042; current state: [24.925925925925927, 7.358913350102802]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.68518049268091\n",
      "current reward: 28.68518049268091; current state: [28.703703703703702, 4.025819863109109]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.06335767062343\n",
      "current reward: 28.06335767062343; current state: [23.666666666666668, 14.52084247417094]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.102904090684806\n",
      "current reward: 28.102904090684806; current state: [23.0, 8.323930118814557]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.69023794876411\n",
      "current reward: 27.69023794876411; current state: [30.333333333333332, 1.008355214470497]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.124492239109554\n",
      "current reward: 28.124492239109554; current state: [30.333333333333332, 3.1131889477556345]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.217079543014716\n",
      "current reward: 28.217079543014716; current state: [24.703703703703702, 8.14054772842364]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.68771873806673\n",
      "current reward: 29.68771873806673; current state: [27.074074074074073, 6.374389282831435]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.49077208702609\n",
      "current reward: 28.49077208702609; current state: [22.814814814814813, 8.149089963098765]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.456330731202033\n",
      "current reward: 28.456330731202033; current state: [27.40740740740741, 4.235047207584841]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.348265530577322\n",
      "current reward: 28.348265530577322; current state: [23.962962962962962, 5.430213836231339]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.417888075275567\n",
      "current reward: 28.417888075275567; current state: [22.11111111111111, 3.086136003331342]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.455109648879386\n",
      "current reward: 29.455109648879386; current state: [25.11111111111111, 6.234097380032836]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.007143365912512\n",
      "current reward: 29.007143365912512; current state: [21.666666666666668, 12.836071426262517]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.67613017269258\n",
      "current reward: 27.67613017269258; current state: [24.703703703703702, 4.485628562342924]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.143748252460124\n",
      "current reward: 29.143748252460124; current state: [23.962962962962962, 6.221721733222415]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.192707190670692\n",
      "current reward: 27.192707190670692; current state: [27.074074074074073, 2.3447620824272697]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.306549586599726\n",
      "current reward: 27.306549586599726; current state: [23.51851851851852, 6.820840626243391]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.42652885710508\n",
      "current reward: 27.42652885710508; current state: [24.703703703703702, 4.015145998370536]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.233473305912185\n",
      "current reward: 27.233473305912185; current state: [29.11111111111111, 4.784774010251208]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.336562618868395\n",
      "current reward: 27.336562618868395; current state: [22.333333333333332, 9.423608339143485]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.762305838526785\n",
      "current reward: 26.762305838526785; current state: [25.444444444444443, 3.5580817460379714]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.97283586757942\n",
      "current reward: 26.97283586757942; current state: [26.666666666666668, 1.056648975834071]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.83001230575376\n",
      "current reward: 27.83001230575376; current state: [25.444444444444443, 2.6900712046342297]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.01934700726645\n",
      "current reward: 27.01934700726645; current state: [24.925925925925927, 8.252117496108182]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.216251696270742\n",
      "current reward: 27.216251696270742; current state: [27.444444444444443, 4.7694676888194145]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.65223111893665\n",
      "current reward: 27.65223111893665; current state: [24.333333333333332, 7.649183297879451]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.301898113997883\n",
      "current reward: 27.301898113997883; current state: [29.51851851851852, 4.697537536606609]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.71260622914504\n",
      "current reward: 26.71260622914504; current state: [29.51851851851852, 2.9937281185751807]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.626397757523694\n",
      "current reward: 27.626397757523694; current state: [29.51851851851852, 3.1765387720797094]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.128704515384594\n",
      "current reward: 27.128704515384594; current state: [29.51851851851852, 4.309557652877736]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.381178609340964\n",
      "current reward: 27.381178609340964; current state: [24.333333333333332, 9.348801802636881]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.06679280224013\n",
      "current reward: 28.06679280224013; current state: [29.0, 2.2808016918735987]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.03297370113115\n",
      "current reward: 28.03297370113115; current state: [29.0, 6.00440551076196]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.8580633727872\n",
      "current reward: 26.8580633727872; current state: [27.666666666666668, 9.035553836131479]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.181574168713016\n",
      "current reward: 28.181574168713016; current state: [31.666666666666668, 5.8424417119226675]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.769170419557593\n",
      "current reward: 26.769170419557593; current state: [32.51851851851852, 2.6305240419698683]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.767717183125836\n",
      "current reward: 26.767717183125836; current state: [28.22222222222222, 6.733072190147279]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.152713540042544\n",
      "current reward: 28.152713540042544; current state: [30.333333333333332, 6.13220174476238]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.947044559698124\n",
      "current reward: 26.947044559698124; current state: [29.0, 3.307517631940797]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.44291248266124\n",
      "current reward: 26.44291248266124; current state: [25.62962962962963, 14.057533310523267]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.784449119004957\n",
      "current reward: 26.784449119004957; current state: [29.51851851851852, 1.901491050923067]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.945905633483317\n",
      "current reward: 26.945905633483317; current state: [28.703703703703702, 4.344117837287916]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.46154801216821\n",
      "current reward: 28.46154801216821; current state: [25.444444444444443, 9.828829913077755]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.667505691798677\n",
      "current reward: 26.667505691798677; current state: [31.555555555555557, 0.6488057044904186]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.544529203215365\n",
      "current reward: 26.544529203215365; current state: [26.185185185185187, 10.055438798359429]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.843460520980386\n",
      "current reward: 26.843460520980386; current state: [26.185185185185187, 2.5150845261989594]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.713514731930847\n",
      "current reward: 28.713514731930847; current state: [28.703703703703702, 3.302320407144691]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.82883203262598\n",
      "current reward: 26.82883203262598; current state: [27.444444444444443, 7.230931757385475]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.106299116764788\n",
      "current reward: 27.106299116764788; current state: [28.703703703703702, 3.41769423019789]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.54716158403834\n",
      "current reward: 28.54716158403834; current state: [32.111111111111114, 2.0706010487030304]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.284525066642818\n",
      "current reward: 27.284525066642818; current state: [26.925925925925927, 13.229018344622965]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.870474073782407\n",
      "current reward: 26.870474073782407; current state: [26.333333333333332, 8.067782279489025]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.132532640028796\n",
      "current reward: 27.132532640028796; current state: [27.666666666666668, 5.543837057483022]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.384505718652733\n",
      "current reward: 27.384505718652733; current state: [25.62962962962963, 5.470334028371378]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.41396461667203\n",
      "current reward: 27.41396461667203; current state: [27.444444444444443, 4.172647568863789]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.254160814367754\n",
      "current reward: 29.254160814367754; current state: [32.48148148148148, 3.562091942931445]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.30267384378615\n",
      "current reward: 27.30267384378615; current state: [29.962962962962962, 1.0111170869555322]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.442915612781363\n",
      "current reward: 27.442915612781363; current state: [27.88888888888889, 5.488107385775496]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.058732809949806\n",
      "current reward: 29.058732809949806; current state: [25.11111111111111, 8.70772504424036]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.490999400790468\n",
      "current reward: 27.490999400790468; current state: [28.25925925925926, 3.6600357553842766]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.290526089887454\n",
      "current reward: 29.290526089887454; current state: [29.444444444444443, 2.1294098146452627]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 27.199419475457024\n",
      "current reward: 27.199419475457024; current state: [26.666666666666668, 10.569728933618467]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.274220277016695\n",
      "current reward: 29.274220277016695; current state: [26.666666666666668, 6.48324492429549]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.481501407670056\n",
      "current reward: 27.481501407670056; current state: [28.703703703703702, 4.9284999644803005]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.800587294053315\n",
      "current reward: 27.800587294053315; current state: [27.444444444444443, 5.1000870595018615]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 27.951906250128157\n",
      "current reward: 27.951906250128157; current state: [23.666666666666668, 10.108014785541188]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.191780546202256\n",
      "current reward: 29.191780546202256; current state: [26.925925925925927, 5.299690194376772]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.695680770813382\n",
      "current reward: 27.695680770813382; current state: [30.814814814814813, 1.8943446263968582]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.708110249146632\n",
      "current reward: 27.708110249146632; current state: [30.814814814814813, 5.725482343148951]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.32292072315644\n",
      "current reward: 28.32292072315644; current state: [26.185185185185187, 0.7458208075194938]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.83361522482424\n",
      "current reward: 27.83361522482424; current state: [27.444444444444443, 6.477880394072487]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.661706864176452\n",
      "current reward: 27.661706864176452; current state: [28.22222222222222, 7.318997570549732]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.720309956312022\n",
      "current reward: 27.720309956312022; current state: [29.51851851851852, 4.98333764639763]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.09054192921104\n",
      "current reward: 28.09054192921104; current state: [25.62962962962963, 6.768061915673]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.10797019630287\n",
      "current reward: 29.10797019630287; current state: [27.444444444444443, 2.5671025946345134]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.51673995356009\n",
      "current reward: 27.51673995356009; current state: [29.51851851851852, 5.302538603910294]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.539258445833003\n",
      "current reward: 27.539258445833003; current state: [25.444444444444443, 4.905933433067305]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.745505685147037\n",
      "current reward: 27.745505685147037; current state: [18.77777777777778, 15.734111025977102]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.36019333734643\n",
      "current reward: 28.36019333734643; current state: [28.25925925925926, 0.7096703725058975]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.53403753317262\n",
      "current reward: 28.53403753317262; current state: [30.62962962962963, 0.7548026732639472]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.777934632680772\n",
      "current reward: 27.777934632680772; current state: [26.666666666666668, 7.773100165558024]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.04335427981537\n",
      "current reward: 29.04335427981537; current state: [26.666666666666668, 4.085422439610456]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.758066976667738\n",
      "current reward: 29.758066976667738; current state: [25.444444444444443, 6.601612968775156]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.11761400385849\n",
      "current reward: 28.11761400385849; current state: [21.14814814814815, 10.780923261220526]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.18242333788101\n",
      "current reward: 29.18242333788101; current state: [21.14814814814815, 9.466846709420004]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.30234145725355\n",
      "current reward: 28.30234145725355; current state: [30.333333333333332, 4.129663519190701]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.496910921746732\n",
      "current reward: 28.496910921746732; current state: [26.666666666666668, 1.8907277829885787]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.496578083236376\n",
      "current reward: 28.496578083236376; current state: [23.666666666666668, 6.658612967951943]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.611623126802566\n",
      "current reward: 27.611623126802566; current state: [28.703703703703702, 2.5265770373707603]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.293455304986036\n",
      "current reward: 28.293455304986036; current state: [26.666666666666668, 3.470614714096954]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.416662307555\n",
      "current reward: 28.416662307555; current state: [27.444444444444443, 6.687002373973952]\n",
      "exploring action\n",
      "Current action = 28, current state (3, 3)\n",
      "act action : 28\n",
      "reward: 28.123750983756775\n",
      "current reward: 28.123750983756775; current state: [30.333333333333332, 4.132018385342062]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.614351239654876\n",
      "current reward: 27.614351239654876; current state: [32.48148148148148, 3.951784550500528]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.759003538866022\n",
      "current reward: 27.759003538866022; current state: [22.40740740740741, 16.464447837257527]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.970125892544882\n",
      "current reward: 27.970125892544882; current state: [29.962962962962962, 0.4685976716634598]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.34437350252377\n",
      "current reward: 29.34437350252377; current state: [26.185185185185187, 10.24419910736999]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.393165835379833\n",
      "current reward: 29.393165835379833; current state: [29.962962962962962, 5.107937922492332]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.261434843092488\n",
      "current reward: 27.261434843092488; current state: [28.703703703703702, 0.6065751274686026]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.429881916551437\n",
      "current reward: 27.429881916551437; current state: [28.703703703703702, 4.4914742089761965]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.006619859261633\n",
      "current reward: 29.006619859261633; current state: [32.111111111111114, 2.2101626894057578]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.146178856324138\n",
      "current reward: 27.146178856324138; current state: [28.703703703703702, 4.936526148036126]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.076296264439566\n",
      "current reward: 27.076296264439566; current state: [30.333333333333332, 4.649513565415936]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.865204199854148\n",
      "current reward: 26.865204199854148; current state: [31.22222222222222, 3.0083975461954577]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.85898964128964\n",
      "current reward: 26.85898964128964; current state: [27.88888888888889, 1.2534542941569526]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.983080360578143\n",
      "current reward: 27.983080360578143; current state: [26.185185185185187, 5.4959042820674995]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.812344876021523\n",
      "current reward: 28.812344876021523; current state: [23.0, 4.334061920121068]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.170774907273067\n",
      "current reward: 27.170774907273067; current state: [20.555555555555557, 11.089885779062595]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.82472119097977\n",
      "current reward: 26.82472119097977; current state: [25.444444444444443, 4.37795382355513]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.915631352977357\n",
      "current reward: 28.915631352977357; current state: [26.666666666666668, 5.779196183800848]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.473530093908654\n",
      "current reward: 26.473530093908654; current state: [27.444444444444443, 6.4619483946030485]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.6365038627107\n",
      "current reward: 28.6365038627107; current state: [31.22222222222222, 1.3751880808190382]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.82737896899077\n",
      "current reward: 26.82737896899077; current state: [30.814814814814813, 3.71624344108271]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.127763454751783\n",
      "current reward: 27.127763454751783; current state: [29.51851851851852, 4.508694303792142]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.316216074960096\n",
      "current reward: 27.316216074960096; current state: [32.111111111111114, 0.05119453924914677]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.90814963392371\n",
      "current reward: 26.90814963392371; current state: [32.111111111111114, 3.461299161800415]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.37744962432795\n",
      "current reward: 27.37744962432795; current state: [28.703703703703702, 5.714871849650644]\n",
      "exploring action\n",
      "Current action = 31, current state (3, 3)\n",
      "act action : 31\n",
      "reward: 26.54345907862955\n",
      "current reward: 26.54345907862955; current state: [24.333333333333332, 12.75535283112997]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.86449491197283\n",
      "current reward: 26.86449491197283; current state: [21.74074074074074, 15.436737342138453]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.29916622638531\n",
      "current reward: 27.29916622638531; current state: [30.814814814814813, 2.6553757377302447]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.912949596580617\n",
      "current reward: 26.912949596580617; current state: [30.814814814814813, 6.0194380201005915]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.090458037555933\n",
      "current reward: 27.090458037555933; current state: [33.407407407407405, 2.867198897517661]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 27.098720479589318\n",
      "current reward: 27.098720479589318; current state: [30.333333333333332, 6.601664962408712]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.952143449574113\n",
      "current reward: 26.952143449574113; current state: [31.666666666666668, 4.731001128623735]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.989706277520952\n",
      "current reward: 26.989706277520952; current state: [30.814814814814813, 4.835446395870762]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.554704678061174\n",
      "current reward: 26.554704678061174; current state: [32.48148148148148, 0.049772468714448244]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.684703866192034\n",
      "current reward: 26.684703866192034; current state: [27.88888888888889, 6.63077137811484]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.60420588208098\n",
      "current reward: 26.60420588208098; current state: [19.88888888888889, 10.327667017049302]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.93984800151379\n",
      "current reward: 26.93984800151379; current state: [21.14814814814815, 9.083852195967747]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.609905496748677\n",
      "current reward: 26.609905496748677; current state: [26.185185185185187, 7.789761775989216]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.89895360079724\n",
      "current reward: 26.89895360079724; current state: [24.925925925925927, 7.404102682858809]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.181063253775168\n",
      "current reward: 27.181063253775168; current state: [27.444444444444443, 5.305482318444073]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.921705851419503\n",
      "current reward: 28.921705851419503; current state: [29.51851851851852, 5.0462660142302305]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.317185751887454\n",
      "current reward: 27.317185751887454; current state: [33.407407407407405, 0.05119453924914677]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.174824067104655\n",
      "current reward: 27.174824067104655; current state: [32.111111111111114, 7.43370751763008]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.320252478763155\n",
      "current reward: 28.320252478763155; current state: [32.48148148148148, 2.168876397599933]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.21930738981216\n",
      "current reward: 27.21930738981216; current state: [30.814814814814813, 3.4124022092469284]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.23283998206558\n",
      "current reward: 29.23283998206558; current state: [29.51851851851852, 3.040883772448902]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.19172778570886\n",
      "current reward: 28.19172778570886; current state: [25.444444444444443, 6.3314048682295025]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.2721848025483\n",
      "current reward: 27.2721848025483; current state: [24.925925925925927, 5.887327910677398]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.179141504659157\n",
      "current reward: 29.179141504659157; current state: [29.11111111111111, 5.316493824720193]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.847300719488903\n",
      "current reward: 28.847300719488903; current state: [24.22222222222222, 10.47913504956075]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.287685906058172\n",
      "current reward: 27.287685906058172; current state: [25.444444444444443, 7.287887655999396]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.88840395105363\n",
      "current reward: 29.88840395105363; current state: [25.444444444444443, 7.8223287040206735]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.499096749219706\n",
      "current reward: 27.499096749219706; current state: [28.703703703703702, 5.0905354783304855]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.874850023881738\n",
      "current reward: 28.874850023881738; current state: [27.444444444444443, 7.697938461377785]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.49266783031347\n",
      "current reward: 27.49266783031347; current state: [29.51851851851852, 5.227847241922356]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.69213508769\n",
      "current reward: 27.69213508769; current state: [28.703703703703702, 5.857785277519327]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.978338700957313\n",
      "current reward: 28.978338700957313; current state: [28.703703703703702, 7.39739923569543]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.028623892693968\n",
      "current reward: 28.028623892693968; current state: [28.703703703703702, 6.25996007355219]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.17015417411926\n",
      "current reward: 28.17015417411926; current state: [26.666666666666668, 5.904360643457556]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.758083117251505\n",
      "current reward: 27.758083117251505; current state: [29.962962962962962, 4.162178500289305]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.997625511936576\n",
      "current reward: 27.997625511936576; current state: [29.962962962962962, 4.97464460627133]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.967388612550323\n",
      "current reward: 27.967388612550323; current state: [24.925925925925927, 4.488501851685424]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.134413138474446\n",
      "current reward: 28.134413138474446; current state: [19.88888888888889, 10.763676916028297]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.70714282945786\n",
      "current reward: 29.70714282945786; current state: [23.666666666666668, 7.845727909253596]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.79272883853714\n",
      "current reward: 27.79272883853714; current state: [28.22222222222222, 2.6154410948476796]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.993087310343544\n",
      "current reward: 27.993087310343544; current state: [29.51851851851852, 4.430561775765629]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.945012106304585\n",
      "current reward: 27.945012106304585; current state: [29.0, 5.5511144907879135]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.627248963874976\n",
      "current reward: 29.627248963874976; current state: [33.0, 3.816321334673165]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.060357709978433\n",
      "current reward: 28.060357709978433; current state: [32.51851851851852, 3.1213298471795126]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.642021818739085\n",
      "current reward: 29.642021818739085; current state: [32.51851851851852, 4.295427703452795]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.422885413316266\n",
      "current reward: 28.422885413316266; current state: [27.666666666666668, 10.94986791411033]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.431389296342928\n",
      "current reward: 29.431389296342928; current state: [26.333333333333332, 4.3419891934214006]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.377243646780798\n",
      "current reward: 28.377243646780798; current state: [29.0, 5.185973215589652]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.694038815202955\n",
      "current reward: 28.694038815202955; current state: [22.333333333333332, 11.110416421446708]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.549856458888385\n",
      "current reward: 28.549856458888385; current state: [20.444444444444443, 8.861392909284639]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 31.506324272532698\n",
      "current reward: 31.506324272532698; current state: [26.925925925925927, 6.063091771527817]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.448630776636588\n",
      "current reward: 28.448630776636588; current state: [27.444444444444443, 7.980333064708457]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.764582135751102\n",
      "current reward: 28.764582135751102; current state: [23.666666666666668, 9.790894994334156]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.180240370275396\n",
      "current reward: 30.180240370275396; current state: [24.333333333333332, 11.902505724060811]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.631507401037783\n",
      "current reward: 28.631507401037783; current state: [31.22222222222222, 1.9517932445114974]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.238241091657997\n",
      "current reward: 29.238241091657997; current state: [34.7037037037037, 0.5936122777344504]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.31035857119355\n",
      "current reward: 28.31035857119355; current state: [29.51851851851852, 5.042352343787473]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.44022930842605\n",
      "current reward: 28.44022930842605; current state: [28.703703703703702, 4.760877085179772]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.5701629551349\n",
      "current reward: 28.5701629551349; current state: [30.814814814814813, 3.2645382102025953]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.721123154128055\n",
      "current reward: 28.721123154128055; current state: [29.51851851851852, 3.2353223226573813]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.099510959214133\n",
      "current reward: 28.099510959214133; current state: [26.333333333333332, 7.561466061399351]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.117997937400762\n",
      "current reward: 28.117997937400762; current state: [23.037037037037038, 8.487050994277018]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.801825702438986\n",
      "current reward: 29.801825702438986; current state: [23.037037037037038, 8.046259313282212]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.845807547902563\n",
      "current reward: 27.845807547902563; current state: [30.814814814814813, 2.403947761113388]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.968753177702137\n",
      "current reward: 27.968753177702137; current state: [24.925925925925927, 10.327011599812524]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 27.57522606244088\n",
      "current reward: 27.57522606244088; current state: [23.037037037037038, 7.422208275986261]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.359607806819767\n",
      "current reward: 29.359607806819767; current state: [26.185185185185187, 4.380739126589382]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.218829772068982\n",
      "current reward: 27.218829772068982; current state: [31.22222222222222, 1.9782718831837949]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.34714171534438\n",
      "current reward: 27.34714171534438; current state: [27.444444444444443, 12.548188658988446]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.30838849709444\n",
      "current reward: 29.30838849709444; current state: [26.666666666666668, 5.889021615071538]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.26174271025855\n",
      "current reward: 27.26174271025855; current state: [30.333333333333332, 2.362697972212652]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.57255397007761\n",
      "current reward: 27.57255397007761; current state: [24.22222222222222, 12.410907933261322]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.094834517487357\n",
      "current reward: 27.094834517487357; current state: [29.11111111111111, 1.44124228902286]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.32315440233757\n",
      "current reward: 27.32315440233757; current state: [24.22222222222222, 8.94665521673947]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.62351425542722\n",
      "current reward: 27.62351425542722; current state: [19.333333333333332, 7.9833219235381385]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.705432674868515\n",
      "current reward: 28.705432674868515; current state: [29.11111111111111, 3.39175926083948]\n",
      "exploring action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.3135256813362\n",
      "current reward: 27.3135256813362; current state: [30.333333333333332, 4.629943495795819]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.830640659757865\n",
      "current reward: 27.830640659757865; current state: [29.962962962962962, 5.921500562586855]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.30415469410583\n",
      "current reward: 27.30415469410583; current state: [27.444444444444443, 4.589566478524197]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.77562808756575\n",
      "current reward: 26.77562808756575; current state: [26.185185185185187, 5.8268572751173275]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.015065497741976\n",
      "current reward: 28.015065497741976; current state: [24.925925925925927, 8.08797994542044]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.409793808596408\n",
      "current reward: 27.409793808596408; current state: [29.962962962962962, 6.6085633989958446]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.06474673193294\n",
      "current reward: 27.06474673193294; current state: [26.925925925925927, 7.148341366977364]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.30270989639782\n",
      "current reward: 27.30270989639782; current state: [24.925925925925927, 7.941297068823993]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.091792354411286\n",
      "current reward: 27.091792354411286; current state: [33.407407407407405, 2.3116804157102973]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.270062096168406\n",
      "current reward: 27.270062096168406; current state: [26.185185185185187, 7.696372430841712]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.41405783867168\n",
      "current reward: 28.41405783867168; current state: [27.444444444444443, 1.5948548214334533]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.597676287642543\n",
      "current reward: 28.597676287642543; current state: [29.962962962962962, 3.643800793031169]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.559278855801313\n",
      "current reward: 27.559278855801313; current state: [26.185185185185187, 9.175527844684233]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.5525219893975\n",
      "current reward: 28.5525219893975; current state: [29.51851851851852, 2.8095675578458015]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.981832014622146\n",
      "current reward: 28.981832014622146; current state: [28.22222222222222, 7.571288433774875]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.501626192047805\n",
      "current reward: 27.501626192047805; current state: [23.666666666666668, 10.675640837612704]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.490202384572225\n",
      "current reward: 29.490202384572225; current state: [21.14814814814815, 7.1798207804113146]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.997660941524988\n",
      "current reward: 27.997660941524988; current state: [26.666666666666668, 5.628259999601641]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.329407658833702\n",
      "current reward: 27.329407658833702; current state: [27.88888888888889, 2.2938358480260885]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.587374684505875\n",
      "current reward: 27.587374684505875; current state: [29.11111111111111, 4.343557543774476]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.29596219297754\n",
      "current reward: 27.29596219297754; current state: [29.11111111111111, 6.8170247171074605]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.496752949006453\n",
      "current reward: 27.496752949006453; current state: [30.333333333333332, 2.125595514329827]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.317162577363295\n",
      "current reward: 29.317162577363295; current state: [31.814814814814813, 2.1375834650973315]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.322133647246748\n",
      "current reward: 27.322133647246748; current state: [27.074074074074073, 8.188678428355825]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.56776613542412\n",
      "current reward: 27.56776613542412; current state: [27.074074074074073, 4.038510530911628]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.272925002443497\n",
      "current reward: 27.272925002443497; current state: [30.333333333333332, 1.4209801027342668]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.270762105472755\n",
      "current reward: 29.270762105472755; current state: [25.444444444444443, 9.622081670348766]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.87909129422822\n",
      "current reward: 26.87909129422822; current state: [27.88888888888889, 7.327133430721607]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.177241936185926\n",
      "current reward: 27.177241936185926; current state: [27.88888888888889, 5.095950031145072]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.06171881396628\n",
      "current reward: 29.06171881396628; current state: [27.88888888888889, 4.104969259550767]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.099615108417584\n",
      "current reward: 27.099615108417584; current state: [32.48148148148148, 1.5717253404319693]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.273186246298604\n",
      "current reward: 27.273186246298604; current state: [21.14814814814815, 14.05245589069784]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.616259949311246\n",
      "current reward: 28.616259949311246; current state: [26.185185185185187, 4.100880989189586]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.721078839498887\n",
      "current reward: 28.721078839498887; current state: [29.962962962962962, 5.100544473318398]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 26.79479598916369\n",
      "current reward: 26.79479598916369; current state: [23.0, 9.264383999410725]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.156706467625195\n",
      "current reward: 27.156706467625195; current state: [24.925925925925927, 3.9272776284761055]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.435301901966113\n",
      "current reward: 27.435301901966113; current state: [32.48148148148148, 1.0278744528434927]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.126334525159013\n",
      "current reward: 27.126334525159013; current state: [30.814814814814813, 4.19902839209722]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.044890815069795\n",
      "current reward: 27.044890815069795; current state: [26.925925925925927, 6.388805303338801]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.52756659436812\n",
      "current reward: 29.52756659436812; current state: [25.62962962962963, 8.603905975398378]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.384470644576794\n",
      "current reward: 27.384470644576794; current state: [30.333333333333332, 4.056461133601437]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.665172594653033\n",
      "current reward: 27.665172594653033; current state: [29.51851851851852, 8.413170935999498]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.916359868691234\n",
      "current reward: 27.916359868691234; current state: [29.0, 9.919208449517669]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.44808302027236\n",
      "current reward: 27.44808302027236; current state: [27.666666666666668, 6.095441618554418]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.647406030229742\n",
      "current reward: 27.647406030229742; current state: [26.925925925925927, 9.539496207165483]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.251428578987017\n",
      "current reward: 27.251428578987017; current state: [29.51851851851852, 2.758652803464928]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.78900843881638\n",
      "current reward: 29.78900843881638; current state: [34.7037037037037, 0.05119453924914677]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.18314728664968\n",
      "current reward: 27.18314728664968; current state: [28.22222222222222, 9.32582695261551]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.0165966175929\n",
      "current reward: 29.0165966175929; current state: [26.925925925925927, 1.8015460722743963]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.020166429527197\n",
      "current reward: 27.020166429527197; current state: [31.666666666666668, 2.925491911847286]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.12608308881911\n",
      "current reward: 27.12608308881911; current state: [27.666666666666668, 9.28791923256996]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.580456653262036\n",
      "current reward: 27.580456653262036; current state: [25.62962962962963, 7.235146347651723]\n",
      "exploring action\n",
      "Current action = 22, current state (3, 3)\n",
      "act action : 22\n",
      "reward: 27.424601980459304\n",
      "current reward: 27.424601980459304; current state: [24.925925925925927, 0.5533875052030595]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.837330429831198\n",
      "current reward: 27.837330429831198; current state: [24.925925925925927, 7.950698949918617]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.565038603452297\n",
      "current reward: 27.565038603452297; current state: [25.62962962962963, 7.686222617165828]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.506874498039384\n",
      "current reward: 27.506874498039384; current state: [27.88888888888889, 2.856269901549353]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.22091890381248\n",
      "current reward: 27.22091890381248; current state: [29.962962962962962, 5.586218908463899]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.171932707505107\n",
      "current reward: 28.171932707505107; current state: [31.814814814814813, 0.046928327645051185]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.458632340786902\n",
      "current reward: 27.458632340786902; current state: [29.444444444444443, 4.54505227324742]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.67988395003155\n",
      "current reward: 27.67988395003155; current state: [23.0, 6.436438516989791]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 29.074817315836345\n",
      "current reward: 29.074817315836345; current state: [21.14814814814815, 2.3568726129771562]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.727839421079043\n",
      "current reward: 27.727839421079043; current state: [24.22222222222222, 10.308105355164995]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.06743496322497\n",
      "current reward: 28.06743496322497; current state: [26.666666666666668, 3.180133347910464]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 30.07284631530878\n",
      "current reward: 30.07284631530878; current state: [22.40740740740741, 6.3759404761085205]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.371217979821534\n",
      "current reward: 28.371217979821534; current state: [26.666666666666668, 8.170048337737184]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 28.509269612329934\n",
      "current reward: 28.509269612329934; current state: [29.11111111111111, 3.513453028780418]\n",
      "maximizing action\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 27.969243590640332\n",
      "current reward: 27.969243590640332; current state: [24.925925925925927, 8.741284545218344]\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "action_space= np.array([19, 22, 25, 28, 31, 33])\n",
    "try:\n",
    "    for i in range(1):#episodes\n",
    "        print(f\"episode: {i}\")\n",
    "        initial_states = env.reset()\n",
    "        #print(env.observation_space)\n",
    "        action_space_size = len(env.action_space)\n",
    "        #print(f\"action_space_size{action_space_size}\")\n",
    "        for t in range(1000):#time steps\n",
    "            state_grid= create_uniform_grid(env.observation_space.low, env.observation_space.high, bins= (400,400))\n",
    "            ql_agents = QLAgent.QLAgent(starting_state=initial_states,\n",
    "                                    state_space=env.observation_space,\n",
    "                                    state_grid = state_grid,\n",
    "                                    action_space=env.action_space,\n",
    "                                    alpha=0.2,\n",
    "                                    gamma=0.99,\n",
    "                                    exploration_strategy=EpsilonGreedy.EpsilonGreedy())\n",
    "\n",
    "            actions =ql_agents.act()\n",
    "            print(f\"act action : {actions}\")\n",
    "            s, r, done, _ = env.step(action=actions)\n",
    "            print(f\"current reward: {r}; current state: {s}\")\n",
    "            ql_agents.learn(next_state=s, reward=r)\n",
    "            if done:\n",
    "                break\n",
    "        env.close()\n",
    "except ValueError:\n",
    "    print(traceback.format_exc())\n",
    "    env.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88117a4c4f7db09762e85aecb2e581e7c8f40331f8439cb18f9752f946649d6e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
