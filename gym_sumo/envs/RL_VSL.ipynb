{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "<div style=\"text-align:center\">\n",
    "    <h1>\n",
    "        VSL RL : SUMO Simulation\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmae/opt/anaconda3/lib/python3.9/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('C:\\PHD\\Workspace\\gym_sumo_vsl_maroc\\gym_sumo\\envs')\n",
    "from utils import plot_policy, plot_action_values, test_agent\n",
    "import SUMOInitializeEnv\n",
    "import gym\n",
    "import sumo_env as env\n",
    "import ql_agent as QLAgent\n",
    "import epsilon_greedy as EpsilonGreedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register\n",
    "from SUMOInitializeEnv import SUMOEnv_Initializer\n",
    "register(\n",
    "    id='SumoGUI-v0',\n",
    "    entry_point='SUMOInitializeEnv:SUMOEnv_Initializer'\n",
    ")\n",
    "env = gym.make('SumoGUI-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_uniform_grid(low,high, bins=(500,500)):\n",
    "        grid= []\n",
    "        for i, lower_upper in enumerate(zip(low,high)):\n",
    "            grid_column= np.linspace(lower_upper[0], lower_upper[1], bins[i]+1)\n",
    "            grid.append(grid_column)\n",
    "        return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0\n",
      " Retrying in 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fontconfig warning: ignoring UTF-8: not a valid region tag\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (3, 3)\n",
      "act action : 19\n",
      "reward: 10.389203548198566\n",
      "current reward: 10.389203548198566; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 11.51216818364046\n",
      "current reward: 11.51216818364046; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[2.30243364 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 12.222546677209516\n",
      "current reward: 12.222546677209516; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[4.74694297 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 13.113275022280481\n",
      "current reward: 13.113275022280481; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[7.36959798 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 14.127060574863185\n",
      "current reward: 14.127060574863185; current state: [2.0, 0.0028441410693970416]\n",
      "maximizing action\n",
      "[10.19501009  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (11, 3)\n",
      "act action : 19\n",
      "reward: 12.265729768822332\n",
      "current reward: 12.265729768822332; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (15, 3)\n",
      "act action : 19\n",
      "reward: 13.316097027691754\n",
      "current reward: 13.316097027691754; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "[2.66321941 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (15, 3)\n",
      "act action : 19\n",
      "reward: 14.097938080038617\n",
      "current reward: 14.097938080038617; current state: [3.0, 0.004266211604095562]\n",
      "maximizing action\n",
      "[5.48280702 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (15, 3)\n",
      "act action : 19\n",
      "reward: 13.49361751412223\n",
      "current reward: 13.49361751412223; current state: [5.0, 0.007110352673492606]\n",
      "exploring action\n",
      "Current action = 33, current state (23, 3)\n",
      "act action : 33\n",
      "reward: 14.427969039484813\n",
      "current reward: 14.427969039484813; current state: [5.0, 0.007110352673492606]\n",
      "maximizing action\n",
      "[0.         0.         0.         0.         0.         2.88559381]\n",
      "Current action = 33, current state (23, 3)\n",
      "act action : 33\n",
      "reward: 13.53392532603281\n",
      "current reward: 13.53392532603281; current state: [6.0, 0.008532423208191125]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (27, 3)\n",
      "act action : 19\n",
      "reward: 14.257399125871911\n",
      "current reward: 14.257399125871911; current state: [6.0, 0.008532423208191125]\n",
      "maximizing action\n",
      "[2.85147983 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (27, 3)\n",
      "act action : 19\n",
      "reward: 14.618630045377737\n",
      "current reward: 14.618630045377737; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (31, 3)\n",
      "act action : 19\n",
      "reward: 15.558483494415015\n",
      "current reward: 15.558483494415015; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "[3.1116967 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (31, 3)\n",
      "act action : 19\n",
      "reward: 16.240860643986238\n",
      "current reward: 16.240860643986238; current state: [7.0, 0.009954493742889647]\n",
      "maximizing action\n",
      "[6.35986883 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (31, 3)\n",
      "act action : 19\n",
      "reward: 17.271838864675757\n",
      "current reward: 17.271838864675757; current state: [8.0, 0.011376564277588166]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (35, 3)\n",
      "act action : 19\n",
      "reward: 17.99805312109114\n",
      "current reward: 17.99805312109114; current state: [8.0, 0.011376564277588166]\n",
      "maximizing action\n",
      "[3.59961062 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (35, 3)\n",
      "act action : 19\n",
      "reward: 17.886619866266997\n",
      "current reward: 17.886619866266997; current state: [8.407407407407407, 1.4078617793508275]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (35, 7)\n",
      "act action : 19\n",
      "reward: 18.76981625268779\n",
      "current reward: 18.76981625268779; current state: [8.407407407407407, 0.012798634812286692]\n",
      "maximizing action\n",
      "[7.1769346 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (35, 3)\n",
      "act action : 19\n",
      "reward: 19.455985537593094\n",
      "current reward: 19.455985537593094; current state: [8.703703703703704, 1.8878402992819714]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (37, 9)\n",
      "act action : 19\n",
      "reward: 18.844329551035884\n",
      "current reward: 18.844329551035884; current state: [9.666666666666666, 1.7970456039055906]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (41, 9)\n",
      "act action : 19\n",
      "reward: 19.82112357828661\n",
      "current reward: 19.82112357828661; current state: [9.0, 4.235285518948025]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (39, 19)\n",
      "act action : 19\n",
      "reward: 19.873471623980723\n",
      "current reward: 19.873471623980723; current state: [10.62962962962963, 0.09764991064036666]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (45, 3)\n",
      "act action : 19\n",
      "reward: 20.843109269114194\n",
      "current reward: 20.843109269114194; current state: [10.62962962962963, 0.01564277588168373]\n",
      "maximizing action\n",
      "[4.16862185 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (45, 3)\n",
      "act action : 19\n",
      "reward: 21.944229912113645\n",
      "current reward: 21.944229912113645; current state: [12.0, 0.01706484641638225]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (51, 3)\n",
      "act action : 19\n",
      "reward: 22.776924013926514\n",
      "current reward: 22.776924013926514; current state: [12.0, 0.01706484641638225]\n",
      "maximizing action\n",
      "[4.5553848 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (51, 3)\n",
      "act action : 19\n",
      "reward: 23.64126624276518\n",
      "current reward: 23.64126624276518; current state: [11.185185185185185, 1.780235846028353]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (47, 9)\n",
      "act action : 19\n",
      "reward: 23.621078238093176\n",
      "current reward: 23.621078238093176; current state: [12.11111111111111, 0.018486916951080776]\n",
      "maximizing action\n",
      "[9.28363805 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (51, 3)\n",
      "act action : 19\n",
      "reward: 24.420622145740243\n",
      "current reward: 24.420622145740243; current state: [13.0, 0.018486916951080776]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (55, 3)\n",
      "act action : 19\n",
      "reward: 24.02063610703973\n",
      "current reward: 24.02063610703973; current state: [12.555555555555555, 5.414706363502371]\n",
      "exploring action\n",
      "Current action = 19, current state (53, 23)\n",
      "act action : 19\n",
      "reward: 24.856503025106765\n",
      "current reward: 24.856503025106765; current state: [14.0, 0.019908987485779295]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (59, 3)\n",
      "act action : 19\n",
      "reward: 25.60149346875755\n",
      "current reward: 25.60149346875755; current state: [13.518518518518519, 2.0252091798833027]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (57, 11)\n",
      "act action : 19\n",
      "reward: 26.45799764381623\n",
      "current reward: 26.45799764381623; current state: [13.962962962962964, 3.31371008556634]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (57, 15)\n",
      "act action : 19\n",
      "reward: 29.09850616209177\n",
      "current reward: 29.09850616209177; current state: [14.481481481481481, 0.021331058020477817]\n",
      "maximizing action\n",
      "[5.12029869 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (59, 3)\n",
      "act action : 19\n",
      "reward: 26.35003439698981\n",
      "current reward: 26.35003439698981; current state: [15.444444444444445, 2.0844325963533183]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (63, 11)\n",
      "act action : 19\n",
      "reward: 26.850288835053007\n",
      "current reward: 26.850288835053007; current state: [13.222222222222221, 8.954141781381455]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (55, 37)\n",
      "act action : 19\n",
      "reward: 26.13493213433144\n",
      "current reward: 26.13493213433144; current state: [15.814814814814815, 0.02417519908987486]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (65, 3)\n",
      "act action : 19\n",
      "reward: 26.460628784992966\n",
      "current reward: 26.460628784992966; current state: [16.40740740740741, 1.6424112861083968]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (67, 9)\n",
      "act action : 19\n",
      "reward: 26.827184847419215\n",
      "current reward: 26.827184847419215; current state: [15.814814814814815, 1.6878915163867687]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (65, 9)\n",
      "act action : 19\n",
      "reward: 25.983333305727836\n",
      "current reward: 25.983333305727836; current state: [16.74074074074074, 4.169608907749711]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (69, 19)\n",
      "act action : 19\n",
      "reward: 26.334696541608114\n",
      "current reward: 26.334696541608114; current state: [17.37037037037037, 0.7061972405460869]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (71, 5)\n",
      "act action : 19\n",
      "reward: 25.26539018359806\n",
      "current reward: 25.26539018359806; current state: [18.333333333333332, 0.027019340159271897]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (75, 3)\n",
      "act action : 19\n",
      "reward: 25.66546711040804\n",
      "current reward: 25.66546711040804; current state: [16.333333333333332, 7.057695977585581]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (67, 31)\n",
      "act action : 19\n",
      "reward: 28.19402343958018\n",
      "current reward: 28.19402343958018; current state: [17.666666666666668, 0.1259476142120884]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (73, 3)\n",
      "act action : 19\n",
      "reward: 25.240311285545754\n",
      "current reward: 25.240311285545754; current state: [16.48148148148148, 7.156697387592193]\n",
      "maximizing action\n",
      "[5.63880469 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (67, 31)\n",
      "act action : 19\n",
      "reward: 25.603536162941907\n",
      "current reward: 25.603536162941907; current state: [19.296296296296298, 1.142030585112415]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (79, 7)\n",
      "act action : 19\n",
      "reward: 24.746701306659862\n",
      "current reward: 24.746701306659862; current state: [19.51851851851852, 2.161626869363563]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (81, 11)\n",
      "act action : 19\n",
      "reward: 27.464869496614586\n",
      "current reward: 27.464869496614586; current state: [18.77777777777778, 2.526169797463802]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 13)\n",
      "act action : 19\n",
      "reward: 27.082144170777113\n",
      "current reward: 27.082144170777113; current state: [18.88888888888889, 4.488097600593049]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 19)\n",
      "act action : 19\n",
      "reward: 24.717163377368408\n",
      "current reward: 24.717163377368408; current state: [21.22222222222222, 1.8976960182910918]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 9)\n",
      "act action : 19\n",
      "reward: 27.54828802880417\n",
      "current reward: 27.54828802880417; current state: [22.0, 0.03128555176336746]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 3)\n",
      "act action : 19\n",
      "reward: 24.328010039836744\n",
      "current reward: 24.328010039836744; current state: [19.74074074074074, 5.335214519554997]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (81, 23)\n",
      "act action : 19\n",
      "reward: 26.281984942415235\n",
      "current reward: 26.281984942415235; current state: [18.925925925925927, 1.8726466635160774]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 9)\n",
      "act action : 19\n",
      "reward: 25.044012635517003\n",
      "current reward: 25.044012635517003; current state: [20.555555555555557, 5.637061094296185]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 25)\n",
      "act action : 19\n",
      "reward: 25.842914900462976\n",
      "current reward: 25.842914900462976; current state: [22.296296296296298, 1.2123678595787286]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 7)\n",
      "act action : 19\n",
      "reward: 25.05377739817774\n",
      "current reward: 25.05377739817774; current state: [21.444444444444443, 2.159925407901785]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 11)\n",
      "act action : 19\n",
      "reward: 27.401262047177443\n",
      "current reward: 27.401262047177443; current state: [24.11111111111111, 1.7096719187033882]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 9)\n",
      "act action : 19\n",
      "reward: 25.390127219771482\n",
      "current reward: 25.390127219771482; current state: [23.22222222222222, 3.0528967601640016]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 15)\n",
      "act action : 19\n",
      "reward: 25.15345893158329\n",
      "current reward: 25.15345893158329; current state: [23.22222222222222, 3.4313851312989976]\n",
      "maximizing action\n",
      "[5.03069179 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 15)\n",
      "act action : 19\n",
      "reward: 26.676614839534224\n",
      "current reward: 26.676614839534224; current state: [25.074074074074073, 0.036973833902161544]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 3)\n",
      "act action : 19\n",
      "reward: 25.306375751372343\n",
      "current reward: 25.306375751372343; current state: [25.074074074074073, 4.172806298722118]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 27.84892960737875\n",
      "current reward: 27.84892960737875; current state: [25.074074074074073, 1.303260461147525]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 7)\n",
      "act action : 19\n",
      "reward: 25.964426331952335\n",
      "current reward: 25.964426331952335; current state: [23.14814814814815, 5.564274996750149]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 25)\n",
      "act action : 19\n",
      "reward: 27.852535209140594\n",
      "current reward: 27.852535209140594; current state: [26.0, 2.849681670473]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 13)\n",
      "act action : 19\n",
      "reward: 27.21487484950312\n",
      "current reward: 27.21487484950312; current state: [24.0, 3.4108715119100426]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 15)\n",
      "act action : 19\n",
      "reward: 25.91498858969047\n",
      "current reward: 25.91498858969047; current state: [25.88888888888889, 3.919547894032715]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 26.162637623206212\n",
      "current reward: 26.162637623206212; current state: [27.962962962962962, 0.041240045506257116]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 3)\n",
      "act action : 19\n",
      "reward: 26.53331151249797\n",
      "current reward: 26.53331151249797; current state: [26.925925925925927, 4.067174647504422]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 26.460088350579138\n",
      "current reward: 26.460088350579138; current state: [28.925925925925927, 0.18466367572656292]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 3)\n",
      "act action : 19\n",
      "reward: 26.847052512922446\n",
      "current reward: 26.847052512922446; current state: [26.77777777777778, 3.077810927146522]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 15)\n",
      "act action : 19\n",
      "reward: 28.323770660714626\n",
      "current reward: 28.323770660714626; current state: [26.555555555555557, 2.729116545022166]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 13)\n",
      "act action : 19\n",
      "reward: 26.923965764979922\n",
      "current reward: 26.923965764979922; current state: [29.88888888888889, 0.04408418657565414]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 3)\n",
      "act action : 19\n",
      "reward: 26.594868206546977\n",
      "current reward: 26.594868206546977; current state: [26.25925925925926, 10.7116873399473]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 45)\n",
      "act action : 19\n",
      "reward: 27.04413156004506\n",
      "current reward: 27.04413156004506; current state: [28.555555555555557, 2.0372590176419028]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 27.18291998791392\n",
      "current reward: 27.18291998791392; current state: [28.77777777777778, 2.4693363360760143]\n",
      "maximizing action\n",
      "[5.436584 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 26.88234101424224\n",
      "current reward: 26.88234101424224; current state: [22.814814814814813, 12.156108005792158]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (93, 51)\n",
      "act action : 19\n",
      "reward: 29.051147394729345\n",
      "current reward: 29.051147394729345; current state: [23.962962962962962, 0.6298051609554386]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 5)\n",
      "act action : 19\n",
      "reward: 27.429787285128672\n",
      "current reward: 27.429787285128672; current state: [28.25925925925926, 0.5719236476315492]\n",
      "exploring action\n",
      "Current action = 28, current state (115, 5)\n",
      "act action : 28\n",
      "reward: 28.26587720639094\n",
      "current reward: 28.26587720639094; current state: [29.444444444444443, 0.13580601083354812]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 3)\n",
      "act action : 19\n",
      "reward: 28.104095062830883\n",
      "current reward: 28.104095062830883; current state: [23.51851851851852, 7.574709980849917]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 33)\n",
      "act action : 19\n",
      "reward: 27.902175271523877\n",
      "current reward: 27.902175271523877; current state: [27.925925925925927, 3.7502633463953146]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 28.155527422006106\n",
      "current reward: 28.155527422006106; current state: [30.333333333333332, 2.201792899768551]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 29.28131828710436\n",
      "current reward: 29.28131828710436; current state: [32.48148148148148, 3.434620528056761]\n",
      "exploring action\n",
      "Current action = 22, current state (131, 15)\n",
      "act action : 22\n",
      "reward: 28.041219862111763\n",
      "current reward: 28.041219862111763; current state: [31.22222222222222, 1.666576356021896]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 9)\n",
      "act action : 19\n",
      "reward: 28.292853015458167\n",
      "current reward: 28.292853015458167; current state: [31.22222222222222, 6.410968669449234]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 27)\n",
      "act action : 19\n",
      "reward: 29.476304823778587\n",
      "current reward: 29.476304823778587; current state: [28.703703703703702, 6.613835176431424]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 28.19710501968608\n",
      "current reward: 28.19710501968608; current state: [28.703703703703702, 4.862607681940675]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 27.966437228381604\n",
      "current reward: 27.966437228381604; current state: [29.51851851851852, 4.904237199253009]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 28.12872123378033\n",
      "current reward: 28.12872123378033; current state: [28.703703703703702, 4.383110680245376]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 28.841897718383155\n",
      "current reward: 28.841897718383155; current state: [27.444444444444443, 5.8404349063228675]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 27.986280887859493\n",
      "current reward: 27.986280887859493; current state: [31.22222222222222, 0.5792616944362075]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 5)\n",
      "act action : 19\n",
      "reward: 29.20115091649735\n",
      "current reward: 29.20115091649735; current state: [26.666666666666668, 6.879249928199345]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 29.21168780322559\n",
      "current reward: 29.21168780322559; current state: [29.962962962962962, 3.5785449649459604]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 27.90981781490409\n",
      "current reward: 27.90981781490409; current state: [32.48148148148148, 3.257955239460339]\n",
      "maximizing action\n",
      "[0.         5.60824397 0.         0.         0.         0.        ]\n",
      "Current action = 22, current state (131, 15)\n",
      "act action : 22\n",
      "reward: 28.802036550151254\n",
      "current reward: 28.802036550151254; current state: [28.22222222222222, 7.854252388953729]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 33)\n",
      "act action : 19\n",
      "reward: 27.83348860192378\n",
      "current reward: 27.83348860192378; current state: [30.814814814814813, 0.9553191106829063]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 5)\n",
      "act action : 19\n",
      "reward: 28.537567028697126\n",
      "current reward: 28.537567028697126; current state: [30.333333333333332, 5.298795363161728]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 23)\n",
      "act action : 19\n",
      "reward: 29.048895238807358\n",
      "current reward: 29.048895238807358; current state: [29.51851851851852, 4.794293952629664]\n",
      "maximizing action\n",
      "[5.62574425 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 29.29242614121905\n",
      "current reward: 29.29242614121905; current state: [30.814814814814813, 7.273673807888507]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 31)\n",
      "act action : 19\n",
      "reward: 29.043456319972503\n",
      "current reward: 29.043456319972503; current state: [29.0, 5.681593269943704]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 25)\n",
      "act action : 19\n",
      "reward: 27.91437273354639\n",
      "current reward: 27.91437273354639; current state: [27.666666666666668, 3.4122685804237793]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 15)\n",
      "act action : 19\n",
      "reward: 27.639913614802808\n",
      "current reward: 27.639913614802808; current state: [29.0, 4.87431402012845]\n",
      "exploring action\n",
      "Current action = 25, current state (119, 21)\n",
      "act action : 25\n",
      "reward: 29.298603589389415\n",
      "current reward: 29.298603589389415; current state: [25.62962962962963, 8.519123189829925]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 37)\n",
      "act action : 19\n",
      "reward: 28.05040867969124\n",
      "current reward: 28.05040867969124; current state: [29.962962962962962, 1.3873267739888095]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 7)\n",
      "act action : 19\n",
      "reward: 28.009218418067174\n",
      "current reward: 28.009218418067174; current state: [28.22222222222222, 5.351071436588368]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 23)\n",
      "act action : 19\n",
      "reward: 28.851347682349594\n",
      "current reward: 28.851347682349594; current state: [27.444444444444443, 8.383691740943839]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 28.269799563247982\n",
      "current reward: 28.269799563247982; current state: [34.7037037037037, 1.699504183018535]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (141, 9)\n",
      "act action : 19\n",
      "reward: 29.056123433043485\n",
      "current reward: 29.056123433043485; current state: [28.25925925925926, 7.365316786814565]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 31)\n",
      "act action : 19\n",
      "reward: 28.306377329163066\n",
      "current reward: 28.306377329163066; current state: [29.11111111111111, 3.2779582435785466]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 28.519428718143576\n",
      "current reward: 28.519428718143576; current state: [25.88888888888889, 5.11897374325391]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 29.609636178439597\n",
      "current reward: 29.609636178439597; current state: [28.25925925925926, 4.582899280944237]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 28.531908787579084\n",
      "current reward: 28.531908787579084; current state: [27.88888888888889, 3.817601733820343]\n",
      "maximizing action\n",
      "[5.63110548 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 28.785470038918913\n",
      "current reward: 28.785470038918913; current state: [23.0, 9.345264291503835]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 39)\n",
      "act action : 19\n",
      "reward: 29.081451697657158\n",
      "current reward: 29.081451697657158; current state: [25.444444444444443, 4.610530470090209]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 30.1893942387766\n",
      "current reward: 30.1893942387766; current state: [25.444444444444443, 5.4913838827348735]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 29.167861420423495\n",
      "current reward: 29.167861420423495; current state: [23.0, 8.938130519924]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 37)\n",
      "act action : 19\n",
      "reward: 29.033057276454468\n",
      "current reward: 29.033057276454468; current state: [29.962962962962962, 2.971476009350164]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 29.159194576076402\n",
      "current reward: 29.159194576076402; current state: [27.88888888888889, 4.331325874729173]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 29.500162406398484\n",
      "current reward: 29.500162406398484; current state: [29.962962962962962, 5.831127237199384]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 29.567078849251683\n",
      "current reward: 29.567078849251683; current state: [28.703703703703702, 3.7635320920741475]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 29.877522846143165\n",
      "current reward: 29.877522846143165; current state: [32.111111111111114, 2.09355968617042]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 29.875887667193638\n",
      "current reward: 29.875887667193638; current state: [24.333333333333332, 10.403989053074971]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 43)\n",
      "act action : 19\n",
      "reward: 30.240013883267164\n",
      "current reward: 30.240013883267164; current state: [28.22222222222222, 4.339401552718633]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 30.117472131781543\n",
      "current reward: 30.117472131781543; current state: [26.185185185185187, 11.108253820486151]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 47)\n",
      "act action : 19\n",
      "reward: 30.480172384376264\n",
      "current reward: 30.480172384376264; current state: [29.962962962962962, 4.833892060664065]\n",
      "maximizing action\n",
      "[11.48422947  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 30.895434515047356\n",
      "current reward: 30.895434515047356; current state: [33.407407407407405, 2.1585466347526125]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 11)\n",
      "act action : 19\n",
      "reward: 29.98400419474868\n",
      "current reward: 29.98400419474868; current state: [32.48148148148148, 2.8126715236230044]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 13)\n",
      "act action : 19\n",
      "reward: 31.394510373581824\n",
      "current reward: 31.394510373581824; current state: [23.666666666666668, 12.793428089338557]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 53)\n",
      "act action : 19\n",
      "reward: 30.21947657663388\n",
      "current reward: 30.21947657663388; current state: [29.51851851851852, 2.1795770505397893]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 30.409578066183524\n",
      "current reward: 30.409578066183524; current state: [34.7037037037037, 0.05119453924914677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (141, 3)\n",
      "act action : 19\n",
      "reward: 30.49726565446006\n",
      "current reward: 30.49726565446006; current state: [27.666666666666668, 10.73480321299038]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 45)\n",
      "act action : 19\n",
      "reward: 30.177734596791044\n",
      "current reward: 30.177734596791044; current state: [25.0, 2.0354893933762925]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 11)\n",
      "act action : 19\n",
      "reward: 30.196916142359772\n",
      "current reward: 30.196916142359772; current state: [26.333333333333332, 6.425383440813585]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 30.226944947256353\n",
      "current reward: 30.226944947256353; current state: [25.0, 8.88296239292608]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 37)\n",
      "act action : 19\n",
      "reward: 29.98991463648592\n",
      "current reward: 29.98991463648592; current state: [23.666666666666668, 8.023540578950362]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 35)\n",
      "act action : 19\n",
      "reward: 29.700638351652106\n",
      "current reward: 29.700638351652106; current state: [29.51851851851852, 4.910635825292731]\n",
      "maximizing action\n",
      "[17.66331638  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 29.64944317015559\n",
      "current reward: 29.64944317015559; current state: [32.48148148148148, 0.049772468714448244]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 3)\n",
      "act action : 19\n",
      "reward: 28.674568715575543\n",
      "current reward: 28.674568715575543; current state: [30.814814814814813, 5.508661034844101]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 29.296409027148872\n",
      "current reward: 29.296409027148872; current state: [28.703703703703702, 3.4407300061303596]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 15)\n",
      "act action : 19\n",
      "reward: 30.305698042702016\n",
      "current reward: 30.305698042702016; current state: [27.88888888888889, 3.6011325987167773]\n",
      "maximizing action\n",
      "[11.38819949  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 29.198775921478035\n",
      "current reward: 29.198775921478035; current state: [26.666666666666668, 4.684195830391015]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 21)\n",
      "act action : 19\n",
      "reward: 29.31886067044739\n",
      "current reward: 29.31886067044739; current state: [29.11111111111111, 4.3599908010713]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 29.928635867375217\n",
      "current reward: 29.928635867375217; current state: [27.88888888888889, 8.394285353667286]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 35)\n",
      "act action : 19\n",
      "reward: 29.268717087396812\n",
      "current reward: 29.268717087396812; current state: [31.555555555555557, 1.338864273757541]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 7)\n",
      "act action : 19\n",
      "reward: 28.96059561867948\n",
      "current reward: 28.96059561867948; current state: [29.11111111111111, 5.428299191927016]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 23)\n",
      "act action : 19\n",
      "reward: 29.044279568666017\n",
      "current reward: 29.044279568666017; current state: [24.22222222222222, 12.517579220400936]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 53)\n",
      "act action : 19\n",
      "reward: 29.25671585255553\n",
      "current reward: 29.25671585255553; current state: [27.88888888888889, 1.9758668878007695]\n",
      "exploring action\n",
      "Current action = 31, current state (113, 9)\n",
      "act action : 31\n",
      "reward: 29.62138535835878\n",
      "current reward: 29.62138535835878; current state: [24.925925925925927, 6.8812216946026314]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 29)\n",
      "act action : 19\n",
      "reward: 29.731920530630422\n",
      "current reward: 29.731920530630422; current state: [27.444444444444443, 1.722201557005622]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 9)\n",
      "act action : 19\n",
      "reward: 29.78507362411523\n",
      "current reward: 29.78507362411523; current state: [28.22222222222222, 4.897636402518999]\n",
      "maximizing action\n",
      "[5.70638176 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 29.992381319089485\n",
      "current reward: 29.992381319089485; current state: [29.962962962962962, 4.858064660677074]\n",
      "maximizing action\n",
      "[23.59320501  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 29.79438419152878\n",
      "current reward: 29.79438419152878; current state: [25.444444444444443, 12.710671453406563]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 53)\n",
      "act action : 19\n",
      "reward: 29.939427619745043\n",
      "current reward: 29.939427619745043; current state: [29.962962962962962, 2.3944123010725495]\n",
      "maximizing action\n",
      "[6.08191561 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 29.64898264377634\n",
      "current reward: 29.64898264377634; current state: [29.11111111111111, 6.896447932486432]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 29.301865782355137\n",
      "current reward: 29.301865782355137; current state: [26.185185185185187, 8.492279787048435]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 29.948907530003368\n",
      "current reward: 29.948907530003368; current state: [31.22222222222222, 0.3579446912755531]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 3)\n",
      "act action : 19\n",
      "reward: 28.808759147744436\n",
      "current reward: 28.808759147744436; current state: [28.703703703703702, 6.317138644046952]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 27)\n",
      "act action : 19\n",
      "reward: 29.035991638964003\n",
      "current reward: 29.035991638964003; current state: [24.925925925925927, 11.55726566906977]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 49)\n",
      "act action : 19\n",
      "reward: 29.240850775484088\n",
      "current reward: 29.240850775484088; current state: [26.185185185185187, 6.260975180495268]\n",
      "maximizing action\n",
      "[6.04538899 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 30.080688245931857\n",
      "current reward: 30.080688245931857; current state: [27.444444444444443, 5.883395199871644]\n",
      "maximizing action\n",
      "[5.59725618 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 29.157210285311248\n",
      "current reward: 29.157210285311248; current state: [29.962962962962962, 5.809769070164923]\n",
      "exploring action\n",
      "Current action = 25, current state (121, 25)\n",
      "act action : 25\n",
      "reward: 28.675883794901754\n",
      "current reward: 28.675883794901754; current state: [33.407407407407405, 1.1663110374487353]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 7)\n",
      "act action : 19\n",
      "reward: 28.781839418625882\n",
      "current reward: 28.781839418625882; current state: [30.814814814814813, 5.988599084603537]\n",
      "maximizing action\n",
      "[5.85928181 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 28.880241434356673\n",
      "current reward: 28.880241434356673; current state: [29.962962962962962, 5.680701447824657]\n",
      "maximizing action\n",
      "[5.91341577 0.         5.73517676 0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 30.051133648998103\n",
      "current reward: 30.051133648998103; current state: [29.962962962962962, 6.257614469527709]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 28.831106618874543\n",
      "current reward: 28.831106618874543; current state: [27.444444444444443, 7.026066520572236]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 28.079784515606477\n",
      "current reward: 28.079784515606477; current state: [29.962962962962962, 3.9018576749915166]\n",
      "maximizing action\n",
      "[5.58196356 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.55250268073067\n",
      "current reward: 29.55250268073067; current state: [27.88888888888889, 3.9087261465278127]\n",
      "maximizing action\n",
      "[17.22795468  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 27.969334482408424\n",
      "current reward: 27.969334482408424; current state: [21.14814814814815, 10.527133295635904]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 45)\n",
      "act action : 19\n",
      "reward: 29.48896797288521\n",
      "current reward: 29.48896797288521; current state: [18.77777777777778, 9.006091296758703]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (77, 39)\n",
      "act action : 19\n",
      "reward: 29.656043718923247\n",
      "current reward: 29.656043718923247; current state: [25.88888888888889, 5.709251831930525]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 27.75977096034673\n",
      "current reward: 27.75977096034673; current state: [29.11111111111111, 4.183839292859277]\n",
      "maximizing action\n",
      "[5.98572717 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 27.870421957420586\n",
      "current reward: 27.870421957420586; current state: [29.11111111111111, 6.658625190119041]\n",
      "maximizing action\n",
      "[5.86037316 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 28.560339494979306\n",
      "current reward: 28.560339494979306; current state: [31.22222222222222, 3.10164212803601]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 15)\n",
      "act action : 19\n",
      "reward: 29.312415413915392\n",
      "current reward: 29.312415413915392; current state: [27.444444444444443, 4.148220102090569]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 27.9340459932569\n",
      "current reward: 27.9340459932569; current state: [26.185185185185187, 5.212769132221813]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 27.380519654390653\n",
      "current reward: 27.380519654390653; current state: [29.51851851851852, 6.048979552555196]\n",
      "maximizing action\n",
      "[5.76622132 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 29.165978258022392\n",
      "current reward: 29.165978258022392; current state: [28.703703703703702, 4.643480452147348]\n",
      "maximizing action\n",
      "[5.59328745 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 29.42039179828745\n",
      "current reward: 29.42039179828745; current state: [27.444444444444443, 5.968576981731009]\n",
      "maximizing action\n",
      "[11.42869823  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.034528150458254\n",
      "current reward: 28.034528150458254; current state: [27.444444444444443, 4.620616545204188]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 29.33458215406779\n",
      "current reward: 29.33458215406779; current state: [24.925925925925927, 7.571504928390666]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 33)\n",
      "act action : 19\n",
      "reward: 27.58458369385578\n",
      "current reward: 27.58458369385578; current state: [26.925925925925927, 4.367712374249987]\n",
      "maximizing action\n",
      "[5.29201767 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 27.75767197204395\n",
      "current reward: 27.75767197204395; current state: [26.925925925925927, 7.537849010717896]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 27.472766866814677\n",
      "current reward: 27.472766866814677; current state: [26.925925925925927, 6.8036556592307065]\n",
      "maximizing action\n",
      "[5.84233756 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 27.543980171786416\n",
      "current reward: 27.543980171786416; current state: [29.962962962962962, 2.3204920069017994]\n",
      "exploring action\n",
      "Current action = 33, current state (121, 11)\n",
      "act action : 33\n",
      "reward: 27.188204555192353\n",
      "current reward: 27.188204555192353; current state: [29.962962962962962, 3.0709390370117413]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 15)\n",
      "act action : 19\n",
      "reward: 27.391239460185535\n",
      "current reward: 27.391239460185535; current state: [25.444444444444443, 5.331376534161217]\n",
      "maximizing action\n",
      "[5.83357228 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 28.20613588669519\n",
      "current reward: 28.20613588669519; current state: [29.11111111111111, 1.7207620463483067]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 27.952542029760792\n",
      "current reward: 27.952542029760792; current state: [26.185185185185187, 5.514197939163245]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 27.987656028296303\n",
      "current reward: 27.987656028296303; current state: [26.666666666666668, 2.2784719500536736]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 11)\n",
      "act action : 19\n",
      "reward: 28.12886968650318\n",
      "current reward: 28.12886968650318; current state: [26.185185185185187, 7.524708367426747]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 27.666106611892342\n",
      "current reward: 27.666106611892342; current state: [26.666666666666668, 4.231675479739263]\n",
      "maximizing action\n",
      "[10.84355206  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 27.373362253618847\n",
      "current reward: 27.373362253618847; current state: [30.333333333333332, 2.5525297343307205]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 13)\n",
      "act action : 19\n",
      "reward: 28.47211299742483\n",
      "current reward: 28.47211299742483; current state: [24.22222222222222, 8.595300165053361]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 37)\n",
      "act action : 19\n",
      "reward: 27.74785382685819\n",
      "current reward: 27.74785382685819; current state: [21.666666666666668, 8.877031541786934]\n",
      "exploring action\n",
      "Current action = 25, current state (89, 37)\n",
      "act action : 25\n",
      "reward: 27.741031225444186\n",
      "current reward: 27.741031225444186; current state: [27.074074074074073, 4.456440710255477]\n",
      "maximizing action\n",
      "[5.5868092 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 28.019045143740087\n",
      "current reward: 28.019045143740087; current state: [28.25925925925926, 2.2873257145873085]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 11)\n",
      "act action : 19\n",
      "reward: 27.118374806187276\n",
      "current reward: 27.118374806187276; current state: [17.666666666666668, 21.273303916104314]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (73, 87)\n",
      "act action : 19\n",
      "reward: 27.420707845885477\n",
      "current reward: 27.420707845885477; current state: [18.77777777777778, 3.120027519970343]\n",
      "exploring action\n",
      "Current action = 31, current state (77, 15)\n",
      "act action : 31\n",
      "reward: 29.27543614342549\n",
      "current reward: 29.27543614342549; current state: [24.333333333333332, 3.156253310691054]\n",
      "maximizing action\n",
      "[5.18299772 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 15)\n",
      "act action : 19\n",
      "reward: 27.76198542160611\n",
      "current reward: 27.76198542160611; current state: [23.22222222222222, 5.833384572443125]\n",
      "maximizing action\n",
      "[5.57050704 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 25)\n",
      "act action : 19\n",
      "reward: 29.370730871855674\n",
      "current reward: 29.370730871855674; current state: [25.444444444444443, 4.0478495265800705]\n",
      "maximizing action\n",
      "[5.5414504 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 27.309636856743555\n",
      "current reward: 27.309636856743555; current state: [26.25925925925926, 9.34083696836054]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 39)\n",
      "act action : 19\n",
      "reward: 27.597021306965882\n",
      "current reward: 27.597021306965882; current state: [26.25925925925926, 1.447764899981378]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 7)\n",
      "act action : 19\n",
      "reward: 27.905740836004313\n",
      "current reward: 27.905740836004313; current state: [26.25925925925926, 4.251493701555762]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 19)\n",
      "act action : 19\n",
      "reward: 27.245029962633637\n",
      "current reward: 27.245029962633637; current state: [23.962962962962962, 13.35516592149442]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 55)\n",
      "act action : 19\n",
      "reward: 27.543294427525183\n",
      "current reward: 27.543294427525183; current state: [28.555555555555557, 0.045506257110352666]\n",
      "maximizing action\n",
      "[5.3694105 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (117, 3)\n",
      "act action : 19\n",
      "reward: 29.788943575392747\n",
      "current reward: 29.788943575392747; current state: [27.074074074074073, 7.345385543488939]\n",
      "maximizing action\n",
      "[5.6159569 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 27.501975160889828\n",
      "current reward: 27.501975160889828; current state: [20.51851851851852, 12.429205194229427]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 51)\n",
      "act action : 19\n",
      "reward: 27.195361825761648\n",
      "current reward: 27.195361825761648; current state: [24.703703703703702, 6.467477257550808]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 27)\n",
      "act action : 19\n",
      "reward: 27.599043159476565\n",
      "current reward: 27.599043159476565; current state: [27.40740740740741, 2.5822967645832993]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 13)\n",
      "act action : 19\n",
      "reward: 27.307883956281774\n",
      "current reward: 27.307883956281774; current state: [23.22222222222222, 11.468914085232225]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 47)\n",
      "act action : 19\n",
      "reward: 29.631944442683295\n",
      "current reward: 29.631944442683295; current state: [25.11111111111111, 4.185428938638434]\n",
      "maximizing action\n",
      "[11.00337777  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 27.203733914635524\n",
      "current reward: 27.203733914635524; current state: [27.40740740740741, 0.687504928090741]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 5)\n",
      "act action : 19\n",
      "reward: 26.5661914714924\n",
      "current reward: 26.5661914714924; current state: [28.25925925925926, 5.002347403550447]\n",
      "maximizing action\n",
      "[5.77026954 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 23)\n",
      "act action : 19\n",
      "reward: 26.62129721498951\n",
      "current reward: 26.62129721498951; current state: [27.40740740740741, 3.0448196560911533]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 28.443962677199398\n",
      "current reward: 28.443962677199398; current state: [27.074074074074073, 5.9811883092921425]\n",
      "maximizing action\n",
      "[17.03560386  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 26.50678374214895\n",
      "current reward: 26.50678374214895; current state: [27.40740740740741, 6.768681392857159]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 26.62580205294039\n",
      "current reward: 26.62580205294039; current state: [21.0, 11.44522603085346]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 47)\n",
      "act action : 19\n",
      "reward: 26.136378828922673\n",
      "current reward: 26.136378828922673; current state: [24.333333333333332, 2.176048862108236]\n",
      "exploring action\n",
      "Current action = 22, current state (99, 11)\n",
      "act action : 22\n",
      "reward: 28.45669080751284\n",
      "current reward: 28.45669080751284; current state: [24.333333333333332, 10.248092190421913]\n",
      "maximizing action\n",
      "[6.04800278 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 43)\n",
      "act action : 19\n",
      "reward: 25.809350556519508\n",
      "current reward: 25.809350556519508; current state: [26.25925925925926, 5.679548197354534]\n",
      "maximizing action\n",
      "[5.59753121 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 25.886483902250248\n",
      "current reward: 25.886483902250248; current state: [25.444444444444443, 7.093893861721513]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 31)\n",
      "act action : 19\n",
      "reward: 26.172639339409518\n",
      "current reward: 26.172639339409518; current state: [23.22222222222222, 8.584175882834415]\n",
      "maximizing action\n",
      "[5.80661146 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 37)\n",
      "act action : 19\n",
      "reward: 27.158519954897315\n",
      "current reward: 27.158519954897315; current state: [25.11111111111111, 2.048763801092176]\n",
      "maximizing action\n",
      "[6.03938323 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 11)\n",
      "act action : 19\n",
      "reward: 26.42679211283198\n",
      "current reward: 26.42679211283198; current state: [21.666666666666668, 8.113127919566478]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 35)\n",
      "act action : 19\n",
      "reward: 27.14683526653758\n",
      "current reward: 27.14683526653758; current state: [25.88888888888889, 5.6227405709803655]\n",
      "maximizing action\n",
      "[5.55195419 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 27.1236850777718\n",
      "current reward: 27.1236850777718; current state: [29.444444444444443, 0.09724653831818493]\n",
      "maximizing action\n",
      "[5.62081901 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 3)\n",
      "act action : 19\n",
      "reward: 26.52458691219689\n",
      "current reward: 26.52458691219689; current state: [27.88888888888889, 6.319176821823652]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 26.809606472503006\n",
      "current reward: 26.809606472503006; current state: [25.444444444444443, 7.816473887850882]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 27.47255124367723\n",
      "current reward: 27.47255124367723; current state: [26.666666666666668, 7.191485402206378]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 26.895388781874846\n",
      "current reward: 26.895388781874846; current state: [26.666666666666668, 6.65648046482289]\n",
      "maximizing action\n",
      "[11.3511336  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 27.07584928891878\n",
      "current reward: 27.07584928891878; current state: [25.444444444444443, 8.394868922702383]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 27.76657513398476\n",
      "current reward: 27.76657513398476; current state: [24.925925925925927, 6.51213832558272]\n",
      "maximizing action\n",
      "[5.94638411 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 29)\n",
      "act action : 19\n",
      "reward: 27.080108765617656\n",
      "current reward: 27.080108765617656; current state: [26.666666666666668, 6.096947919899585]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 27.10707351455257\n",
      "current reward: 27.10707351455257; current state: [25.88888888888889, 8.260332334464207]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 35)\n",
      "act action : 19\n",
      "reward: 27.344276799338015\n",
      "current reward: 27.344276799338015; current state: [21.77777777777778, 4.379505538711274]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 19)\n",
      "act action : 19\n",
      "reward: 26.985928130219023\n",
      "current reward: 26.985928130219023; current state: [26.666666666666668, 5.505221142390121]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 26.738319410418427\n",
      "current reward: 26.738319410418427; current state: [29.962962962962962, 4.925023572469326]\n",
      "exploring action\n",
      "Current action = 22, current state (121, 21)\n",
      "act action : 22\n",
      "reward: 27.688670542329106\n",
      "current reward: 27.688670542329106; current state: [31.22222222222222, 4.176164349419788]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 19)\n",
      "act action : 19\n",
      "reward: 26.38809535276118\n",
      "current reward: 26.38809535276118; current state: [28.703703703703702, 6.218071485472895]\n",
      "maximizing action\n",
      "[5.80719833 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 27)\n",
      "act action : 19\n",
      "reward: 26.55457793881844\n",
      "current reward: 26.55457793881844; current state: [26.185185185185187, 5.439666595779471]\n",
      "maximizing action\n",
      "[5.47610393 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 26.572528309791746\n",
      "current reward: 26.572528309791746; current state: [25.444444444444443, 7.129488769323667]\n",
      "maximizing action\n",
      "[5.23452787 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 31)\n",
      "act action : 19\n",
      "reward: 27.427951396886556\n",
      "current reward: 27.427951396886556; current state: [26.185185185185187, 6.341172876988999]\n",
      "maximizing action\n",
      "[12.06152664  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 26.441353576531657\n",
      "current reward: 26.441353576531657; current state: [26.185185185185187, 5.018748333024893]\n",
      "maximizing action\n",
      "[10.79060959  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 28.681749401741325\n",
      "current reward: 28.681749401741325; current state: [28.703703703703702, 0.23256956205373272]\n",
      "maximizing action\n",
      "[11.32719922  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 3)\n",
      "act action : 19\n",
      "reward: 27.74227396445539\n",
      "current reward: 27.74227396445539; current state: [26.925925925925927, 11.87325902525042]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 49)\n",
      "act action : 19\n",
      "reward: 26.403649419113346\n",
      "current reward: 26.403649419113346; current state: [25.62962962962963, 11.131624868602925]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 47)\n",
      "act action : 19\n",
      "reward: 25.97650103434042\n",
      "current reward: 25.97650103434042; current state: [27.444444444444443, 4.073882098603495]\n",
      "maximizing action\n",
      "[11.19061823  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 26.249441698724297\n",
      "current reward: 26.249441698724297; current state: [31.22222222222222, 3.121947026624456]\n",
      "maximizing action\n",
      "[5.86248308 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 15)\n",
      "act action : 19\n",
      "reward: 27.279470963703687\n",
      "current reward: 27.279470963703687; current state: [23.666666666666668, 7.008374008658114]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 26.283158254778034\n",
      "current reward: 26.283158254778034; current state: [28.22222222222222, 0.05119453924914677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 3)\n",
      "act action : 19\n",
      "reward: 25.992810924676053\n",
      "current reward: 25.992810924676053; current state: [34.333333333333336, 1.7776980763745396]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 9)\n",
      "act action : 19\n",
      "reward: 27.0644243879799\n",
      "current reward: 27.0644243879799; current state: [23.666666666666668, 5.982392007947635]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 25)\n",
      "act action : 19\n",
      "reward: 26.260489627056984\n",
      "current reward: 26.260489627056984; current state: [26.185185185185187, 1.7279804850719824]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 9)\n",
      "act action : 19\n",
      "reward: 26.293287673102594\n",
      "current reward: 26.293287673102594; current state: [29.51851851851852, 7.523490999948435]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 33)\n",
      "act action : 19\n",
      "reward: 27.27349915947939\n",
      "current reward: 27.27349915947939; current state: [26.925925925925927, 4.552592971615995]\n",
      "maximizing action\n",
      "[5.86377213 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 21)\n",
      "act action : 19\n",
      "reward: 26.31361295988459\n",
      "current reward: 26.31361295988459; current state: [23.037037037037038, 11.39011495413002]\n",
      "maximizing action\n",
      "[5.92638889 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 47)\n",
      "act action : 19\n",
      "reward: 27.189904728697808\n",
      "current reward: 27.189904728697808; current state: [21.77777777777778, 6.5773816228523]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 29)\n",
      "act action : 19\n",
      "reward: 26.655798534284617\n",
      "current reward: 26.655798534284617; current state: [29.11111111111111, 2.0838316865232644]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 26.602349162828755\n",
      "current reward: 26.602349162828755; current state: [29.962962962962962, 6.597815557082329]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 27.419151021501147\n",
      "current reward: 27.419151021501147; current state: [25.444444444444443, 2.345837139430122]\n",
      "maximizing action\n",
      "[11.32474165  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 11)\n",
      "act action : 19\n",
      "reward: 26.824372543488966\n",
      "current reward: 26.824372543488966; current state: [26.185185185185187, 3.609557572889232]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 17)\n",
      "act action : 19\n",
      "reward: 27.585444815355157\n",
      "current reward: 27.585444815355157; current state: [26.185185185185187, 6.4032932558841]\n",
      "maximizing action\n",
      "[17.34979735  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 27)\n",
      "act action : 19\n",
      "reward: 27.452951510415954\n",
      "current reward: 27.452951510415954; current state: [29.51851851851852, 2.2494914194804183]\n",
      "maximizing action\n",
      "[12.01171214  0.          0.          0.          0.          5.43764091]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 27.38433234853844\n",
      "current reward: 27.38433234853844; current state: [26.925925925925927, 14.575396571500765]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 61)\n",
      "act action : 19\n",
      "reward: 27.785985352340116\n",
      "current reward: 27.785985352340116; current state: [30.814814814814813, 2.3557104888630147]\n",
      "exploring action\n",
      "Current action = 33, current state (125, 11)\n",
      "act action : 33\n",
      "reward: 27.505442206331153\n",
      "current reward: 27.505442206331153; current state: [30.333333333333332, 7.238323787958155]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 31)\n",
      "act action : 19\n",
      "reward: 27.621950370964942\n",
      "current reward: 27.621950370964942; current state: [27.666666666666668, 11.443156196432309]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 47)\n",
      "act action : 19\n",
      "reward: 28.633197755869443\n",
      "current reward: 28.633197755869443; current state: [24.296296296296298, 8.618027679374606]\n",
      "maximizing action\n",
      "[5.54957077 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 37)\n",
      "act action : 19\n",
      "reward: 27.78748717278246\n",
      "current reward: 27.78748717278246; current state: [27.666666666666668, 7.152323538639623]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 27.907182825894097\n",
      "current reward: 27.907182825894097; current state: [30.333333333333332, 6.125894374072889]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 27)\n",
      "act action : 19\n",
      "reward: 28.885103702633796\n",
      "current reward: 28.885103702633796; current state: [32.51851851851852, 5.368081409866626]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 23)\n",
      "act action : 19\n",
      "reward: 27.966421438270597\n",
      "current reward: 27.966421438270597; current state: [30.333333333333332, 4.579258796508688]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 21)\n",
      "act action : 19\n",
      "reward: 29.286361876859065\n",
      "current reward: 29.286361876859065; current state: [29.77777777777778, 7.104002620551598]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 31)\n",
      "act action : 19\n",
      "reward: 27.509344400123926\n",
      "current reward: 27.509344400123926; current state: [29.0, 5.348963399005682]\n",
      "maximizing action\n",
      "[5.80885591 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 23)\n",
      "act action : 19\n",
      "reward: 26.99529069928995\n",
      "current reward: 26.99529069928995; current state: [32.51851851851852, 6.400858116142715]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 27)\n",
      "act action : 19\n",
      "reward: 28.628373703844712\n",
      "current reward: 28.628373703844712; current state: [31.14814814814815, 9.280169781658682]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 39)\n",
      "act action : 19\n",
      "reward: 27.324673835926067\n",
      "current reward: 27.324673835926067; current state: [27.666666666666668, 8.108785746172243]\n",
      "maximizing action\n",
      "[5.85374342 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 35)\n",
      "act action : 19\n",
      "reward: 27.214753139002614\n",
      "current reward: 27.214753139002614; current state: [31.14814814814815, 8.509648697277354]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 37)\n",
      "act action : 19\n",
      "reward: 27.28673388930349\n",
      "current reward: 27.28673388930349; current state: [26.925925925925927, 8.12671914208419]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 35)\n",
      "act action : 19\n",
      "reward: 27.08310430312676\n",
      "current reward: 27.08310430312676; current state: [29.0, 7.895959811970933]\n",
      "exploring action\n",
      "Current action = 25, current state (119, 33)\n",
      "act action : 25\n",
      "reward: 27.27562018300786\n",
      "current reward: 27.27562018300786; current state: [31.666666666666668, 3.928705407910179]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 28.52123396463787\n",
      "current reward: 28.52123396463787; current state: [30.814814814814813, 5.7549125483676855]\n",
      "maximizing action\n",
      "[11.63533009  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 27.15418786728004\n",
      "current reward: 27.15418786728004; current state: [33.0, 0.05261660978384527]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 3)\n",
      "act action : 19\n",
      "reward: 29.0163038145544\n",
      "current reward: 29.0163038145544; current state: [26.925925925925927, 10.377097937732831]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 43)\n",
      "act action : 19\n",
      "reward: 26.48125149470981\n",
      "current reward: 26.48125149470981; current state: [24.333333333333332, 3.5292619639393217]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 17)\n",
      "act action : 19\n",
      "reward: 26.65594167580987\n",
      "current reward: 26.65594167580987; current state: [26.925925925925927, 4.075591345607666]\n",
      "maximizing action\n",
      "[16.31822452  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 26.676894989782497\n",
      "current reward: 26.676894989782497; current state: [26.185185185185187, 11.143982620680797]\n",
      "maximizing action\n",
      "[6.09603448 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 47)\n",
      "act action : 19\n",
      "reward: 26.647476609390733\n",
      "current reward: 26.647476609390733; current state: [25.444444444444443, 2.8378973435950203]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 13)\n",
      "act action : 19\n",
      "reward: 26.860124397208057\n",
      "current reward: 26.860124397208057; current state: [29.11111111111111, 3.584411966279617]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 26.377332037932167\n",
      "current reward: 26.377332037932167; current state: [27.444444444444443, 7.681095654891793]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 33)\n",
      "act action : 19\n",
      "reward: 26.213481834921144\n",
      "current reward: 26.213481834921144; current state: [32.111111111111114, 1.6159996132761134]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 26.293400064525965\n",
      "current reward: 26.293400064525965; current state: [26.925925925925927, 8.375381812352256]\n",
      "maximizing action\n",
      "[5.41662086 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 35)\n",
      "act action : 19\n",
      "reward: 26.33417582345345\n",
      "current reward: 26.33417582345345; current state: [27.666666666666668, 7.8932842849038085]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 33)\n",
      "act action : 19\n",
      "reward: 26.607272815674502\n",
      "current reward: 26.607272815674502; current state: [31.666666666666668, 1.3713483157143103]\n",
      "maximizing action\n",
      "[5.79211912 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 7)\n",
      "act action : 19\n",
      "reward: 26.48165585865922\n",
      "current reward: 26.48165585865922; current state: [28.40740740740741, 7.303536617062934]\n",
      "maximizing action\n",
      "[5.66127547 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 31)\n",
      "act action : 19\n",
      "reward: 26.381224613073286\n",
      "current reward: 26.381224613073286; current state: [29.0, 5.653456312103363]\n",
      "maximizing action\n",
      "[5.58287455 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 25)\n",
      "act action : 19\n",
      "reward: 26.1451647399871\n",
      "current reward: 26.1451647399871; current state: [25.666666666666668, 9.970795142629493]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 41)\n",
      "act action : 19\n",
      "reward: 26.418254847297217\n",
      "current reward: 26.418254847297217; current state: [26.333333333333332, 7.465416807616329]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 26.131779620756344\n",
      "current reward: 26.131779620756344; current state: [28.40740740740741, 5.8676526832495295]\n",
      "exploring action\n",
      "Current action = 31, current state (115, 25)\n",
      "act action : 31\n",
      "reward: 26.213706436983387\n",
      "current reward: 26.213706436983387; current state: [29.77777777777778, 4.862324408283587]\n",
      "maximizing action\n",
      "[29.55208185  5.53773411  0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 26.27699459234317\n",
      "current reward: 26.27699459234317; current state: [33.0, 2.5319552170119297]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 13)\n",
      "act action : 19\n",
      "reward: 26.286273908411427\n",
      "current reward: 26.286273908411427; current state: [27.666666666666668, 4.178182940702898]\n",
      "maximizing action\n",
      "[5.90003248 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 26.069157915956954\n",
      "current reward: 26.069157915956954; current state: [31.666666666666668, 0.052616609783845275]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 3)\n",
      "act action : 19\n",
      "reward: 26.433374701557568\n",
      "current reward: 26.433374701557568; current state: [29.51851851851852, 7.594158274672048]\n",
      "maximizing action\n",
      "[5.45469983 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 33)\n",
      "act action : 19\n",
      "reward: 26.23368025217408\n",
      "current reward: 26.23368025217408; current state: [26.333333333333332, 7.968567585960552]\n",
      "maximizing action\n",
      "[5.53322132 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 26.368119016600165\n",
      "current reward: 26.368119016600165; current state: [28.22222222222222, 5.747427995784499]\n",
      "maximizing action\n",
      "[0.         0.         0.         0.         5.24274129 0.        ]\n",
      "Current action = 31, current state (115, 25)\n",
      "act action : 31\n",
      "reward: 26.242054270122065\n",
      "current reward: 26.242054270122065; current state: [29.51851851851852, 6.765813646342104]\n",
      "maximizing action\n",
      "[5.4838302 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 26.568475363051263\n",
      "current reward: 26.568475363051263; current state: [32.111111111111114, 4.037330051730192]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 26.262550376214715\n",
      "current reward: 26.262550376214715; current state: [26.925925925925927, 13.123431294090926]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 55)\n",
      "act action : 19\n",
      "reward: 26.98554384172283\n",
      "current reward: 26.98554384172283; current state: [32.111111111111114, 4.381987078381382]\n",
      "maximizing action\n",
      "[5.25251008 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 26.23211992114913\n",
      "current reward: 26.23211992114913; current state: [32.111111111111114, 4.753676122607184]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 21)\n",
      "act action : 19\n",
      "reward: 26.41447403846008\n",
      "current reward: 26.41447403846008; current state: [26.185185185185187, 12.308648024985887]\n",
      "exploring action\n",
      "Current action = 31, current state (107, 51)\n",
      "act action : 31\n",
      "reward: 26.662115981017468\n",
      "current reward: 26.662115981017468; current state: [29.962962962962962, 2.780096623410522]\n",
      "maximizing action\n",
      "[5.83183892 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 27.848075653076446\n",
      "current reward: 27.848075653076446; current state: [29.444444444444443, 1.9585171848895795]\n",
      "maximizing action\n",
      "[5.59050841 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 26.665064372633168\n",
      "current reward: 26.665064372633168; current state: [27.074074074074073, 7.146202380627475]\n",
      "maximizing action\n",
      "[11.11635194  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 26.375481945410275\n",
      "current reward: 26.375481945410275; current state: [19.333333333333332, 14.820562862317907]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (79, 61)\n",
      "act action : 19\n",
      "reward: 28.713580254908322\n",
      "current reward: 28.713580254908322; current state: [21.77777777777778, 4.542484515097911]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 21)\n",
      "act action : 19\n",
      "reward: 27.29032800506558\n",
      "current reward: 27.29032800506558; current state: [34.0, 0.04835039817974972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 3)\n",
      "act action : 19\n",
      "reward: 26.38218847602486\n",
      "current reward: 26.38218847602486; current state: [31.555555555555557, 3.9130152867743133]\n",
      "maximizing action\n",
      "[5.70424679 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 26.72436542123177\n",
      "current reward: 26.72436542123177; current state: [31.555555555555557, 2.5631597054078243]\n",
      "exploring action\n",
      "Current action = 22, current state (129, 13)\n",
      "act action : 22\n",
      "reward: 26.449531903865978\n",
      "current reward: 26.449531903865978; current state: [28.703703703703702, 4.57045359093144]\n",
      "maximizing action\n",
      "[11.47736581  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 28.667813998151303\n",
      "current reward: 28.667813998151303; current state: [27.444444444444443, 4.77217116217897]\n",
      "maximizing action\n",
      "[5.86691643 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 26.318948423538334\n",
      "current reward: 26.318948423538334; current state: [25.62962962962963, 7.286282801710304]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 26.356330260673726\n",
      "current reward: 26.356330260673726; current state: [25.62962962962963, 7.514388810592648]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 33)\n",
      "act action : 19\n",
      "reward: 26.755857345427774\n",
      "current reward: 26.755857345427774; current state: [28.703703703703702, 0.9185206990681603]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 5)\n",
      "act action : 19\n",
      "reward: 26.737556921129084\n",
      "current reward: 26.737556921129084; current state: [23.666666666666668, 9.967678101153949]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 28.35780450614037\n",
      "current reward: 28.35780450614037; current state: [26.185185185185187, 4.409176441839368]\n",
      "maximizing action\n",
      "[5.44900599 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 19)\n",
      "act action : 19\n",
      "reward: 27.164851441980236\n",
      "current reward: 27.164851441980236; current state: [29.51851851851852, 6.185403902597279]\n",
      "maximizing action\n",
      "[11.59941698  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 27.481189490583347\n",
      "current reward: 27.481189490583347; current state: [26.925925925925927, 9.28120726170303]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 27.684660888162384\n",
      "current reward: 27.684660888162384; current state: [29.51851851851852, 2.0707519795814266]\n",
      "maximizing action\n",
      "[17.48857861  0.          0.          0.          0.          5.43764091]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 29.230146654401068\n",
      "current reward: 29.230146654401068; current state: [35.666666666666664, 0.6221412978697186]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (145, 5)\n",
      "act action : 19\n",
      "reward: 29.306300842526127\n",
      "current reward: 29.306300842526127; current state: [29.0, 7.583205907640624]\n",
      "maximizing action\n",
      "[0.         0.         5.45512404 0.         0.         0.        ]\n",
      "Current action = 25, current state (119, 33)\n",
      "act action : 25\n",
      "reward: 27.906638432323223\n",
      "current reward: 27.906638432323223; current state: [25.666666666666668, 7.0734300834087565]\n",
      "maximizing action\n",
      "[5.27126605 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 28.161167326626067\n",
      "current reward: 28.161167326626067; current state: [32.51851851851852, 3.421564273344646]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 15)\n",
      "act action : 19\n",
      "reward: 29.71376425027458\n",
      "current reward: 29.71376425027458; current state: [29.14814814814815, 5.922712143351878]\n",
      "maximizing action\n",
      "[10.81190749  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 25)\n",
      "act action : 19\n",
      "reward: 28.293376833701924\n",
      "current reward: 28.293376833701924; current state: [27.74074074074074, 6.915416313697237]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 29)\n",
      "act action : 19\n",
      "reward: 28.515722372408465\n",
      "current reward: 28.515722372408465; current state: [31.962962962962962, 3.589185768908342]\n",
      "maximizing action\n",
      "[11.04911988  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 29.184623085637657\n",
      "current reward: 29.184623085637657; current state: [31.333333333333332, 5.048202575093108]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 23)\n",
      "act action : 19\n",
      "reward: 28.362365843354244\n",
      "current reward: 28.362365843354244; current state: [31.962962962962962, 5.885730162090569]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 25)\n",
      "act action : 19\n",
      "reward: 28.40554479408952\n",
      "current reward: 28.40554479408952; current state: [34.22222222222222, 5.965975584894091]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 25)\n",
      "act action : 19\n",
      "reward: 28.486703498397684\n",
      "current reward: 28.486703498397684; current state: [31.962962962962962, 7.716919223269138]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 33)\n",
      "act action : 19\n",
      "reward: 28.359445394040648\n",
      "current reward: 28.359445394040648; current state: [29.77777777777778, 4.941653195489975]\n",
      "maximizing action\n",
      "[34.80748077  5.53773411  0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 28.507624401747545\n",
      "current reward: 28.507624401747545; current state: [31.962962962962962, 4.012583250956566]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 19)\n",
      "act action : 19\n",
      "reward: 30.00364409644003\n",
      "current reward: 30.00364409644003; current state: [29.14814814814815, 8.509245585476338]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 37)\n",
      "act action : 19\n",
      "reward: 28.479238327245856\n",
      "current reward: 28.479238327245856; current state: [28.40740740740741, 7.2108955459644495]\n",
      "maximizing action\n",
      "[10.93752039  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 31)\n",
      "act action : 19\n",
      "reward: 28.74103245407043\n",
      "current reward: 28.74103245407043; current state: [31.666666666666668, 4.263199189809037]\n",
      "maximizing action\n",
      "[6.00072882 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 19)\n",
      "act action : 19\n",
      "reward: 28.42341035994529\n",
      "current reward: 28.42341035994529; current state: [32.51851851851852, 6.394673539646792]\n",
      "maximizing action\n",
      "[5.72567474 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (133, 27)\n",
      "act action : 19\n",
      "reward: 28.597580153763854\n",
      "current reward: 28.597580153763854; current state: [31.14814814814815, 9.808605832048883]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 41)\n",
      "act action : 19\n",
      "reward: 30.004682406433805\n",
      "current reward: 30.004682406433805; current state: [27.666666666666668, 5.932530043687471]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 25)\n",
      "act action : 19\n",
      "reward: 28.66019332603028\n",
      "current reward: 28.66019332603028; current state: [31.666666666666668, 3.724611913062955]\n",
      "maximizing action\n",
      "[16.87530438  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 28.8051107984865\n",
      "current reward: 28.8051107984865; current state: [28.22222222222222, 9.073698162975798]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 39)\n",
      "act action : 19\n",
      "reward: 29.32171221211644\n",
      "current reward: 29.32171221211644; current state: [25.0, 9.492225217380255]\n",
      "exploring action\n",
      "Current action = 25, current state (103, 39)\n",
      "act action : 25\n",
      "reward: 28.65741186737201\n",
      "current reward: 28.65741186737201; current state: [26.925925925925927, 10.047086550781701]\n",
      "maximizing action\n",
      "[5.2962503 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (109, 43)\n",
      "act action : 19\n",
      "reward: 29.550480613942096\n",
      "current reward: 29.550480613942096; current state: [26.185185185185187, 4.641296923419328]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 29.824297166586387\n",
      "current reward: 29.824297166586387; current state: [29.51851851851852, 4.910836493570933]\n",
      "maximizing action\n",
      "[40.50900565  5.53773411  0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 28.543047343342526\n",
      "current reward: 28.543047343342526; current state: [31.22222222222222, 2.7606638291482137]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 13)\n",
      "act action : 19\n",
      "reward: 28.117887193431915\n",
      "current reward: 28.117887193431915; current state: [30.814814814814813, 4.937198234134457]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 21)\n",
      "act action : 19\n",
      "reward: 28.229044118940973\n",
      "current reward: 28.229044118940973; current state: [27.444444444444443, 4.941233467104976]\n",
      "maximizing action\n",
      "[11.13070612  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 28.432875448594988\n",
      "current reward: 28.432875448594988; current state: [31.22222222222222, 0.049772468714448244]\n",
      "exploring action\n",
      "Current action = 28, current state (127, 3)\n",
      "act action : 28\n",
      "reward: 28.32497020750785\n",
      "current reward: 28.32497020750785; current state: [28.22222222222222, 6.982741594454545]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 28.306103864563415\n",
      "current reward: 28.306103864563415; current state: [23.666666666666668, 9.656414683664732]\n",
      "maximizing action\n",
      "[5.6715609 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 27.80246344209859\n",
      "current reward: 27.80246344209859; current state: [32.111111111111114, 4.833982428716706]\n",
      "maximizing action\n",
      "[5.28289481 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 21)\n",
      "act action : 19\n",
      "reward: 28.799651804979266\n",
      "current reward: 28.799651804979266; current state: [25.62962962962963, 7.711256829888369]\n",
      "maximizing action\n",
      "[5.35117147 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 33)\n",
      "act action : 19\n",
      "reward: 28.425380924913046\n",
      "current reward: 28.425380924913046; current state: [23.037037037037038, 7.195147579468938]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 31)\n",
      "act action : 19\n",
      "reward: 27.534816776454917\n",
      "current reward: 27.534816776454917; current state: [25.62962962962963, 10.319575632087863]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 43)\n",
      "act action : 19\n",
      "reward: 28.68368991739925\n",
      "current reward: 28.68368991739925; current state: [26.185185185185187, 5.26940267030216]\n",
      "maximizing action\n",
      "[16.52695947  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 27.08422453058731\n",
      "current reward: 27.08422453058731; current state: [25.62962962962963, 8.386374970843919]\n",
      "maximizing action\n",
      "[5.46885536 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 35)\n",
      "act action : 19\n",
      "reward: 28.71921332503335\n",
      "current reward: 28.71921332503335; current state: [28.22222222222222, 5.055097303389181]\n",
      "maximizing action\n",
      "[11.09452898  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 23)\n",
      "act action : 19\n",
      "reward: 27.01317485070479\n",
      "current reward: 27.01317485070479; current state: [29.0, 2.7916517895221378]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 13)\n",
      "act action : 19\n",
      "reward: 27.128685215759546\n",
      "current reward: 27.128685215759546; current state: [25.62962962962963, 9.18009681943907]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 39)\n",
      "act action : 19\n",
      "reward: 28.076954791903514\n",
      "current reward: 28.076954791903514; current state: [31.666666666666668, 2.508530261939583]\n",
      "maximizing action\n",
      "[0.         5.28990638 0.         0.         0.         0.        ]\n",
      "Current action = 22, current state (129, 13)\n",
      "act action : 22\n",
      "reward: 28.556512669439655\n",
      "current reward: 28.556512669439655; current state: [29.0, 2.4810241230301213]\n",
      "maximizing action\n",
      "[5.32046983 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 26.938715968783914\n",
      "current reward: 26.938715968783914; current state: [28.22222222222222, 5.756839215251619]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.         10.49115214  0.        ]\n",
      "Current action = 31, current state (115, 25)\n",
      "act action : 31\n",
      "reward: 26.866983854248236\n",
      "current reward: 26.866983854248236; current state: [28.22222222222222, 6.678201186234695]\n",
      "maximizing action\n",
      "[5.66122077 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 26.629546676312156\n",
      "current reward: 26.629546676312156; current state: [32.111111111111114, 1.411581790204498]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 7)\n",
      "act action : 19\n",
      "reward: 26.414763516116125\n",
      "current reward: 26.414763516116125; current state: [24.333333333333332, 14.076671287693378]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 59)\n",
      "act action : 19\n",
      "reward: 26.705778462374525\n",
      "current reward: 26.705778462374525; current state: [24.925925925925927, 6.994584533395601]\n",
      "maximizing action\n",
      "[11.36240586  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 29)\n",
      "act action : 19\n",
      "reward: 26.78008101019363\n",
      "current reward: 26.78008101019363; current state: [26.185185185185187, 4.130584426233367]\n",
      "maximizing action\n",
      "[10.88197628  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 19)\n",
      "act action : 19\n",
      "reward: 26.342407240001435\n",
      "current reward: 26.342407240001435; current state: [28.22222222222222, 8.403348889620453]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 35)\n",
      "act action : 19\n",
      "reward: 26.584324754364285\n",
      "current reward: 26.584324754364285; current state: [30.814814814814813, 6.02502277002646]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 27)\n",
      "act action : 19\n",
      "reward: 28.720991280295465\n",
      "current reward: 28.720991280295465; current state: [30.814814814814813, 3.6846521539536696]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 17)\n",
      "act action : 19\n",
      "reward: 26.31309771144828\n",
      "current reward: 26.31309771144828; current state: [25.62962962962963, 7.087711270707285]\n",
      "maximizing action\n",
      "[10.90349952  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 25.98684140656464\n",
      "current reward: 25.98684140656464; current state: [28.22222222222222, 6.520483729925292]\n",
      "maximizing action\n",
      "[10.97654586  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 26.188428294122147\n",
      "current reward: 26.188428294122147; current state: [29.51851851851852, 7.107089726515871]\n",
      "maximizing action\n",
      "[5.50186888 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 31)\n",
      "act action : 19\n",
      "reward: 26.431798634626706\n",
      "current reward: 26.431798634626706; current state: [26.925925925925927, 6.749726777163666]\n",
      "maximizing action\n",
      "[16.76630345  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 26.064202620460662\n",
      "current reward: 26.064202620460662; current state: [30.814814814814813, 3.689734579507507]\n",
      "maximizing action\n",
      "[5.26261954 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 17)\n",
      "act action : 19\n",
      "reward: 26.518017906270032\n",
      "current reward: 26.518017906270032; current state: [30.814814814814813, 4.400688871166126]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 26.607281217660287\n",
      "current reward: 26.607281217660287; current state: [30.333333333333332, 7.086119941855429]\n",
      "maximizing action\n",
      "[5.52439007 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 31)\n",
      "act action : 19\n",
      "reward: 26.661845927633845\n",
      "current reward: 26.661845927633845; current state: [23.666666666666668, 7.1995764878621955]\n",
      "maximizing action\n",
      "[5.25663165 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 28.803567054410752\n",
      "current reward: 28.803567054410752; current state: [28.703703703703702, 4.32926386722443]\n",
      "maximizing action\n",
      "[5.76837954 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 26.499707851590966\n",
      "current reward: 26.499707851590966; current state: [30.814814814814813, 4.557017553656533]\n",
      "exploring action\n",
      "Current action = 33, current state (125, 21)\n",
      "act action : 33\n",
      "reward: 28.33110427497436\n",
      "current reward: 28.33110427497436; current state: [26.925925925925927, 4.048682212795837]\n",
      "maximizing action\n",
      "[21.64366091  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 26.552713587428173\n",
      "current reward: 26.552713587428173; current state: [26.925925925925927, 7.311338532608821]\n",
      "maximizing action\n",
      "[5.37907776 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 26.83142661519786\n",
      "current reward: 26.83142661519786; current state: [28.22222222222222, 9.524799177718524]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 41)\n",
      "act action : 19\n",
      "reward: 26.265135910637184\n",
      "current reward: 26.265135910637184; current state: [28.22222222222222, 10.231332596896673]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 43)\n",
      "act action : 19\n",
      "reward: 30.432536349664556\n",
      "current reward: 30.432536349664556; current state: [26.185185185185187, 5.410612120110543]\n",
      "maximizing action\n",
      "[21.94380438  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 26.910748752891568\n",
      "current reward: 26.910748752891568; current state: [26.185185185185187, 7.674314716033266]\n",
      "maximizing action\n",
      "[10.80684513  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 26.521642356516328\n",
      "current reward: 26.521642356516328; current state: [29.962962962962962, 4.893541843278338]\n",
      "maximizing action\n",
      "[46.21761512  5.53773411  0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 26.708033927796652\n",
      "current reward: 26.708033927796652; current state: [27.88888888888889, 4.061936065982995]\n",
      "maximizing action\n",
      "[11.11386406  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 28.27132510236387\n",
      "current reward: 28.27132510236387; current state: [27.88888888888889, 3.28166161624746]\n",
      "maximizing action\n",
      "[5.52798272 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 15)\n",
      "act action : 19\n",
      "reward: 26.69689319501369\n",
      "current reward: 26.69689319501369; current state: [27.444444444444443, 6.071978876232683]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 26.896295962910354\n",
      "current reward: 26.896295962910354; current state: [24.925925925925927, 7.95410007151893]\n",
      "maximizing action\n",
      "[5.51691674 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 33)\n",
      "act action : 19\n",
      "reward: 28.34279188581229\n",
      "current reward: 28.34279188581229; current state: [32.111111111111114, 0.16379331429691782]\n",
      "maximizing action\n",
      "[5.73491374 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 3)\n",
      "act action : 19\n",
      "reward: 28.951804855217997\n",
      "current reward: 28.951804855217997; current state: [29.51851851851852, 5.504393167410774]\n",
      "maximizing action\n",
      "[11.9236425   0.          5.73517676  0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 27.22884318532304\n",
      "current reward: 27.22884318532304; current state: [26.925925925925927, 4.2841596130578985]\n",
      "maximizing action\n",
      "[26.95420363  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 26.986790101693057\n",
      "current reward: 26.986790101693057; current state: [28.22222222222222, 4.363254753890658]\n",
      "maximizing action\n",
      "[6.01355183 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 26.582032331836373\n",
      "current reward: 26.582032331836373; current state: [29.962962962962962, 5.543760492086051]\n",
      "exploring action\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 28.776283077014842\n",
      "current reward: 28.776283077014842; current state: [27.444444444444443, 7.568747474259383]\n",
      "maximizing action\n",
      "[5.24269637 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 33)\n",
      "act action : 19\n",
      "reward: 27.081219601287255\n",
      "current reward: 27.081219601287255; current state: [23.0, 6.439124260832263]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 27)\n",
      "act action : 19\n",
      "reward: 28.646273677410004\n",
      "current reward: 28.646273677410004; current state: [26.666666666666668, 4.870689115465719]\n",
      "maximizing action\n",
      "[11.12649473  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 21)\n",
      "act action : 19\n",
      "reward: 26.71488892664087\n",
      "current reward: 26.71488892664087; current state: [24.703703703703702, 11.967632926022905]\n",
      "maximizing action\n",
      "[5.84817016 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 49)\n",
      "act action : 19\n",
      "reward: 26.76790665770264\n",
      "current reward: 26.76790665770264; current state: [29.11111111111111, 2.078576709157918]\n",
      "maximizing action\n",
      "[10.70821303  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 28.868765032804635\n",
      "current reward: 28.868765032804635; current state: [26.666666666666668, 5.151716095918089]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 27.234930107718437\n",
      "current reward: 27.234930107718437; current state: [24.703703703703702, 10.050814122932957]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 43)\n",
      "act action : 19\n",
      "reward: 26.818457970156476\n",
      "current reward: 26.818457970156476; current state: [29.444444444444443, 1.6035713403451184]\n",
      "maximizing action\n",
      "[10.92352128  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 28.7578895878888\n",
      "current reward: 28.7578895878888; current state: [27.074074074074073, 8.051252539949935]\n",
      "maximizing action\n",
      "[5.65395991 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 27.290336765065188\n",
      "current reward: 27.290336765065188; current state: [23.0, 10.592082533247536]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 45)\n",
      "act action : 19\n",
      "reward: 29.300870278543183\n",
      "current reward: 29.300870278543183; current state: [21.77777777777778, 5.7688273873867155]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 25)\n",
      "act action : 19\n",
      "reward: 27.520404721026562\n",
      "current reward: 27.520404721026562; current state: [31.22222222222222, 1.2662279557603648]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (127, 7)\n",
      "act action : 19\n",
      "reward: 27.660862066515488\n",
      "current reward: 27.660862066515488; current state: [27.444444444444443, 6.917433911915147]\n",
      "maximizing action\n",
      "[5.32516041 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 27.94852136005335\n",
      "current reward: 27.94852136005335; current state: [26.185185185185187, 5.104250086971204]\n",
      "maximizing action\n",
      "[27.32595413  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 27.749572761653436\n",
      "current reward: 27.749572761653436; current state: [27.444444444444443, 6.603747462303891]\n",
      "maximizing action\n",
      "[10.91486468  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 28.815433736688068\n",
      "current reward: 28.815433736688068; current state: [26.666666666666668, 9.075495869862795]\n",
      "maximizing action\n",
      "[5.53693218 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 27.864155679073605\n",
      "current reward: 27.864155679073605; current state: [31.22222222222222, 2.909754676755646]\n",
      "maximizing action\n",
      "[5.62357744 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 13)\n",
      "act action : 19\n",
      "reward: 28.692231718962073\n",
      "current reward: 28.692231718962073; current state: [24.22222222222222, 10.886820704607722]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 45)\n",
      "act action : 19\n",
      "reward: 29.167821553819305\n",
      "current reward: 29.167821553819305; current state: [27.88888888888889, 4.557994703668122]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 28.401408783445728\n",
      "current reward: 28.401408783445728; current state: [26.185185185185187, 4.793836127493694]\n",
      "maximizing action\n",
      "[5.96485943 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 28.655602504584262\n",
      "current reward: 28.655602504584262; current state: [22.40740740740741, 13.516077296474393]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 57)\n",
      "act action : 19\n",
      "reward: 28.739768272015258\n",
      "current reward: 28.739768272015258; current state: [28.22222222222222, 4.47881733645806]\n",
      "maximizing action\n",
      "[11.32995829  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 30.019119530212176\n",
      "current reward: 30.019119530212176; current state: [28.22222222222222, 2.4483982172575396]\n",
      "maximizing action\n",
      "[5.42367496 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 11)\n",
      "act action : 19\n",
      "reward: 30.140597141824983\n",
      "current reward: 30.140597141824983; current state: [28.703703703703702, 3.096876818873696]\n",
      "maximizing action\n",
      "[6.06113961 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 15)\n",
      "act action : 19\n",
      "reward: 29.468214297510414\n",
      "current reward: 29.468214297510414; current state: [28.703703703703702, 2.1043645432256444]\n",
      "maximizing action\n",
      "[10.8130522  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 30.256768398619585\n",
      "current reward: 30.256768398619585; current state: [28.703703703703702, 2.4140201387921576]\n",
      "maximizing action\n",
      "[16.86440588  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 29.61996928667863\n",
      "current reward: 29.61996928667863; current state: [30.814814814814813, 4.342620785207998]\n",
      "maximizing action\n",
      "[5.32145624 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 30.19768549621556\n",
      "current reward: 30.19768549621556; current state: [27.444444444444443, 7.8499866577466895]\n",
      "maximizing action\n",
      "[10.65894029  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 33)\n",
      "act action : 19\n",
      "reward: 29.68524388110014\n",
      "current reward: 29.68524388110014; current state: [28.22222222222222, 3.096406889017089]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 15)\n",
      "act action : 19\n",
      "reward: 30.091038232592265\n",
      "current reward: 30.091038232592265; current state: [24.925925925925927, 9.815421010658508]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 41)\n",
      "act action : 19\n",
      "reward: 30.31053920759899\n",
      "current reward: 30.31053920759899; current state: [24.22222222222222, 4.598403112850768]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 21)\n",
      "act action : 19\n",
      "reward: 31.083134583459316\n",
      "current reward: 31.083134583459316; current state: [23.0, 14.004807280148642]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 59)\n",
      "act action : 19\n",
      "reward: 30.666938651675135\n",
      "current reward: 30.666938651675135; current state: [26.666666666666668, 8.759278006616935]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 30.52881219844038\n",
      "current reward: 30.52881219844038; current state: [29.962962962962962, 7.977347440798627]\n",
      "maximizing action\n",
      "[10.70143588  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 33)\n",
      "act action : 19\n",
      "reward: 31.162334262196993\n",
      "current reward: 31.162334262196993; current state: [28.703703703703702, 5.31706435836877]\n",
      "exploring action\n",
      "Current action = 33, current state (117, 23)\n",
      "act action : 33\n",
      "reward: 30.731262812418194\n",
      "current reward: 30.731262812418194; current state: [26.185185185185187, 8.391900232442389]\n",
      "maximizing action\n",
      "[5.98978151 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 30.233249438909652\n",
      "current reward: 30.233249438909652; current state: [26.666666666666668, 2.5667910191149974]\n",
      "maximizing action\n",
      "[5.38479315 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 13)\n",
      "act action : 19\n",
      "reward: 30.300777760337628\n",
      "current reward: 30.300777760337628; current state: [27.074074074074073, 7.442669183284132]\n",
      "exploring action\n",
      "Current action = 28, current state (111, 31)\n",
      "act action : 28\n",
      "reward: 30.193512351799907\n",
      "current reward: 30.193512351799907; current state: [27.88888888888889, 6.329975608827828]\n",
      "maximizing action\n",
      "[5.36192129 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 30.315886185101743\n",
      "current reward: 30.315886185101743; current state: [26.666666666666668, 4.222437219296643]\n",
      "maximizing action\n",
      "[32.35156165  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 30.224323596474292\n",
      "current reward: 30.224323596474292; current state: [29.962962962962962, 6.43446424482273]\n",
      "maximizing action\n",
      "[17.09565487  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 30.10674375720622\n",
      "current reward: 30.10674375720622; current state: [24.22222222222222, 5.745371195357776]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 30.613279312659376\n",
      "current reward: 30.613279312659376; current state: [21.77777777777778, 10.91409544189689]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 45)\n",
      "act action : 19\n",
      "reward: 30.328431825554603\n",
      "current reward: 30.328431825554603; current state: [29.11111111111111, 4.394221733646937]\n",
      "maximizing action\n",
      "[11.55981156  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 30.36804818403915\n",
      "current reward: 30.36804818403915; current state: [24.22222222222222, 8.082171862017255]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 35)\n",
      "act action : 19\n",
      "reward: 30.49796634024021\n",
      "current reward: 30.49796634024021; current state: [28.703703703703702, 5.988765078900136]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 30.640569266947946\n",
      "current reward: 30.640569266947946; current state: [29.11111111111111, 6.071963291771617]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 27)\n",
      "act action : 19\n",
      "reward: 31.332068992740208\n",
      "current reward: 31.332068992740208; current state: [26.185185185185187, 8.922173785223318]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 37)\n",
      "act action : 19\n",
      "reward: 30.151422793058753\n",
      "current reward: 30.151422793058753; current state: [27.444444444444443, 4.485941335362826]\n",
      "maximizing action\n",
      "[16.44050657  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 30.75841803293791\n",
      "current reward: 30.75841803293791; current state: [29.962962962962962, 2.966944725522112]\n",
      "maximizing action\n",
      "[11.40145405  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 30.735909068105997\n",
      "current reward: 30.735909068105997; current state: [28.22222222222222, 6.172392231364898]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 30.789020457836955\n",
      "current reward: 30.789020457836955; current state: [27.88888888888889, 2.2251529153404705]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 11)\n",
      "act action : 19\n",
      "reward: 30.30068799386025\n",
      "current reward: 30.30068799386025; current state: [28.703703703703702, 8.451143595459635]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 35)\n",
      "act action : 19\n",
      "reward: 31.170361412862793\n",
      "current reward: 31.170361412862793; current state: [27.444444444444443, 6.939892839994291]\n",
      "maximizing action\n",
      "[16.67795143  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 31.31433991060918\n",
      "current reward: 31.31433991060918; current state: [27.444444444444443, 5.660675977620739]\n",
      "maximizing action\n",
      "[22.33696061  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 30.242237847276584\n",
      "current reward: 30.242237847276584; current state: [25.62962962962963, 5.378964174164251]\n",
      "maximizing action\n",
      "[5.92192724 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 30.64928498575485\n",
      "current reward: 30.64928498575485; current state: [25.62962962962963, 5.096752612890515]\n",
      "maximizing action\n",
      "[12.05178423  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 29.417216573475333\n",
      "current reward: 29.417216573475333; current state: [31.666666666666668, 4.6383610504494595]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 21)\n",
      "act action : 19\n",
      "reward: 29.401140143750926\n",
      "current reward: 29.401140143750926; current state: [33.0, 2.209194323041975]\n",
      "maximizing action\n",
      "[5.99680084 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 11)\n",
      "act action : 19\n",
      "reward: 29.44002005458621\n",
      "current reward: 29.44002005458621; current state: [33.0, 4.422483090232794]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 19)\n",
      "act action : 19\n",
      "reward: 29.539516204781496\n",
      "current reward: 29.539516204781496; current state: [33.0, 3.396019270898512]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 15)\n",
      "act action : 19\n",
      "reward: 29.505252306124344\n",
      "current reward: 29.505252306124344; current state: [30.814814814814813, 1.9606853785964786]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 9)\n",
      "act action : 19\n",
      "reward: 30.15435081123994\n",
      "current reward: 30.15435081123994; current state: [29.51851851851852, 7.966593797242427]\n",
      "maximizing action\n",
      "[16.93390273  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 33)\n",
      "act action : 19\n",
      "reward: 29.083811765912387\n",
      "current reward: 29.083811765912387; current state: [26.925925925925927, 9.071332418790954]\n",
      "maximizing action\n",
      "[11.10976331  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 28.358596704173852\n",
      "current reward: 28.358596704173852; current state: [21.74074074074074, 9.685920872719068]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 41)\n",
      "act action : 19\n",
      "reward: 29.201690078013787\n",
      "current reward: 29.201690078013787; current state: [24.925925925925927, 10.040195496203056]\n",
      "maximizing action\n",
      "[5.36369159 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 43)\n",
      "act action : 19\n",
      "reward: 28.454196028567736\n",
      "current reward: 28.454196028567736; current state: [32.48148148148148, 2.2846549744874833]\n",
      "maximizing action\n",
      "[5.97517753 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 28.022488178319687\n",
      "current reward: 28.022488178319687; current state: [30.814814814814813, 6.66367990519215]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 29)\n",
      "act action : 19\n",
      "reward: 28.132270904055556\n",
      "current reward: 28.132270904055556; current state: [29.51851851851852, 6.543652760188029]\n",
      "maximizing action\n",
      "[10.78713194  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 28.220222921737946\n",
      "current reward: 28.220222921737946; current state: [25.62962962962963, 4.013295868967468]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 19)\n",
      "act action : 19\n",
      "reward: 27.993309913534492\n",
      "current reward: 27.993309913534492; current state: [25.62962962962963, 8.632632637140004]\n",
      "maximizing action\n",
      "[5.61008174 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 37)\n",
      "act action : 19\n",
      "reward: 27.668579627736865\n",
      "current reward: 27.668579627736865; current state: [32.111111111111114, 1.0202941887603438]\n",
      "maximizing action\n",
      "[5.2829527 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (131, 7)\n",
      "act action : 19\n",
      "reward: 28.73371434226068\n",
      "current reward: 28.73371434226068; current state: [28.703703703703702, 4.635666901024519]\n",
      "maximizing action\n",
      "[17.2109286  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 27.883557755518193\n",
      "current reward: 27.883557755518193; current state: [28.703703703703702, 5.221067987836908]\n",
      "maximizing action\n",
      "[0.         0.         0.         0.         0.         6.14625256]\n",
      "Current action = 33, current state (117, 23)\n",
      "act action : 33\n",
      "reward: 27.67739953869555\n",
      "current reward: 27.67739953869555; current state: [26.925925925925927, 6.960261064660297]\n",
      "maximizing action\n",
      "[21.97914398  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 28.21982647891601\n",
      "current reward: 28.21982647891601; current state: [22.40740740740741, 4.76083094761096]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 21)\n",
      "act action : 19\n",
      "reward: 27.69768426283939\n",
      "current reward: 27.69768426283939; current state: [25.62962962962963, 5.186458205617713]\n",
      "maximizing action\n",
      "[17.93522755  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 29.390658239125372\n",
      "current reward: 29.390658239125372; current state: [29.962962962962962, 4.466700405799982]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 27.85371376432509\n",
      "current reward: 27.85371376432509; current state: [28.703703703703702, 5.588215347136971]\n",
      "maximizing action\n",
      "[6.12811385 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 27.907158674516342\n",
      "current reward: 27.907158674516342; current state: [30.814814814814813, 6.183816669291924]\n",
      "maximizing action\n",
      "[5.74419826 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 27)\n",
      "act action : 19\n",
      "reward: 29.153794974131795\n",
      "current reward: 29.153794974131795; current state: [29.51851851851852, 6.548152165170706]\n",
      "maximizing action\n",
      "[16.43117653  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 27.92538846969448\n",
      "current reward: 27.92538846969448; current state: [29.0, 6.791590149531745]\n",
      "maximizing action\n",
      "[11.57244106  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 28.235926562280408\n",
      "current reward: 28.235926562280408; current state: [26.333333333333332, 9.94017217150431]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 41)\n",
      "act action : 19\n",
      "reward: 29.468405106586612\n",
      "current reward: 29.468405106586612; current state: [27.666666666666668, 1.9840281502066848]\n",
      "maximizing action\n",
      "[0.         0.         0.         0.         5.92427707 0.        ]\n",
      "Current action = 31, current state (113, 9)\n",
      "act action : 31\n",
      "reward: 28.74418258805967\n",
      "current reward: 28.74418258805967; current state: [29.51851851851852, 2.6575198277425582]\n",
      "maximizing action\n",
      "[17.54863586  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 28.92281677194485\n",
      "current reward: 28.92281677194485; current state: [26.185185185185187, 7.406506849675326]\n",
      "maximizing action\n",
      "[5.22635592 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 28.70810338605165\n",
      "current reward: 28.70810338605165; current state: [29.51851851851852, 0.5705796574469051]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 5)\n",
      "act action : 19\n",
      "reward: 28.85243175604805\n",
      "current reward: 28.85243175604805; current state: [26.185185185185187, 9.310325279883761]\n",
      "maximizing action\n",
      "[5.51940426 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (107, 39)\n",
      "act action : 19\n",
      "reward: 28.72182868366824\n",
      "current reward: 28.72182868366824; current state: [26.925925925925927, 6.687639201534302]\n",
      "maximizing action\n",
      "[27.62310927  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 28.867104007189955\n",
      "current reward: 28.867104007189955; current state: [31.22222222222222, 2.1621122020516967]\n",
      "exploring action\n",
      "Current action = 25, current state (127, 11)\n",
      "act action : 25\n",
      "reward: 29.957291988279852\n",
      "current reward: 29.957291988279852; current state: [28.703703703703702, 4.85649134645402]\n",
      "maximizing action\n",
      "[22.78764016  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 28.819519458809292\n",
      "current reward: 28.819519458809292; current state: [26.185185185185187, 3.4960403882502438]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 15)\n",
      "act action : 19\n",
      "reward: 29.090139045058354\n",
      "current reward: 29.090139045058354; current state: [22.40740740740741, 13.390295027592064]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 55)\n",
      "act action : 19\n",
      "reward: 28.939100712995852\n",
      "current reward: 28.939100712995852; current state: [31.22222222222222, 2.4754641891486076]\n",
      "maximizing action\n",
      "[0.        0.        5.9914584 0.        0.        0.       ]\n",
      "Current action = 25, current state (127, 11)\n",
      "act action : 25\n",
      "reward: 28.977197139080364\n",
      "current reward: 28.977197139080364; current state: [26.666666666666668, 9.709840026396323]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 41)\n",
      "act action : 19\n",
      "reward: 28.441069605384154\n",
      "current reward: 28.441069605384154; current state: [25.88888888888889, 3.979820308731889]\n",
      "maximizing action\n",
      "[5.23252752 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 28.606874301197433\n",
      "current reward: 28.606874301197433; current state: [21.666666666666668, 15.047722591637614]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 63)\n",
      "act action : 19\n",
      "reward: 28.781915204676427\n",
      "current reward: 28.781915204676427; current state: [21.666666666666668, 5.6959218803997675]\n",
      "maximizing action\n",
      "[5.50408094 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (89, 25)\n",
      "act action : 19\n",
      "reward: 30.069901836688757\n",
      "current reward: 30.069901836688757; current state: [25.88888888888889, 4.227142616930242]\n",
      "maximizing action\n",
      "[5.59866198 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 19)\n",
      "act action : 19\n",
      "reward: 28.529972306415107\n",
      "current reward: 28.529972306415107; current state: [26.555555555555557, 5.258058406083758]\n",
      "maximizing action\n",
      "[5.44698602 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 28.448723632606217\n",
      "current reward: 28.448723632606217; current state: [25.11111111111111, 3.6920805051535632]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 17)\n",
      "act action : 19\n",
      "reward: 28.663605599582493\n",
      "current reward: 28.663605599582493; current state: [26.25925925925926, 0.37205776173569244]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 3)\n",
      "act action : 19\n",
      "reward: 30.16192091830911\n",
      "current reward: 30.16192091830911; current state: [22.814814814814813, 13.114274801966156]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (93, 55)\n",
      "act action : 19\n",
      "reward: 30.066251445552634\n",
      "current reward: 30.066251445552634; current state: [23.51851851851852, 5.475162478166003]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 23)\n",
      "act action : 19\n",
      "reward: 28.75986315725477\n",
      "current reward: 28.75986315725477; current state: [28.555555555555557, 0.9211231050906036]\n",
      "maximizing action\n",
      "[5.34751138 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 5)\n",
      "act action : 19\n",
      "reward: 28.831007001046412\n",
      "current reward: 28.831007001046412; current state: [28.25925925925926, 2.67031447305642]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 28.977686975091817\n",
      "current reward: 28.977686975091817; current state: [24.703703703703702, 10.279205317105871]\n",
      "exploring action\n",
      "Current action = 31, current state (101, 43)\n",
      "act action : 31\n",
      "reward: 29.75133496372149\n",
      "current reward: 29.75133496372149; current state: [29.444444444444443, 4.544363479100986]\n",
      "maximizing action\n",
      "[0.         0.         5.85972072 0.         0.         0.        ]\n",
      "Current action = 25, current state (119, 21)\n",
      "act action : 25\n",
      "reward: 29.333033641174293\n",
      "current reward: 29.333033641174293; current state: [24.703703703703702, 10.724141827735654]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 45)\n",
      "act action : 19\n",
      "reward: 29.101680428914904\n",
      "current reward: 29.101680428914904; current state: [23.962962962962962, 8.58539452013118]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 37)\n",
      "act action : 19\n",
      "reward: 30.015128672528018\n",
      "current reward: 30.015128672528018; current state: [25.88888888888889, 3.647610282242923]\n",
      "maximizing action\n",
      "[10.95390238  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 17)\n",
      "act action : 19\n",
      "reward: 28.6516452884118\n",
      "current reward: 28.6516452884118; current state: [27.074074074074073, 4.05973232536807]\n",
      "maximizing action\n",
      "[22.59219017  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 28.85684333306547\n",
      "current reward: 28.85684333306547; current state: [29.444444444444443, 3.733277722070753]\n",
      "maximizing action\n",
      "[5.27546641 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 28.91247990244435\n",
      "current reward: 28.91247990244435; current state: [24.22222222222222, 7.773278185098202]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 28.598929793943253\n",
      "current reward: 28.598929793943253; current state: [25.444444444444443, 0.5507014963661094]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 5)\n",
      "act action : 19\n",
      "reward: 29.413487964668008\n",
      "current reward: 29.413487964668008; current state: [25.444444444444443, 7.690354334048323]\n",
      "maximizing action\n",
      "[5.49451025 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 28.29177972433335\n",
      "current reward: 28.29177972433335; current state: [22.333333333333332, 6.00324979725437]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 27)\n",
      "act action : 19\n",
      "reward: 28.38100235875392\n",
      "current reward: 28.38100235875392; current state: [25.444444444444443, 5.460459743220413]\n",
      "maximizing action\n",
      "[11.47479946  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 28.764947211386936\n",
      "current reward: 28.764947211386936; current state: [28.25925925925926, 4.397269381697615]\n",
      "maximizing action\n",
      "[17.3337822  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 28.309282907117677\n",
      "current reward: 28.309282907117677; current state: [21.77777777777778, 13.668196113561878]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 57)\n",
      "act action : 19\n",
      "reward: 28.376721103505076\n",
      "current reward: 28.376721103505076; current state: [28.25925925925926, 2.2081665538103894]\n",
      "maximizing action\n",
      "[11.45179439  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 11)\n",
      "act action : 19\n",
      "reward: 28.83383864368014\n",
      "current reward: 28.83383864368014; current state: [29.703703703703702, 4.39613128717989]\n",
      "maximizing action\n",
      "[5.57074275 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.09448150926529\n",
      "current reward: 28.09448150926529; current state: [28.25925925925926, 8.125642356086338]\n",
      "maximizing action\n",
      "[5.31686495 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 35)\n",
      "act action : 19\n",
      "reward: 27.94971675376551\n",
      "current reward: 27.94971675376551; current state: [27.666666666666668, 4.156387775684463]\n",
      "maximizing action\n",
      "[16.76812908  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 28.211237780709272\n",
      "current reward: 28.211237780709272; current state: [29.703703703703702, 2.869187175234836]\n",
      "maximizing action\n",
      "[23.33319921  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 27.351961868739654\n",
      "current reward: 27.351961868739654; current state: [24.333333333333332, 6.1558716423919915]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 27)\n",
      "act action : 19\n",
      "reward: 28.29507589555637\n",
      "current reward: 28.29507589555637; current state: [24.333333333333332, 2.8683935646317362]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 13)\n",
      "act action : 19\n",
      "reward: 27.107898122222988\n",
      "current reward: 27.107898122222988; current state: [23.962962962962962, 7.97787873589708]\n",
      "maximizing action\n",
      "[5.58043505 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 33)\n",
      "act action : 19\n",
      "reward: 27.249021462663407\n",
      "current reward: 27.249021462663407; current state: [25.11111111111111, 2.7287581747446663]\n",
      "maximizing action\n",
      "[5.37202488 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 13)\n",
      "act action : 19\n",
      "reward: 28.27812139334434\n",
      "current reward: 28.27812139334434; current state: [22.333333333333332, 8.299749026232812]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 35)\n",
      "act action : 19\n",
      "reward: 27.645246679890036\n",
      "current reward: 27.645246679890036; current state: [23.51851851851852, 6.043178194326317]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 27)\n",
      "act action : 19\n",
      "reward: 27.186614656114134\n",
      "current reward: 27.186614656114134; current state: [25.88888888888889, 7.06658349312478]\n",
      "maximizing action\n",
      "[16.1008678  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 27.47854328982466\n",
      "current reward: 27.47854328982466; current state: [29.444444444444443, 1.964802457014832]\n",
      "maximizing action\n",
      "[16.6750992  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 27.753526047446865\n",
      "current reward: 27.753526047446865; current state: [27.074074074074073, 6.781192208349045]\n",
      "maximizing action\n",
      "[22.94081941  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 28.667134099852415\n",
      "current reward: 28.667134099852415; current state: [26.666666666666668, 5.991741857800042]\n",
      "maximizing action\n",
      "[5.34766388 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 29.338442295870834\n",
      "current reward: 29.338442295870834; current state: [30.333333333333332, 0.04835039817974972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 3)\n",
      "act action : 19\n",
      "reward: 27.415220003416135\n",
      "current reward: 27.415220003416135; current state: [28.703703703703702, 10.416258667847288]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 43)\n",
      "act action : 19\n",
      "reward: 27.414610468733628\n",
      "current reward: 27.414610468733628; current state: [28.703703703703702, 6.690229971804054]\n",
      "maximizing action\n",
      "[5.639421 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 29.500621126129104\n",
      "current reward: 29.500621126129104; current state: [26.666666666666668, 6.334795600280639]\n",
      "maximizing action\n",
      "[5.4214147 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 27.64814338967004\n",
      "current reward: 27.64814338967004; current state: [25.444444444444443, 9.513718222335125]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 41)\n",
      "act action : 19\n",
      "reward: 29.608027697953798\n",
      "current reward: 29.608027697953798; current state: [26.666666666666668, 3.802210973733539]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 17)\n",
      "act action : 19\n",
      "reward: 27.627477258282735\n",
      "current reward: 27.627477258282735; current state: [23.666666666666668, 8.183314076469385]\n",
      "maximizing action\n",
      "[5.94012767 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 35)\n",
      "act action : 19\n",
      "reward: 27.71755374087073\n",
      "current reward: 27.71755374087073; current state: [24.925925925925927, 10.962519805652262]\n",
      "maximizing action\n",
      "[5.82033609 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 45)\n",
      "act action : 19\n",
      "reward: 27.769929467719663\n",
      "current reward: 27.769929467719663; current state: [29.11111111111111, 2.1229795666844873]\n",
      "maximizing action\n",
      "[16.48196603  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 27.36580322485229\n",
      "current reward: 27.36580322485229; current state: [26.666666666666668, 9.48467263760692]\n",
      "maximizing action\n",
      "[16.78148265  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 39)\n",
      "act action : 19\n",
      "reward: 27.575947187185665\n",
      "current reward: 27.575947187185665; current state: [31.555555555555557, 3.793972006998177]\n",
      "maximizing action\n",
      "[22.63632654  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 27.52458654152259\n",
      "current reward: 27.52458654152259; current state: [32.48148148148148, 0.9755721059823533]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 5)\n",
      "act action : 19\n",
      "reward: 27.80302383924187\n",
      "current reward: 27.80302383924187; current state: [28.703703703703702, 8.123285819087263]\n",
      "maximizing action\n",
      "[6.23407228 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 35)\n",
      "act action : 19\n",
      "reward: 27.76077785482089\n",
      "current reward: 27.76077785482089; current state: [28.22222222222222, 5.971596272134288]\n",
      "exploring action\n",
      "Current action = 31, current state (115, 25)\n",
      "act action : 31\n",
      "reward: 27.886203300813364\n",
      "current reward: 27.886203300813364; current state: [25.62962962962963, 4.877591065802522]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 21)\n",
      "act action : 19\n",
      "reward: 28.042963420897184\n",
      "current reward: 28.042963420897184; current state: [28.22222222222222, 2.682279097550499]\n",
      "maximizing action\n",
      "[5.7955374 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 27.490508580241876\n",
      "current reward: 27.490508580241876; current state: [30.814814814814813, 5.780951357970958]\n",
      "maximizing action\n",
      "[17.06616767  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 27.572724210548206\n",
      "current reward: 27.572724210548206; current state: [29.11111111111111, 6.995089652633189]\n",
      "maximizing action\n",
      "[17.21962637  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 29.32906048416892\n",
      "current reward: 29.32906048416892; current state: [24.22222222222222, 12.497692939675481]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 51)\n",
      "act action : 19\n",
      "reward: 29.316532298608994\n",
      "current reward: 29.316532298608994; current state: [25.11111111111111, 7.69364602836796]\n",
      "maximizing action\n",
      "[11.15286619  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 26.59056441436225\n",
      "current reward: 26.59056441436225; current state: [27.88888888888889, 2.9311745766026047]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 13)\n",
      "act action : 19\n",
      "reward: 26.805389985053115\n",
      "current reward: 26.805389985053115; current state: [29.11111111111111, 6.674855659206989]\n",
      "maximizing action\n",
      "[23.08543846  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 29)\n",
      "act action : 19\n",
      "reward: 26.88433261948613\n",
      "current reward: 26.88433261948613; current state: [28.25925925925926, 6.638330042704983]\n",
      "maximizing action\n",
      "[16.21423152  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 28.004650901900835\n",
      "current reward: 28.004650901900835; current state: [27.88888888888889, 5.446745831311616]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 23)\n",
      "act action : 19\n",
      "reward: 26.59311351266091\n",
      "current reward: 26.59311351266091; current state: [27.074074074074073, 6.050306547447153]\n",
      "maximizing action\n",
      "[5.37925919 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 27.09251998648874\n",
      "current reward: 27.09251998648874; current state: [29.11111111111111, 7.312408623377025]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (119, 31)\n",
      "act action : 19\n",
      "reward: 27.233663290232325\n",
      "current reward: 27.233663290232325; current state: [27.88888888888889, 5.351452182291827]\n",
      "maximizing action\n",
      "[5.3186227 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (113, 23)\n",
      "act action : 19\n",
      "reward: 26.602296039365807\n",
      "current reward: 26.602296039365807; current state: [27.88888888888889, 4.991656160072137]\n",
      "maximizing action\n",
      "[5.68028176 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 27.51408191493587\n",
      "current reward: 27.51408191493587; current state: [26.185185185185187, 4.478110622500533]\n",
      "maximizing action\n",
      "[16.15045773  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 19)\n",
      "act action : 19\n",
      "reward: 27.785904370565067\n",
      "current reward: 27.785904370565067; current state: [21.14814814814815, 10.97727145673672]\n",
      "maximizing action\n",
      "[5.89779359 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (87, 45)\n",
      "act action : 19\n",
      "reward: 26.288390838066153\n",
      "current reward: 26.288390838066153; current state: [24.22222222222222, 8.376263940324732]\n",
      "maximizing action\n",
      "[6.09959327 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 35)\n",
      "act action : 19\n",
      "reward: 26.610302951624764\n",
      "current reward: 26.610302951624764; current state: [25.444444444444443, 7.016789856655329]\n",
      "maximizing action\n",
      "[10.72011815  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 31)\n",
      "act action : 19\n",
      "reward: 26.041123631629915\n",
      "current reward: 26.041123631629915; current state: [30.333333333333332, 4.595568753986994]\n",
      "maximizing action\n",
      "[5.85727238 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 21)\n",
      "act action : 19\n",
      "reward: 27.823347703601033\n",
      "current reward: 27.823347703601033; current state: [29.11111111111111, 2.4945246265804855]\n",
      "maximizing action\n",
      "[21.95512668  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 26.604548194024726\n",
      "current reward: 26.604548194024726; current state: [24.22222222222222, 11.420270743385814]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 47)\n",
      "act action : 19\n",
      "reward: 27.548376222809292\n",
      "current reward: 27.548376222809292; current state: [27.88888888888889, 2.9485994041854697]\n",
      "maximizing action\n",
      "[5.361078 0.       0.       0.       0.       0.      ]\n",
      "Current action = 19, current state (113, 13)\n",
      "act action : 19\n",
      "reward: 26.41418470353948\n",
      "current reward: 26.41418470353948; current state: [27.88888888888889, 2.891927046293509]\n",
      "maximizing action\n",
      "[10.64391494  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 13)\n",
      "act action : 19\n",
      "reward: 28.039987727514525\n",
      "current reward: 28.039987727514525; current state: [24.703703703703702, 8.325031819254185]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 35)\n",
      "act action : 19\n",
      "reward: 26.54757946749775\n",
      "current reward: 26.54757946749775; current state: [26.666666666666668, 5.927126411198391]\n",
      "maximizing action\n",
      "[11.21535234  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 26.769604844922025\n",
      "current reward: 26.769604844922025; current state: [23.0, 9.033324643060999]\n",
      "maximizing action\n",
      "[5.81629034 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 39)\n",
      "act action : 19\n",
      "reward: 28.22945566806659\n",
      "current reward: 28.22945566806659; current state: [26.666666666666668, 2.9964558934182017]\n",
      "maximizing action\n",
      "[11.44494871  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 13)\n",
      "act action : 19\n",
      "reward: 26.435643636972415\n",
      "current reward: 26.435643636972415; current state: [27.074074074074073, 3.1887916888577164]\n",
      "maximizing action\n",
      "[5.68879254 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 26.080563869316748\n",
      "current reward: 26.080563869316748; current state: [26.666666666666668, 5.953130560504214]\n",
      "maximizing action\n",
      "[16.56927331  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 25)\n",
      "act action : 19\n",
      "reward: 26.352960454406702\n",
      "current reward: 26.352960454406702; current state: [30.333333333333332, 4.450360822871141]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 19)\n",
      "act action : 19\n",
      "reward: 26.192641262103866\n",
      "current reward: 26.192641262103866; current state: [30.333333333333332, 6.562844631699341]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 29)\n",
      "act action : 19\n",
      "reward: 26.548014297931598\n",
      "current reward: 26.548014297931598; current state: [32.77777777777778, 1.9628469067756364]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 9)\n",
      "act action : 19\n",
      "reward: 26.864327006408022\n",
      "current reward: 26.864327006408022; current state: [26.666666666666668, 6.955521700378182]\n",
      "maximizing action\n",
      "[33.39653007  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 26.73940262519194\n",
      "current reward: 26.73940262519194; current state: [23.0, 6.308435267551123]\n",
      "maximizing action\n",
      "[5.72925474 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (95, 27)\n",
      "act action : 19\n",
      "reward: 27.06730600600802\n",
      "current reward: 27.06730600600802; current state: [27.88888888888889, 4.64330863116409]\n",
      "maximizing action\n",
      "[11.18309814  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 27.716351539614294\n",
      "current reward: 27.716351539614294; current state: [29.962962962962962, 2.4406075287043]\n",
      "maximizing action\n",
      "[23.33460794  0.          0.          0.          0.          5.43764091]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 29.24582575470785\n",
      "current reward: 29.24582575470785; current state: [23.51851851851852, 10.482670860161305]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 43)\n",
      "act action : 19\n",
      "reward: 26.846964235369924\n",
      "current reward: 26.846964235369924; current state: [28.25925925925926, 6.288055999584593]\n",
      "maximizing action\n",
      "[6.15780409 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 27.967640525590113\n",
      "current reward: 27.967640525590113; current state: [31.814814814814813, 0.046928327645051185]\n",
      "maximizing action\n",
      "[5.28667494 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 3)\n",
      "act action : 19\n",
      "reward: 28.064521484629974\n",
      "current reward: 28.064521484629974; current state: [30.62962962962963, 2.3315916783664252]\n",
      "maximizing action\n",
      "[0.         0.         0.         0.         0.         5.50108844]\n",
      "Current action = 33, current state (125, 11)\n",
      "act action : 33\n",
      "reward: 26.511729530538464\n",
      "current reward: 26.511729530538464; current state: [26.666666666666668, 6.922334855760537]\n",
      "maximizing action\n",
      "[38.7444106  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 29)\n",
      "act action : 19\n",
      "reward: 26.67504492837729\n",
      "current reward: 26.67504492837729; current state: [25.444444444444443, 11.174633952764944]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 47)\n",
      "act action : 19\n",
      "reward: 26.472770704568415\n",
      "current reward: 26.472770704568415; current state: [26.185185185185187, 5.382858399709996]\n",
      "maximizing action\n",
      "[32.87586868  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 26.72649244111828\n",
      "current reward: 26.72649244111828; current state: [27.444444444444443, 3.942160765627088]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 27.093797191145196\n",
      "current reward: 27.093797191145196; current state: [23.666666666666668, 9.728973026046708]\n",
      "maximizing action\n",
      "[11.23205359  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 26.831399892259203\n",
      "current reward: 26.831399892259203; current state: [24.925925925925927, 3.1967304121828977]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 15)\n",
      "act action : 19\n",
      "reward: 26.943698392977016\n",
      "current reward: 26.943698392977016; current state: [29.11111111111111, 2.108857417599399]\n",
      "maximizing action\n",
      "[27.27603632  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 11)\n",
      "act action : 19\n",
      "reward: 28.945586981765\n",
      "current reward: 28.945586981765; current state: [24.925925925925927, 12.227603887614984]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 51)\n",
      "act action : 19\n",
      "reward: 28.99964459443376\n",
      "current reward: 28.99964459443376; current state: [23.666666666666668, 5.233152434085242]\n",
      "maximizing action\n",
      "[5.75197263 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 23)\n",
      "act action : 19\n",
      "reward: 27.419809128206634\n",
      "current reward: 27.419809128206634; current state: [29.962962962962962, 3.997465725963184]\n",
      "maximizing action\n",
      "[11.4924641  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.2326368257753\n",
      "current reward: 29.2326368257753; current state: [33.407407407407405, 2.006125275899004]\n",
      "maximizing action\n",
      "[11.87407398  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (135, 11)\n",
      "act action : 19\n",
      "reward: 28.0136808995356\n",
      "current reward: 28.0136808995356; current state: [30.814814814814813, 6.558571280261401]\n",
      "maximizing action\n",
      "[5.62645418 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 29)\n",
      "act action : 19\n",
      "reward: 27.63942496859649\n",
      "current reward: 27.63942496859649; current state: [27.666666666666668, 8.637447831592867]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 37)\n",
      "act action : 19\n",
      "reward: 28.541357396760223\n",
      "current reward: 28.541357396760223; current state: [29.0, 4.901050284320375]\n",
      "maximizing action\n",
      "[ 0.          0.         11.72632745  0.          0.          0.        ]\n",
      "Current action = 25, current state (119, 21)\n",
      "act action : 25\n",
      "reward: 27.996536730536565\n",
      "current reward: 27.996536730536565; current state: [27.037037037037038, 9.9418850297179]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 41)\n",
      "act action : 19\n",
      "reward: 27.930141312934296\n",
      "current reward: 27.930141312934296; current state: [23.666666666666668, 8.958652982844555]\n",
      "maximizing action\n",
      "[6.00302573 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 37)\n",
      "act action : 19\n",
      "reward: 28.140067666718824\n",
      "current reward: 28.140067666718824; current state: [25.62962962962963, 3.0926875593134238]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 15)\n",
      "act action : 19\n",
      "reward: 28.98458497891399\n",
      "current reward: 28.98458497891399; current state: [25.62962962962963, 12.095054397067171]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 51)\n",
      "act action : 19\n",
      "reward: 28.263856998951685\n",
      "current reward: 28.263856998951685; current state: [24.925925925925927, 10.042719542136394]\n",
      "maximizing action\n",
      "[11.0545308   0.          0.          0.          5.95026699  0.        ]\n",
      "Current action = 19, current state (101, 43)\n",
      "act action : 19\n",
      "reward: 28.16852774393381\n",
      "current reward: 28.16852774393381; current state: [25.62962962962963, 5.618835162296199]\n",
      "maximizing action\n",
      "[10.97669121  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 28.8322619792402\n",
      "current reward: 28.8322619792402; current state: [31.22222222222222, 0.604669641743081]\n",
      "exploring action\n",
      "Current action = 28, current state (127, 5)\n",
      "act action : 28\n",
      "reward: 28.54367063327621\n",
      "current reward: 28.54367063327621; current state: [27.88888888888889, 8.824735799335565]\n",
      "maximizing action\n",
      "[5.70827148 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 37)\n",
      "act action : 19\n",
      "reward: 29.295076187118635\n",
      "current reward: 29.295076187118635; current state: [31.22222222222222, 2.350952558465075]\n",
      "maximizing action\n",
      "[ 0.          0.         11.78689783  0.          0.          0.        ]\n",
      "Current action = 25, current state (127, 11)\n",
      "act action : 25\n",
      "reward: 28.585429279527915\n",
      "current reward: 28.585429279527915; current state: [30.333333333333332, 3.5349218482474787]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 17)\n",
      "act action : 19\n",
      "reward: 28.443161003397886\n",
      "current reward: 28.443161003397886; current state: [22.40740740740741, 12.84970088060177]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 53)\n",
      "act action : 19\n",
      "reward: 28.560463631146828\n",
      "current reward: 28.560463631146828; current state: [24.22222222222222, 2.288362902845817]\n",
      "maximizing action\n",
      "[0.         5.69133816 0.         0.         0.         0.        ]\n",
      "Current action = 22, current state (99, 11)\n",
      "act action : 22\n",
      "reward: 27.998215125567725\n",
      "current reward: 27.998215125567725; current state: [28.703703703703702, 2.495764624609854]\n",
      "maximizing action\n",
      "[22.78839974  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 11)\n",
      "act action : 19\n",
      "reward: 28.12254421275473\n",
      "current reward: 28.12254421275473; current state: [24.22222222222222, 6.243212807498808]\n",
      "maximizing action\n",
      "[5.65901518 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 27)\n",
      "act action : 19\n",
      "reward: 29.93055614041977\n",
      "current reward: 29.93055614041977; current state: [21.77777777777778, 10.352512781264725]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 43)\n",
      "act action : 19\n",
      "reward: 27.83203954400111\n",
      "current reward: 27.83203954400111; current state: [25.444444444444443, 6.933464580476265]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 29)\n",
      "act action : 19\n",
      "reward: 28.05122011230853\n",
      "current reward: 28.05122011230853; current state: [26.666666666666668, 7.653754556340812]\n",
      "maximizing action\n",
      "[5.49455337 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 29.62712953005779\n",
      "current reward: 29.62712953005779; current state: [23.666666666666668, 8.997111519591247]\n",
      "maximizing action\n",
      "[11.63103927  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 37)\n",
      "act action : 19\n",
      "reward: 28.27886824302446\n",
      "current reward: 28.27886824302446; current state: [28.703703703703702, 1.062965229387625]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 7)\n",
      "act action : 19\n",
      "reward: 29.837896623197565\n",
      "current reward: 29.837896623197565; current state: [32.48148148148148, 1.870796974658619]\n",
      "maximizing action\n",
      "[5.25868001 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 28.126552020632474\n",
      "current reward: 28.126552020632474; current state: [32.111111111111114, 2.281862013317894]\n",
      "maximizing action\n",
      "[11.57967517  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 28.22755253132421\n",
      "current reward: 28.22755253132421; current state: [28.22222222222222, 4.047487877763253]\n",
      "maximizing action\n",
      "[22.99563878  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 27.901725742690047\n",
      "current reward: 27.901725742690047; current state: [26.333333333333332, 11.096550648528515]\n",
      "maximizing action\n",
      "[11.4255298  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 47)\n",
      "act action : 19\n",
      "reward: 28.106409538343268\n",
      "current reward: 28.106409538343268; current state: [34.333333333333336, 2.1047111268482315]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 11)\n",
      "act action : 19\n",
      "reward: 29.363689559368325\n",
      "current reward: 29.363689559368325; current state: [28.40740740740741, 8.849798558660094]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 37)\n",
      "act action : 19\n",
      "reward: 27.757459277908595\n",
      "current reward: 27.757459277908595; current state: [25.0, 9.678197464823013]\n",
      "maximizing action\n",
      "[5.92160554 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 41)\n",
      "act action : 19\n",
      "reward: 28.17254477768593\n",
      "current reward: 28.17254477768593; current state: [26.333333333333332, 4.938141725705794]\n",
      "maximizing action\n",
      "[11.69597993  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 29.29292156658191\n",
      "current reward: 29.29292156658191; current state: [28.22222222222222, 3.2106941722043882]\n",
      "maximizing action\n",
      "[6.01820765 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 15)\n",
      "act action : 19\n",
      "reward: 27.733505677963127\n",
      "current reward: 27.733505677963127; current state: [28.703703703703702, 5.233520022028694]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         11.68173247]\n",
      "Current action = 33, current state (117, 23)\n",
      "act action : 33\n",
      "reward: 27.309816621399985\n",
      "current reward: 27.309816621399985; current state: [27.444444444444443, 6.074007082939284]\n",
      "maximizing action\n",
      "[10.79776319  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.894588712376958\n",
      "current reward: 28.894588712376958; current state: [28.703703703703702, 7.45236317047496]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 31)\n",
      "act action : 19\n",
      "reward: 27.81583802908484\n",
      "current reward: 27.81583802908484; current state: [29.962962962962962, 5.527844767714186]\n",
      "maximizing action\n",
      "[23.12466775  0.          5.73517676  0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 27.665381530199213\n",
      "current reward: 27.665381530199213; current state: [28.22222222222222, 9.350719151656014]\n",
      "maximizing action\n",
      "[5.86434244 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 39)\n",
      "act action : 19\n",
      "reward: 28.24250953587098\n",
      "current reward: 28.24250953587098; current state: [34.7037037037037, 0.05119453924914677]\n",
      "maximizing action\n",
      "[6.09945313 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (141, 3)\n",
      "act action : 19\n",
      "reward: 28.09771300289061\n",
      "current reward: 28.09771300289061; current state: [32.111111111111114, 4.926688689099127]\n",
      "maximizing action\n",
      "[11.04282517  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 21)\n",
      "act action : 19\n",
      "reward: 27.79470813301504\n",
      "current reward: 27.79470813301504; current state: [24.925925925925927, 11.02421288236892]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 47)\n",
      "act action : 19\n",
      "reward: 27.761124128214487\n",
      "current reward: 27.761124128214487; current state: [30.814814814814813, 3.316795812867485]\n",
      "exploring action\n",
      "Current action = 28, current state (125, 15)\n",
      "act action : 28\n",
      "reward: 27.754129872660826\n",
      "current reward: 27.754129872660826; current state: [28.703703703703702, 7.427142995212141]\n",
      "maximizing action\n",
      "[5.56316761 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 31)\n",
      "act action : 19\n",
      "reward: 27.880689647655085\n",
      "current reward: 27.880689647655085; current state: [29.962962962962962, 3.9553517198264068]\n",
      "maximizing action\n",
      "[17.33899146  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 28.487059186959126\n",
      "current reward: 28.487059186959126; current state: [28.22222222222222, 5.210665258932602]\n",
      "exploring action\n",
      "Current action = 25, current state (115, 23)\n",
      "act action : 25\n",
      "reward: 29.645051395881733\n",
      "current reward: 29.645051395881733; current state: [26.925925925925927, 8.057220434468407]\n",
      "maximizing action\n",
      "[10.68345603  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 35)\n",
      "act action : 19\n",
      "reward: 27.625782754556734\n",
      "current reward: 27.625782754556734; current state: [27.666666666666668, 7.88567877961442]\n",
      "maximizing action\n",
      "[5.32145456 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 33)\n",
      "act action : 19\n",
      "reward: 28.02931085620394\n",
      "current reward: 28.02931085620394; current state: [29.0, 4.03071940328579]\n",
      "maximizing action\n",
      "[17.6334212  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 30.642114415462885\n",
      "current reward: 30.642114415462885; current state: [29.0, 8.601058132724686]\n",
      "maximizing action\n",
      "[5.68420826 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 37)\n",
      "act action : 19\n",
      "reward: 28.211421483925168\n",
      "current reward: 28.211421483925168; current state: [35.666666666666664, 1.163789841323714]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (145, 7)\n",
      "act action : 19\n",
      "reward: 28.465645294482794\n",
      "current reward: 28.465645294482794; current state: [34.333333333333336, 0.7119156550535775]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (139, 5)\n",
      "act action : 19\n",
      "reward: 28.615158410493617\n",
      "current reward: 28.615158410493617; current state: [22.925925925925927, 13.064387203364173]\n",
      "maximizing action\n",
      "[6.01325029 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (93, 55)\n",
      "act action : 19\n",
      "reward: 28.938121257708648\n",
      "current reward: 28.938121257708648; current state: [24.333333333333332, 4.750657723513091]\n",
      "maximizing action\n",
      "[6.21662692 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 21)\n",
      "act action : 19\n",
      "reward: 28.525417719037645\n",
      "current reward: 28.525417719037645; current state: [27.666666666666668, 4.138410648234294]\n",
      "maximizing action\n",
      "[22.41037664  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 28.848864437337397\n",
      "current reward: 28.848864437337397; current state: [30.814814814814813, 2.403448449889304]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         10.80343435]\n",
      "Current action = 33, current state (125, 11)\n",
      "act action : 33\n",
      "reward: 29.01132447038187\n",
      "current reward: 29.01132447038187; current state: [26.185185185185187, 7.264610983215629]\n",
      "maximizing action\n",
      "[10.9679766  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 31)\n",
      "act action : 19\n",
      "reward: 29.89376683410587\n",
      "current reward: 29.89376683410587; current state: [23.666666666666668, 6.152701364706912]\n",
      "maximizing action\n",
      "[5.43732293 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 27)\n",
      "act action : 19\n",
      "reward: 28.93708181232544\n",
      "current reward: 28.93708181232544; current state: [26.185185185185187, 5.1882119369021495]\n",
      "maximizing action\n",
      "[38.22116717  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 29.036302410345723\n",
      "current reward: 29.036302410345723; current state: [28.22222222222222, 6.017132472169078]\n",
      "maximizing action\n",
      "[11.7513322  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 29.251099899611372\n",
      "current reward: 29.251099899611372; current state: [29.51851851851852, 2.3203309623373625]\n",
      "maximizing action\n",
      "[29.18377309  0.          0.          0.          0.          5.43764091]\n",
      "Current action = 19, current state (121, 11)\n",
      "act action : 19\n",
      "reward: 29.381507619417665\n",
      "current reward: 29.381507619417665; current state: [32.48148148148148, 3.1633030347558795]\n",
      "maximizing action\n",
      "[ 0.         11.36865128  0.          0.          0.          0.        ]\n",
      "Current action = 22, current state (131, 15)\n",
      "act action : 22\n",
      "reward: 29.019154035420865\n",
      "current reward: 29.019154035420865; current state: [28.22222222222222, 4.077344325257185]\n",
      "maximizing action\n",
      "[28.56604133  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 30.366919372486365\n",
      "current reward: 30.366919372486365; current state: [25.62962962962963, 4.263384700077096]\n",
      "maximizing action\n",
      "[11.30465644  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 19)\n",
      "act action : 19\n",
      "reward: 29.958891119754586\n",
      "current reward: 29.958891119754586; current state: [25.62962962962963, 9.693823087055195]\n",
      "maximizing action\n",
      "[5.28365097 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 41)\n",
      "act action : 19\n",
      "reward: 29.033237973987998\n",
      "current reward: 29.033237973987998; current state: [30.814814814814813, 0.05119453924914677]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 3)\n",
      "act action : 19\n",
      "reward: 29.56790688697424\n",
      "current reward: 29.56790688697424; current state: [30.814814814814813, 5.243191499084303]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 23)\n",
      "act action : 19\n",
      "reward: 28.584332909145928\n",
      "current reward: 28.584332909145928; current state: [26.185185185185187, 5.874196851502198]\n",
      "maximizing action\n",
      "[10.77482799  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 28.763418994241253\n",
      "current reward: 28.763418994241253; current state: [27.444444444444443, 7.314741873163039]\n",
      "exploring action\n",
      "Current action = 31, current state (111, 31)\n",
      "act action : 31\n",
      "reward: 28.621745991111695\n",
      "current reward: 28.621745991111695; current state: [30.814814814814813, 2.585974474364834]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 13)\n",
      "act action : 19\n",
      "reward: 29.778954551607914\n",
      "current reward: 29.778954551607914; current state: [26.925925925925927, 5.473553364559044]\n",
      "maximizing action\n",
      "[11.13673075  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.725549991618365\n",
      "current reward: 29.725549991618365; current state: [29.51851851851852, 3.48140461928869]\n",
      "exploring action\n",
      "Current action = 22, current state (121, 15)\n",
      "act action : 22\n",
      "reward: 28.377832536177966\n",
      "current reward: 28.377832536177966; current state: [24.333333333333332, 10.543826753781875]\n",
      "maximizing action\n",
      "[5.83356431 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 45)\n",
      "act action : 19\n",
      "reward: 29.601629266754625\n",
      "current reward: 29.601629266754625; current state: [26.925925925925927, 4.151352612924315]\n",
      "maximizing action\n",
      "[38.39642637  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 28.646210409336863\n",
      "current reward: 28.646210409336863; current state: [27.666666666666668, 4.818153956301803]\n",
      "maximizing action\n",
      "[16.72636845  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 21)\n",
      "act action : 19\n",
      "reward: 29.72188866259506\n",
      "current reward: 29.72188866259506; current state: [23.037037037037038, 5.826422613039422]\n",
      "maximizing action\n",
      "[11.44465322  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (95, 25)\n",
      "act action : 19\n",
      "reward: 28.32977084214659\n",
      "current reward: 28.32977084214659; current state: [24.333333333333332, 5.763151475370339]\n",
      "maximizing action\n",
      "[6.12265586 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 25)\n",
      "act action : 19\n",
      "reward: 28.59486688591144\n",
      "current reward: 28.59486688591144; current state: [29.51851851851852, 6.224571317271402]\n",
      "maximizing action\n",
      "[23.11700362  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 27)\n",
      "act action : 19\n",
      "reward: 29.01751566525286\n",
      "current reward: 29.01751566525286; current state: [26.185185185185187, 7.555472145508081]\n",
      "maximizing action\n",
      "[16.1111736  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 28.57633254018751\n",
      "current reward: 28.57633254018751; current state: [24.22222222222222, 2.2640152853600353]\n",
      "maximizing action\n",
      "[ 0.         11.29098119  0.          0.          0.          0.        ]\n",
      "Current action = 22, current state (99, 11)\n",
      "act action : 22\n",
      "reward: 28.451675256925128\n",
      "current reward: 28.451675256925128; current state: [27.88888888888889, 6.210490722848906]\n",
      "maximizing action\n",
      "[11.42509853  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 29.146391673072813\n",
      "current reward: 29.146391673072813; current state: [26.666666666666668, 7.614236343130385]\n",
      "maximizing action\n",
      "[11.41997928  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 28.66684656874465\n",
      "current reward: 28.66684656874465; current state: [22.814814814814813, 5.123447545844999]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (93, 23)\n",
      "act action : 19\n",
      "reward: 28.525084693169788\n",
      "current reward: 28.525084693169788; current state: [29.444444444444443, 2.5950453748102613]\n",
      "maximizing action\n",
      "[5.42573704 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 13)\n",
      "act action : 19\n",
      "reward: 29.295342134252042\n",
      "current reward: 29.295342134252042; current state: [25.88888888888889, 10.389263464132963]\n",
      "maximizing action\n",
      "[5.73673798 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 43)\n",
      "act action : 19\n",
      "reward: 29.324058621884674\n",
      "current reward: 29.324058621884674; current state: [24.703703703703702, 2.863900833732447]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 13)\n",
      "act action : 19\n",
      "reward: 28.113346865814453\n",
      "current reward: 28.113346865814453; current state: [24.22222222222222, 7.615554908454657]\n",
      "maximizing action\n",
      "[5.71978596 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 27.990196756013912\n",
      "current reward: 27.990196756013912; current state: [24.703703703703702, 8.646914931904709]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 28.498258269215636\n",
      "current reward: 28.498258269215636; current state: [30.333333333333332, 2.1944256953836883]\n",
      "maximizing action\n",
      "[5.85626366 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 27.83590455897721\n",
      "current reward: 27.83590455897721; current state: [28.25925925925926, 6.779439002418957]\n",
      "maximizing action\n",
      "[21.8151617  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 27.695114061620625\n",
      "current reward: 27.695114061620625; current state: [24.22222222222222, 10.155968177103121]\n",
      "maximizing action\n",
      "[11.20987289  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 43)\n",
      "act action : 19\n",
      "reward: 29.004126662281138\n",
      "current reward: 29.004126662281138; current state: [26.25925925925926, 3.573839455838256]\n",
      "exploring action\n",
      "Current action = 22, current state (107, 17)\n",
      "act action : 22\n",
      "reward: 29.113548558544966\n",
      "current reward: 29.113548558544966; current state: [22.814814814814813, 5.693114568759682]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (93, 25)\n",
      "act action : 19\n",
      "reward: 27.934359290198326\n",
      "current reward: 27.934359290198326; current state: [24.703703703703702, 3.1272037903943035]\n",
      "exploring action\n",
      "Current action = 28, current state (101, 15)\n",
      "act action : 28\n",
      "reward: 29.58431579598943\n",
      "current reward: 29.58431579598943; current state: [28.25925925925926, 2.919261582367622]\n",
      "maximizing action\n",
      "[11.29363911  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 28.004422033317912\n",
      "current reward: 28.004422033317912; current state: [25.444444444444443, 5.871849936398284]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 25)\n",
      "act action : 19\n",
      "reward: 28.30414330576895\n",
      "current reward: 28.30414330576895; current state: [26.666666666666668, 5.399006107050475]\n",
      "maximizing action\n",
      "[17.08184075  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 28.5521769839485\n",
      "current reward: 28.5521769839485; current state: [30.333333333333332, 3.1452955797318505]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 15)\n",
      "act action : 19\n",
      "reward: 29.0989778769581\n",
      "current reward: 29.0989778769581; current state: [32.48148148148148, 2.1128840344729856]\n",
      "maximizing action\n",
      "[17.22518568  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 11)\n",
      "act action : 19\n",
      "reward: 28.586960313634975\n",
      "current reward: 28.586960313634975; current state: [23.51851851851852, 11.390193867202115]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 47)\n",
      "act action : 19\n",
      "reward: 28.562766011969074\n",
      "current reward: 28.562766011969074; current state: [23.0, 2.712970082190054]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 13)\n",
      "act action : 19\n",
      "reward: 28.280500309609707\n",
      "current reward: 28.280500309609707; current state: [25.444444444444443, 9.830260182908463]\n",
      "maximizing action\n",
      "[11.5561145  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (103, 41)\n",
      "act action : 19\n",
      "reward: 28.398624346989013\n",
      "current reward: 28.398624346989013; current state: [32.48148148148148, 4.079474212240269]\n",
      "maximizing action\n",
      "[10.49893406  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 19)\n",
      "act action : 19\n",
      "reward: 30.025196417877368\n",
      "current reward: 30.025196417877368; current state: [28.703703703703702, 3.8266720402846803]\n",
      "maximizing action\n",
      "[5.97550457 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 28.71155426145172\n",
      "current reward: 28.71155426145172; current state: [23.0, 12.538594913514045]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 53)\n",
      "act action : 19\n",
      "reward: 28.975483184969193\n",
      "current reward: 28.975483184969193; current state: [29.11111111111111, 1.54813349412657]\n",
      "maximizing action\n",
      "[22.22580441  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 9)\n",
      "act action : 19\n",
      "reward: 28.349017691852797\n",
      "current reward: 28.349017691852797; current state: [29.11111111111111, 4.209570095930223]\n",
      "maximizing action\n",
      "[23.76184408  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 29.09983527544449\n",
      "current reward: 29.09983527544449; current state: [21.14814814814815, 17.611297949521273]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 73)\n",
      "act action : 19\n",
      "reward: 28.14672681965642\n",
      "current reward: 28.14672681965642; current state: [26.666666666666668, 2.013362411627284]\n",
      "maximizing action\n",
      "[5.62577394 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 11)\n",
      "act action : 19\n",
      "reward: 28.26744879870677\n",
      "current reward: 28.26744879870677; current state: [29.11111111111111, 3.185717609462518]\n",
      "maximizing action\n",
      "[5.70388574 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 29.311110791418827\n",
      "current reward: 29.311110791418827; current state: [27.444444444444443, 6.759869710291495]\n",
      "exploring action\n",
      "Current action = 28, current state (111, 29)\n",
      "act action : 28\n",
      "reward: 27.902031567973932\n",
      "current reward: 27.902031567973932; current state: [24.925925925925927, 9.911823697135285]\n",
      "maximizing action\n",
      "[6.06210784 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 41)\n",
      "act action : 19\n",
      "reward: 27.718284783951216\n",
      "current reward: 27.718284783951216; current state: [22.333333333333332, 5.202875315085042]\n",
      "exploring action\n",
      "Current action = 25, current state (91, 23)\n",
      "act action : 25\n",
      "reward: 27.90386369328259\n",
      "current reward: 27.90386369328259; current state: [25.88888888888889, 5.22285880599644]\n",
      "maximizing action\n",
      "[23.8133592  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 27.105696282999265\n",
      "current reward: 27.105696282999265; current state: [31.22222222222222, 0.39399656992510934]\n",
      "maximizing action\n",
      "[5.76175183 0.         0.         5.66499404 0.         0.        ]\n",
      "Current action = 19, current state (127, 3)\n",
      "act action : 19\n",
      "reward: 27.24422908818764\n",
      "current reward: 27.24422908818764; current state: [31.22222222222222, 3.2948805439952573]\n",
      "maximizing action\n",
      "[11.31837728  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (127, 15)\n",
      "act action : 19\n",
      "reward: 29.16198098571557\n",
      "current reward: 29.16198098571557; current state: [26.666666666666668, 7.28989662278156]\n",
      "maximizing action\n",
      "[10.74536308  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 29.252926261274705\n",
      "current reward: 29.252926261274705; current state: [28.25925925925926, 1.875290913874673]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 9)\n",
      "act action : 19\n",
      "reward: 26.902728705722307\n",
      "current reward: 26.902728705722307; current state: [25.444444444444443, 8.450037796160768]\n",
      "maximizing action\n",
      "[5.55331503 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 27.13772326796185\n",
      "current reward: 27.13772326796185; current state: [27.88888888888889, 2.704201632037569]\n",
      "maximizing action\n",
      "[16.25191248  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 13)\n",
      "act action : 19\n",
      "reward: 26.730978938051404\n",
      "current reward: 26.730978938051404; current state: [28.703703703703702, 6.955444223006992]\n",
      "maximizing action\n",
      "[11.53954523  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 26.90589371087825\n",
      "current reward: 26.90589371087825; current state: [23.666666666666668, 9.568422086107773]\n",
      "maximizing action\n",
      "[16.59833357  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 41)\n",
      "act action : 19\n",
      "reward: 27.42833410165088\n",
      "current reward: 27.42833410165088; current state: [26.185185185185187, 4.981686840806499]\n",
      "maximizing action\n",
      "[17.55456425  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 27.05579360559472\n",
      "current reward: 27.05579360559472; current state: [26.925925925925927, 5.301188422922661]\n",
      "maximizing action\n",
      "[22.79227614  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.24905521746687\n",
      "current reward: 29.24905521746687; current state: [24.333333333333332, 7.704928903970274]\n",
      "maximizing action\n",
      "[11.31782531  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 27.55394926748375\n",
      "current reward: 27.55394926748375; current state: [31.22222222222222, 0.9320443497448321]\n",
      "maximizing action\n",
      "[5.84023018 0.         0.         5.70873413 0.         0.        ]\n",
      "Current action = 19, current state (127, 5)\n",
      "act action : 19\n",
      "reward: 27.185409963039557\n",
      "current reward: 27.185409963039557; current state: [29.11111111111111, 3.4036037735646514]\n",
      "maximizing action\n",
      "[11.5661079  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 28.979807778254607\n",
      "current reward: 28.979807778254607; current state: [27.444444444444443, 9.265391252989348]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 39)\n",
      "act action : 19\n",
      "reward: 27.94139119326877\n",
      "current reward: 27.94139119326877; current state: [28.703703703703702, 4.027284261895844]\n",
      "maximizing action\n",
      "[11.06832111  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 27.06916599485126\n",
      "current reward: 27.06916599485126; current state: [21.77777777777778, 14.139721150819755]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 59)\n",
      "act action : 19\n",
      "reward: 27.274130664312423\n",
      "current reward: 27.274130664312423; current state: [26.666666666666668, 1.849453250612748]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 9)\n",
      "act action : 19\n",
      "reward: 27.167839861778273\n",
      "current reward: 27.167839861778273; current state: [33.74074074074074, 2.199108121405667]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (137, 11)\n",
      "act action : 19\n",
      "reward: 27.290446012175227\n",
      "current reward: 27.290446012175227; current state: [24.22222222222222, 7.428378376280758]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 31)\n",
      "act action : 19\n",
      "reward: 29.35949062166287\n",
      "current reward: 29.35949062166287; current state: [20.555555555555557, 4.278756939723907]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 19)\n",
      "act action : 19\n",
      "reward: 27.48478254690238\n",
      "current reward: 27.48478254690238; current state: [24.22222222222222, 7.064887979209031]\n",
      "maximizing action\n",
      "[5.87189812 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 31)\n",
      "act action : 19\n",
      "reward: 29.179279135496348\n",
      "current reward: 29.179279135496348; current state: [25.88888888888889, 4.074807198941299]\n",
      "maximizing action\n",
      "[17.29643467  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 19)\n",
      "act action : 19\n",
      "reward: 28.930541451890644\n",
      "current reward: 28.930541451890644; current state: [27.074074074074073, 6.503651133790803]\n",
      "maximizing action\n",
      "[28.67424623  0.          0.          5.58040631  0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 27.23616458101124\n",
      "current reward: 27.23616458101124; current state: [27.074074074074073, 2.4198720837403647]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 11)\n",
      "act action : 19\n",
      "reward: 26.823616624187622\n",
      "current reward: 26.823616624187622; current state: [29.11111111111111, 4.002348266569516]\n",
      "maximizing action\n",
      "[29.58181114  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 27.039154835723433\n",
      "current reward: 27.039154835723433; current state: [26.666666666666668, 3.940094426549098]\n",
      "maximizing action\n",
      "[5.52549545 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 17)\n",
      "act action : 19\n",
      "reward: 27.41923598835852\n",
      "current reward: 27.41923598835852; current state: [24.22222222222222, 7.221992311168929]\n",
      "maximizing action\n",
      "[11.70775395  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 31)\n",
      "act action : 19\n",
      "reward: 27.244742273880536\n",
      "current reward: 27.244742273880536; current state: [31.22222222222222, 4.208485105962116]\n",
      "maximizing action\n",
      "[5.27761907 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 19)\n",
      "act action : 19\n",
      "reward: 27.391076597137545\n",
      "current reward: 27.391076597137545; current state: [27.88888888888889, 7.417211181709662]\n",
      "maximizing action\n",
      "[5.58143657 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 31)\n",
      "act action : 19\n",
      "reward: 29.19236405514103\n",
      "current reward: 29.19236405514103; current state: [28.703703703703702, 4.856897597611845]\n",
      "maximizing action\n",
      "[28.55154405  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 27.572574864575785\n",
      "current reward: 27.572574864575785; current state: [27.444444444444443, 6.609499124007353]\n",
      "maximizing action\n",
      "[34.12147915  0.          0.          5.58040631  0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 27.747831057075075\n",
      "current reward: 27.747831057075075; current state: [23.0, 11.578996015934855]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 49)\n",
      "act action : 19\n",
      "reward: 27.537741701246144\n",
      "current reward: 27.537741701246144; current state: [20.555555555555557, 9.357522539531985]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 39)\n",
      "act action : 19\n",
      "reward: 29.273626629809957\n",
      "current reward: 29.273626629809957; current state: [25.444444444444443, 2.598164765818296]\n",
      "maximizing action\n",
      "[11.02764916  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 13)\n",
      "act action : 19\n",
      "reward: 29.04276139238226\n",
      "current reward: 29.04276139238226; current state: [28.703703703703702, 6.78951037116524]\n",
      "maximizing action\n",
      "[16.92072397  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 29)\n",
      "act action : 19\n",
      "reward: 27.69576409301069\n",
      "current reward: 27.69576409301069; current state: [28.703703703703702, 5.25039647285109]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         17.14369579]\n",
      "Current action = 33, current state (117, 23)\n",
      "act action : 33\n",
      "reward: 27.949857814569842\n",
      "current reward: 27.949857814569842; current state: [29.962962962962962, 2.590739796565158]\n",
      "maximizing action\n",
      "[28.80359159  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 13)\n",
      "act action : 19\n",
      "reward: 29.72016332699224\n",
      "current reward: 29.72016332699224; current state: [30.333333333333332, 2.25842186840167]\n",
      "maximizing action\n",
      "[11.42344457  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (123, 11)\n",
      "act action : 19\n",
      "reward: 28.367855014485315\n",
      "current reward: 28.367855014485315; current state: [25.444444444444443, 8.028154860145325]\n",
      "maximizing action\n",
      "[10.98085968  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 27.937173123055274\n",
      "current reward: 27.937173123055274; current state: [26.666666666666668, 5.055289110192591]\n",
      "maximizing action\n",
      "[28.64208719  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.6685120597155\n",
      "current reward: 29.6685120597155; current state: [26.666666666666668, 7.7032525527533275]\n",
      "maximizing action\n",
      "[17.15334859  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 27.744221562506414\n",
      "current reward: 27.744221562506414; current state: [29.962962962962962, 4.513471197203655]\n",
      "maximizing action\n",
      "[51.5592219   5.53773411  0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 29.599996756794678\n",
      "current reward: 29.599996756794678; current state: [24.925925925925927, 4.287904812005613]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 19)\n",
      "act action : 19\n",
      "reward: 28.000550355782412\n",
      "current reward: 28.000550355782412; current state: [25.444444444444443, 5.204022665329648]\n",
      "maximizing action\n",
      "[17.2277889  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 27.3561319595016\n",
      "current reward: 27.3561319595016; current state: [25.444444444444443, 7.511691781510337]\n",
      "maximizing action\n",
      "[16.47097908  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 27.66284590219855\n",
      "current reward: 27.66284590219855; current state: [24.22222222222222, 4.235383584594059]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 19)\n",
      "act action : 19\n",
      "reward: 27.38505559766898\n",
      "current reward: 27.38505559766898; current state: [32.48148148148148, 0.049772468714448244]\n",
      "maximizing action\n",
      "[11.52527471  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 3)\n",
      "act action : 19\n",
      "reward: 27.67807094046594\n",
      "current reward: 27.67807094046594; current state: [29.962962962962962, 5.831382195505674]\n",
      "maximizing action\n",
      "[28.65774406  0.          5.73517676  0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 25)\n",
      "act action : 19\n",
      "reward: 29.29829373904637\n",
      "current reward: 29.29829373904637; current state: [30.814814814814813, 2.9107974875291065]\n",
      "maximizing action\n",
      "[5.95579091 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 13)\n",
      "act action : 19\n",
      "reward: 27.52810576359334\n",
      "current reward: 27.52810576359334; current state: [32.111111111111114, 3.8563307203887205]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (131, 17)\n",
      "act action : 19\n",
      "reward: 27.789958156731327\n",
      "current reward: 27.789958156731327; current state: [29.51851851851852, 3.9910190278511597]\n",
      "maximizing action\n",
      "[23.0258201  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 27.229187208579535\n",
      "current reward: 27.229187208579535; current state: [28.22222222222222, 6.451142637247061]\n",
      "maximizing action\n",
      "[17.60155218  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 27)\n",
      "act action : 19\n",
      "reward: 30.806039243662564\n",
      "current reward: 30.806039243662564; current state: [28.22222222222222, 10.76239243586667]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (115, 45)\n",
      "act action : 19\n",
      "reward: 29.09361736603583\n",
      "current reward: 29.09361736603583; current state: [29.51851851851852, 4.265829415717698]\n",
      "maximizing action\n",
      "[11.18963905  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 27.662040455766782\n",
      "current reward: 27.662040455766782; current state: [30.333333333333332, 6.071289434291019]\n",
      "maximizing action\n",
      "[5.77702074 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 27)\n",
      "act action : 19\n",
      "reward: 30.00303470557418\n",
      "current reward: 30.00303470557418; current state: [26.333333333333332, 4.550239108259702]\n",
      "maximizing action\n",
      "[22.96572297  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 21)\n",
      "act action : 19\n",
      "reward: 27.44358751687572\n",
      "current reward: 27.44358751687572; current state: [23.037037037037038, 6.518252904424121]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 29)\n",
      "act action : 19\n",
      "reward: 28.823920032305825\n",
      "current reward: 28.823920032305825; current state: [32.111111111111114, 3.168738358481844]\n",
      "maximizing action\n",
      "[ 0.         17.17248209  0.          0.          0.          0.        ]\n",
      "Current action = 22, current state (131, 15)\n",
      "act action : 22\n",
      "reward: 27.272987585070968\n",
      "current reward: 27.272987585070968; current state: [29.962962962962962, 3.873813509552114]\n",
      "maximizing action\n",
      "[28.47165754  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 27.556549501975535\n",
      "current reward: 27.556549501975535; current state: [26.185185185185187, 6.986081130668111]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (107, 29)\n",
      "act action : 19\n",
      "reward: 27.195343025808643\n",
      "current reward: 27.195343025808643; current state: [29.962962962962962, 5.215659236147065]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 27.250055824759162\n",
      "current reward: 27.250055824759162; current state: [28.25925925925926, 4.265540457419148]\n",
      "maximizing action\n",
      "[34.6394252  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 27.572531910127434\n",
      "current reward: 27.572531910127434; current state: [27.074074074074073, 7.971550727364668]\n",
      "maximizing action\n",
      "[16.59598906  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 33)\n",
      "act action : 19\n",
      "reward: 29.317384018812835\n",
      "current reward: 29.317384018812835; current state: [25.88888888888889, 5.272284370930712]\n",
      "maximizing action\n",
      "[29.23449845  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 27.694070416759985\n",
      "current reward: 27.694070416759985; current state: [25.11111111111111, 2.9387183269166437]\n",
      "maximizing action\n",
      "[16.83620144  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 13)\n",
      "act action : 19\n",
      "reward: 29.1794609566434\n",
      "current reward: 29.1794609566434; current state: [25.88888888888889, 4.944499223688667]\n",
      "maximizing action\n",
      "[5.60859268 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (105, 21)\n",
      "act action : 19\n",
      "reward: 29.44417113498439\n",
      "current reward: 29.44417113498439; current state: [23.51851851851852, 11.05376044776226]\n",
      "maximizing action\n",
      "[5.7125532 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (97, 47)\n",
      "act action : 19\n",
      "reward: 28.137927858957198\n",
      "current reward: 28.137927858957198; current state: [23.51851851851852, 4.599451571344804]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 21)\n",
      "act action : 19\n",
      "reward: 29.25137402089088\n",
      "current reward: 29.25137402089088; current state: [27.88888888888889, 2.0573225475301338]\n",
      "maximizing action\n",
      "[6.0601376 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (113, 11)\n",
      "act action : 19\n",
      "reward: 27.972732312499428\n",
      "current reward: 27.972732312499428; current state: [29.11111111111111, 4.001162802746147]\n",
      "maximizing action\n",
      "[34.98964211  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 27.99468591717802\n",
      "current reward: 27.99468591717802; current state: [27.88888888888889, 6.793370695060751]\n",
      "maximizing action\n",
      "[5.70314447 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 29)\n",
      "act action : 19\n",
      "reward: 29.640946432410804\n",
      "current reward: 29.640946432410804; current state: [27.88888888888889, 4.165576699301486]\n",
      "maximizing action\n",
      "[28.18014953  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 29.853978180634353\n",
      "current reward: 29.853978180634353; current state: [32.77777777777778, 0.5726460495961905]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 5)\n",
      "act action : 19\n",
      "reward: 28.436792537244134\n",
      "current reward: 28.436792537244134; current state: [27.444444444444443, 8.049653428005998]\n",
      "maximizing action\n",
      "[11.11202727  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 28.708564362959603\n",
      "current reward: 28.708564362959603; current state: [23.666666666666668, 8.582133968370819]\n",
      "maximizing action\n",
      "[17.28681292  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 37)\n",
      "act action : 19\n",
      "reward: 28.768123452486595\n",
      "current reward: 28.768123452486595; current state: [28.703703703703702, 0.541323876346773]\n",
      "maximizing action\n",
      "[11.11371278  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 5)\n",
      "act action : 19\n",
      "reward: 29.00239078301036\n",
      "current reward: 29.00239078301036; current state: [25.444444444444443, 10.087560118039463]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 43)\n",
      "act action : 19\n",
      "reward: 28.751220775684715\n",
      "current reward: 28.751220775684715; current state: [26.185185185185187, 5.833514483057032]\n",
      "maximizing action\n",
      "[16.52751178  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 25)\n",
      "act action : 19\n",
      "reward: 30.01945171047313\n",
      "current reward: 30.01945171047313; current state: [29.962962962962962, 3.005110910762978]\n",
      "maximizing action\n",
      "[5.47824789 5.67556651 0.         0.         0.         0.        ]\n",
      "Current action = 22, current state (121, 15)\n",
      "act action : 22\n",
      "reward: 29.030566886829547\n",
      "current reward: 29.030566886829547; current state: [26.666666666666668, 8.730636653984888]\n",
      "maximizing action\n",
      "[6.10576244 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 29.902118018212093\n",
      "current reward: 29.902118018212093; current state: [23.666666666666668, 7.6175406177496985]\n",
      "maximizing action\n",
      "[11.03023935  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 33)\n",
      "act action : 19\n",
      "reward: 28.81116679257296\n",
      "current reward: 28.81116679257296; current state: [27.88888888888889, 0.7577536907180794]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (113, 5)\n",
      "act action : 19\n",
      "reward: 28.379896563333272\n",
      "current reward: 28.379896563333272; current state: [28.703703703703702, 4.2784729679343005]\n",
      "maximizing action\n",
      "[16.48215431  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 19)\n",
      "act action : 19\n",
      "reward: 28.65133842570908\n",
      "current reward: 28.65133842570908; current state: [28.703703703703702, 1.5799516997652476]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 9)\n",
      "act action : 19\n",
      "reward: 28.304905564430666\n",
      "current reward: 28.304905564430666; current state: [31.22222222222222, 0.8319941361394698]\n",
      "maximizing action\n",
      "[11.27731218  0.          0.          5.70873413  0.          0.        ]\n",
      "Current action = 19, current state (127, 5)\n",
      "act action : 19\n",
      "reward: 28.50079455745946\n",
      "current reward: 28.50079455745946; current state: [26.185185185185187, 9.004383867359062]\n",
      "maximizing action\n",
      "[11.26377  0.       0.       0.       0.       0.     ]\n",
      "Current action = 19, current state (107, 39)\n",
      "act action : 19\n",
      "reward: 31.086176469388345\n",
      "current reward: 31.086176469388345; current state: [24.925925925925927, 7.301748961800274]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 31)\n",
      "act action : 19\n",
      "reward: 28.139835271845854\n",
      "current reward: 28.139835271845854; current state: [28.22222222222222, 4.887406272641469]\n",
      "maximizing action\n",
      "[11.70485802  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 28.320360186412042\n",
      "current reward: 28.320360186412042; current state: [28.22222222222222, 5.099376406014208]\n",
      "maximizing action\n",
      "[16.49716395  0.          5.92901028  0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 23)\n",
      "act action : 19\n",
      "reward: 29.071041917781926\n",
      "current reward: 29.071041917781926; current state: [25.62962962962963, 7.725184843711236]\n",
      "maximizing action\n",
      "[11.03624765  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 33)\n",
      "act action : 19\n",
      "reward: 28.54873122266578\n",
      "current reward: 28.54873122266578; current state: [25.62962962962963, 1.6398226503252586]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 9)\n",
      "act action : 19\n",
      "reward: 28.73279021979863\n",
      "current reward: 28.73279021979863; current state: [26.925925925925927, 2.3047415682878234]\n",
      "maximizing action\n",
      "[11.2792637  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 11)\n",
      "act action : 19\n",
      "reward: 28.538220585394175\n",
      "current reward: 28.538220585394175; current state: [29.0, 3.8755792470755956]\n",
      "maximizing action\n",
      "[11.05796239  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 17)\n",
      "act action : 19\n",
      "reward: 29.834996231892518\n",
      "current reward: 29.834996231892518; current state: [29.962962962962962, 4.254804702610082]\n",
      "maximizing action\n",
      "[16.72204715  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 28.39268880379582\n",
      "current reward: 28.39268880379582; current state: [32.111111111111114, 3.937241531089605]\n",
      "maximizing action\n",
      "[5.55799163 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 17)\n",
      "act action : 19\n",
      "reward: 29.73327900782049\n",
      "current reward: 29.73327900782049; current state: [29.51851851851852, 3.401269375738938]\n",
      "maximizing action\n",
      "[ 5.47824789 11.48167988  0.          0.          0.          0.        ]\n",
      "Current action = 22, current state (121, 15)\n",
      "act action : 22\n",
      "reward: 27.886248455177096\n",
      "current reward: 27.886248455177096; current state: [28.22222222222222, 5.193643499684477]\n",
      "maximizing action\n",
      "[22.31137233  0.          5.92901028  0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 23)\n",
      "act action : 19\n",
      "reward: 29.17663129679386\n",
      "current reward: 29.17663129679386; current state: [25.62962962962963, 7.231426627326311]\n",
      "maximizing action\n",
      "[21.59657646  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 31.039905978302688\n",
      "current reward: 31.039905978302688; current state: [27.444444444444443, 5.650760955678201]\n",
      "maximizing action\n",
      "[28.38540818  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 25)\n",
      "act action : 19\n",
      "reward: 28.191126317783514\n",
      "current reward: 28.191126317783514; current state: [24.22222222222222, 11.220438143881747]\n",
      "maximizing action\n",
      "[5.50967524 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 47)\n",
      "act action : 19\n",
      "reward: 28.42008385257635\n",
      "current reward: 28.42008385257635; current state: [30.333333333333332, 0.04835039817974972]\n",
      "exploring action\n",
      "Current action = 28, current state (123, 3)\n",
      "act action : 28\n",
      "reward: 28.15206454921128\n",
      "current reward: 28.15206454921128; current state: [26.666666666666668, 10.537726897300196]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 45)\n",
      "act action : 19\n",
      "reward: 28.408633956308716\n",
      "current reward: 28.408633956308716; current state: [26.666666666666668, 5.4630135003793265]\n",
      "maximizing action\n",
      "[34.5757896  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (109, 23)\n",
      "act action : 19\n",
      "reward: 29.0308741743829\n",
      "current reward: 29.0308741743829; current state: [31.555555555555557, 1.9676311945557916]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (129, 9)\n",
      "act action : 19\n",
      "reward: 28.022024759408016\n",
      "current reward: 28.022024759408016; current state: [27.88888888888889, 6.338632350043878]\n",
      "maximizing action\n",
      "[17.25437687  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 29.443679130393264\n",
      "current reward: 29.443679130393264; current state: [25.444444444444443, 4.059668834885219]\n",
      "maximizing action\n",
      "[16.44412455  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 19)\n",
      "act action : 19\n",
      "reward: 29.13151787101798\n",
      "current reward: 29.13151787101798; current state: [27.88888888888889, 3.400893910707336]\n",
      "maximizing action\n",
      "[10.86736136  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 15)\n",
      "act action : 19\n",
      "reward: 27.860579335825168\n",
      "current reward: 27.860579335825168; current state: [30.62962962962963, 1.170075078902813]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (125, 7)\n",
      "act action : 19\n",
      "reward: 27.25074359600514\n",
      "current reward: 27.25074359600514; current state: [25.444444444444443, 8.342272420840443]\n",
      "maximizing action\n",
      "[16.56829431  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 35)\n",
      "act action : 19\n",
      "reward: 29.72410326359176\n",
      "current reward: 29.72410326359176; current state: [23.51851851851852, 3.2423224995674618]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 15)\n",
      "act action : 19\n",
      "reward: 27.675060872496818\n",
      "current reward: 27.675060872496818; current state: [24.703703703703702, 8.66182317297206]\n",
      "maximizing action\n",
      "[5.69965165 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 27.92649736873499\n",
      "current reward: 27.92649736873499; current state: [25.88888888888889, 4.111881915281698]\n",
      "maximizing action\n",
      "[23.08254296  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 19)\n",
      "act action : 19\n",
      "reward: 27.60192809591879\n",
      "current reward: 27.60192809591879; current state: [23.51851851851852, 7.506962367577585]\n",
      "maximizing action\n",
      "[16.79247271  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 33)\n",
      "act action : 19\n",
      "reward: 27.191678872333686\n",
      "current reward: 27.191678872333686; current state: [25.444444444444443, 6.026152021812283]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 27.267435228332076\n",
      "current reward: 27.267435228332076; current state: [27.074074074074073, 3.7317400301173773]\n",
      "maximizing action\n",
      "[5.41875944 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 27.580278215297927\n",
      "current reward: 27.580278215297927; current state: [21.14814814814815, 11.592153417096972]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 49)\n",
      "act action : 19\n",
      "reward: 29.418519312181058\n",
      "current reward: 29.418519312181058; current state: [23.51851851851852, 1.234037084017132]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 7)\n",
      "act action : 19\n",
      "reward: 27.749498686062925\n",
      "current reward: 27.749498686062925; current state: [29.11111111111111, 3.343601802524479]\n",
      "maximizing action\n",
      "[17.36206946  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 29.191282196382797\n",
      "current reward: 29.191282196382797; current state: [26.185185185185187, 7.845439521603726]\n",
      "maximizing action\n",
      "[21.82644011  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 33)\n",
      "act action : 19\n",
      "reward: 27.822655114553612\n",
      "current reward: 27.822655114553612; current state: [26.666666666666668, 1.7197518243952428]\n",
      "maximizing action\n",
      "[5.43356797 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 9)\n",
      "act action : 19\n",
      "reward: 29.542250616114583\n",
      "current reward: 29.542250616114583; current state: [29.962962962962962, 6.876841105039064]\n",
      "maximizing action\n",
      "[22.01625422  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 29)\n",
      "act action : 19\n",
      "reward: 28.128690178166938\n",
      "current reward: 28.128690178166938; current state: [27.444444444444443, 8.236717446885294]\n",
      "maximizing action\n",
      "[16.85374014  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 31.196448000016407\n",
      "current reward: 31.196448000016407; current state: [27.88888888888889, 2.60912955447156]\n",
      "maximizing action\n",
      "[21.59810827  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 13)\n",
      "act action : 19\n",
      "reward: 27.981992018797516\n",
      "current reward: 27.981992018797516; current state: [27.444444444444443, 8.20438128000685]\n",
      "maximizing action\n",
      "[23.09302974  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 28.345292451830378\n",
      "current reward: 28.345292451830378; current state: [27.444444444444443, 6.179333702648528]\n",
      "maximizing action\n",
      "[16.57668093  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.233816815511222\n",
      "current reward: 28.233816815511222; current state: [24.333333333333332, 10.397419458154115]\n",
      "maximizing action\n",
      "[17.01069822  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 43)\n",
      "act action : 19\n",
      "reward: 28.49725602996159\n",
      "current reward: 28.49725602996159; current state: [28.22222222222222, 7.328399069608643]\n",
      "maximizing action\n",
      "[16.68572688  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 31)\n",
      "act action : 19\n",
      "reward: 29.871732423015875\n",
      "current reward: 29.871732423015875; current state: [28.703703703703702, 5.437580530671111]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         22.73366736]\n",
      "Current action = 33, current state (117, 23)\n",
      "act action : 33\n",
      "reward: 29.760137594907196\n",
      "current reward: 29.760137594907196; current state: [27.444444444444443, 2.7800615372613984]\n",
      "maximizing action\n",
      "[5.46157679 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (111, 13)\n",
      "act action : 19\n",
      "reward: 28.57384720104046\n",
      "current reward: 28.57384720104046; current state: [29.962962962962962, 3.285811622268633]\n",
      "maximizing action\n",
      "[ 5.47824789 18.10666628  0.          0.          0.          0.        ]\n",
      "Current action = 22, current state (121, 15)\n",
      "act action : 22\n",
      "reward: 28.13197100903524\n",
      "current reward: 28.13197100903524; current state: [30.814814814814813, 2.9923173801906233]\n",
      "exploring action\n",
      "Current action = 28, current state (125, 13)\n",
      "act action : 28\n",
      "reward: 28.380098854647542\n",
      "current reward: 28.380098854647542; current state: [28.22222222222222, 4.24161581122582]\n",
      "maximizing action\n",
      "[40.15393158  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 19)\n",
      "act action : 19\n",
      "reward: 29.72875073088868\n",
      "current reward: 29.72875073088868; current state: [31.666666666666668, 1.8085898346539497]\n",
      "maximizing action\n",
      "[5.60440495 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (129, 9)\n",
      "act action : 19\n",
      "reward: 28.5073460235207\n",
      "current reward: 28.5073460235207; current state: [29.51851851851852, 7.045907586743957]\n",
      "maximizing action\n",
      "[10.78822861  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 31)\n",
      "act action : 19\n",
      "reward: 28.66803071986745\n",
      "current reward: 28.66803071986745; current state: [28.703703703703702, 5.868367054498576]\n",
      "maximizing action\n",
      "[11.70954559  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 25)\n",
      "act action : 19\n",
      "reward: 29.98742429814816\n",
      "current reward: 29.98742429814816; current state: [28.22222222222222, 7.7623648504370975]\n",
      "maximizing action\n",
      "[5.56669772 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (115, 33)\n",
      "act action : 19\n",
      "reward: 28.780140832238555\n",
      "current reward: 28.780140832238555; current state: [23.037037037037038, 13.127025820344759]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (95, 55)\n",
      "act action : 19\n",
      "reward: 28.78048049449636\n",
      "current reward: 28.78048049449636; current state: [26.925925925925927, 3.5183417709780076]\n",
      "maximizing action\n",
      "[11.00934265  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 17)\n",
      "act action : 19\n",
      "reward: 28.989270950336632\n",
      "current reward: 28.989270950336632; current state: [29.51851851851852, 3.6235475492290967]\n",
      "maximizing action\n",
      "[33.98296744  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.78936588078169\n",
      "current reward: 29.78936588078169; current state: [28.703703703703702, 3.5527972091816453]\n",
      "maximizing action\n",
      "[11.71781542  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 17)\n",
      "act action : 19\n",
      "reward: 28.637187633967013\n",
      "current reward: 28.637187633967013; current state: [27.444444444444443, 7.065882164119154]\n",
      "maximizing action\n",
      "[16.39144832  0.          0.          6.03870247  5.7243492   0.        ]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 28.665853700496214\n",
      "current reward: 28.665853700496214; current state: [30.333333333333332, 2.661981630387997]\n",
      "maximizing action\n",
      "[5.6944226 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (123, 13)\n",
      "act action : 19\n",
      "reward: 29.167779644731965\n",
      "current reward: 29.167779644731965; current state: [27.444444444444443, 8.041996662124989]\n",
      "maximizing action\n",
      "[28.76208823  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 35)\n",
      "act action : 19\n",
      "reward: 28.67099386312874\n",
      "current reward: 28.67099386312874; current state: [25.444444444444443, 11.533788778426562]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (103, 49)\n",
      "act action : 19\n",
      "reward: 28.755149505079\n",
      "current reward: 28.755149505079; current state: [32.48148148148148, 0.651910584069001]\n",
      "maximizing action\n",
      "[5.56060477 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (131, 5)\n",
      "act action : 19\n",
      "reward: 28.889623314567164\n",
      "current reward: 28.889623314567164; current state: [28.703703703703702, 5.49581433073684]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.          0.         28.68569488]\n",
      "Current action = 33, current state (117, 23)\n",
      "act action : 33\n",
      "reward: 29.10353484247614\n",
      "current reward: 29.10353484247614; current state: [22.40740740740741, 9.944097802818714]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 41)\n",
      "act action : 19\n",
      "reward: 28.901460714513203\n",
      "current reward: 28.901460714513203; current state: [26.925925925925927, 6.10996075853793]\n",
      "maximizing action\n",
      "[10.95104338  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 27)\n",
      "act action : 19\n",
      "reward: 28.856799625229158\n",
      "current reward: 28.856799625229158; current state: [25.444444444444443, 4.970547716170909]\n",
      "maximizing action\n",
      "[6.03787885 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 21)\n",
      "act action : 19\n",
      "reward: 31.643612694779847\n",
      "current reward: 31.643612694779847; current state: [27.88888888888889, 6.468577951877734]\n",
      "maximizing action\n",
      "[23.14311269  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 29.242475754723927\n",
      "current reward: 29.242475754723927; current state: [25.444444444444443, 4.909637707044521]\n",
      "exploring action\n",
      "Current action = 22, current state (103, 21)\n",
      "act action : 22\n",
      "reward: 29.311765462106262\n",
      "current reward: 29.311765462106262; current state: [24.703703703703702, 6.370967538039832]\n",
      "maximizing action\n",
      "[5.51980863 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 27)\n",
      "act action : 19\n",
      "reward: 29.260079588151907\n",
      "current reward: 29.260079588151907; current state: [29.11111111111111, 4.453739791438856]\n",
      "maximizing action\n",
      "[40.58857929  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (119, 19)\n",
      "act action : 19\n",
      "reward: 30.526303172178768\n",
      "current reward: 30.526303172178768; current state: [30.333333333333332, 3.410673536963987]\n",
      "maximizing action\n",
      "[5.81979558 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 15)\n",
      "act action : 19\n",
      "reward: 28.801285045137675\n",
      "current reward: 28.801285045137675; current state: [24.22222222222222, 12.794366394387282]\n",
      "maximizing action\n",
      "[5.85134317 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (99, 53)\n",
      "act action : 19\n",
      "reward: 29.80877321517845\n",
      "current reward: 29.80877321517845; current state: [31.555555555555557, 1.876356230901705]\n",
      "maximizing action\n",
      "[11.30587416  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (129, 9)\n",
      "act action : 19\n",
      "reward: 29.228358217898062\n",
      "current reward: 29.228358217898062; current state: [31.22222222222222, 2.3196024410848803]\n",
      "maximizing action\n",
      "[ 0.          0.         17.50398368  0.          0.          0.        ]\n",
      "Current action = 25, current state (127, 11)\n",
      "act action : 25\n",
      "reward: 27.724764130537363\n",
      "current reward: 27.724764130537363; current state: [26.666666666666668, 8.719097595683323]\n",
      "maximizing action\n",
      "[12.08618604  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 29.456244577298012\n",
      "current reward: 29.456244577298012; current state: [21.77777777777778, 7.157971778037062]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (89, 31)\n",
      "act action : 19\n",
      "reward: 29.132150989194\n",
      "current reward: 29.132150989194; current state: [25.444444444444443, 5.1989437634347135]\n",
      "maximizing action\n",
      "[22.6990153  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (103, 23)\n",
      "act action : 19\n",
      "reward: 29.11879425794074\n",
      "current reward: 29.11879425794074; current state: [26.666666666666668, 7.887965995210924]\n",
      "maximizing action\n",
      "[22.70219291  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 33)\n",
      "act action : 19\n",
      "reward: 29.313215691964313\n",
      "current reward: 29.313215691964313; current state: [24.22222222222222, 7.864538763707652]\n",
      "maximizing action\n",
      "[16.82861516  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 33)\n",
      "act action : 19\n",
      "reward: 28.854428144910656\n",
      "current reward: 28.854428144910656; current state: [26.666666666666668, 10.70219409387104]\n",
      "maximizing action\n",
      "[5.68172679 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 45)\n",
      "act action : 19\n",
      "reward: 28.742364485335404\n",
      "current reward: 28.742364485335404; current state: [28.555555555555557, 1.9428274689750362]\n",
      "maximizing action\n",
      "[5.66098111 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 9)\n",
      "act action : 19\n",
      "reward: 28.964442557073113\n",
      "current reward: 28.964442557073113; current state: [23.962962962962962, 6.449119698491533]\n",
      "maximizing action\n",
      "[11.22473929  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 27)\n",
      "act action : 19\n",
      "reward: 28.28580799997547\n",
      "current reward: 28.28580799997547; current state: [28.25925925925926, 4.702205136041242]\n",
      "maximizing action\n",
      "[17.35834686  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 28.453736306951882\n",
      "current reward: 28.453736306951882; current state: [27.074074074074073, 4.685265925229994]\n",
      "exploring action\n",
      "Current action = 25, current state (111, 21)\n",
      "act action : 25\n",
      "reward: 28.603727901858445\n",
      "current reward: 28.603727901858445; current state: [27.074074074074073, 4.618659694370781]\n",
      "maximizing action\n",
      "[16.81728121  0.          5.72074558  0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 21)\n",
      "act action : 19\n",
      "reward: 28.27044760994902\n",
      "current reward: 28.27044760994902; current state: [24.703703703703702, 4.661778689697626]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 21)\n",
      "act action : 19\n",
      "reward: 27.38626133200529\n",
      "current reward: 27.38626133200529; current state: [17.59259259259259, 12.01420238775792]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (73, 51)\n",
      "act action : 19\n",
      "reward: 28.744861801110243\n",
      "current reward: 28.744861801110243; current state: [23.51851851851852, 7.479467925084253]\n",
      "maximizing action\n",
      "[11.01734506  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 27.67963351291979\n",
      "current reward: 27.67963351291979; current state: [30.62962962962963, 1.190843576519361]\n",
      "maximizing action\n",
      "[5.45014872 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (125, 7)\n",
      "act action : 19\n",
      "reward: 29.358591335926366\n",
      "current reward: 29.358591335926366; current state: [27.074074074074073, 6.4481117714783185]\n",
      "exploring action\n",
      "Current action = 25, current state (111, 27)\n",
      "act action : 25\n",
      "reward: 26.454579715526\n",
      "current reward: 26.454579715526; current state: [25.444444444444443, 9.977440738411692]\n",
      "maximizing action\n",
      "[17.22544603  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 41)\n",
      "act action : 19\n",
      "reward: 27.838611656076313\n",
      "current reward: 27.838611656076313; current state: [30.333333333333332, 3.8829437243796834]\n",
      "maximizing action\n",
      "[5.6886322 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (123, 17)\n",
      "act action : 19\n",
      "reward: 28.12882478543028\n",
      "current reward: 28.12882478543028; current state: [30.333333333333332, 6.015292717975831]\n",
      "maximizing action\n",
      "[11.77762768  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (123, 27)\n",
      "act action : 19\n",
      "reward: 28.350079500748816\n",
      "current reward: 28.350079500748816; current state: [27.88888888888889, 6.253711801370944]\n",
      "maximizing action\n",
      "[28.99160784  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 27)\n",
      "act action : 19\n",
      "reward: 26.43095566458834\n",
      "current reward: 26.43095566458834; current state: [26.666666666666668, 4.749248783834298]\n",
      "maximizing action\n",
      "[16.46947251  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 21)\n",
      "act action : 19\n",
      "reward: 27.782858386816567\n",
      "current reward: 27.782858386816567; current state: [28.703703703703702, 1.3629708874630437]\n",
      "maximizing action\n",
      "[5.96757932 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (117, 7)\n",
      "act action : 19\n",
      "reward: 28.409177441151844\n",
      "current reward: 28.409177441151844; current state: [27.444444444444443, 6.196356358929415]\n",
      "maximizing action\n",
      "[22.2234443   0.          5.29091594  0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 26.498703036014486\n",
      "current reward: 26.498703036014486; current state: [27.444444444444443, 6.505778371059058]\n",
      "maximizing action\n",
      "[39.67104536  0.          0.          5.58040631  0.          0.        ]\n",
      "Current action = 19, current state (111, 29)\n",
      "act action : 19\n",
      "reward: 26.266969412307844\n",
      "current reward: 26.266969412307844; current state: [25.62962962962963, 7.075623621635463]\n",
      "maximizing action\n",
      "[27.80455765  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 31)\n",
      "act action : 19\n",
      "reward: 30.46273504456231\n",
      "current reward: 30.46273504456231; current state: [28.22222222222222, 4.634039592254432]\n",
      "maximizing action\n",
      "[23.04909412  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 26.43015195342704\n",
      "current reward: 26.43015195342704; current state: [30.814814814814813, 4.096203113188437]\n",
      "maximizing action\n",
      "[11.36099334  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 19)\n",
      "act action : 19\n",
      "reward: 26.523916125147867\n",
      "current reward: 26.523916125147867; current state: [28.703703703703702, 8.319261654259439]\n",
      "maximizing action\n",
      "[11.78622785  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 35)\n",
      "act action : 19\n",
      "reward: 28.500556337109668\n",
      "current reward: 28.500556337109668; current state: [28.22222222222222, 2.7884358826476583]\n",
      "maximizing action\n",
      "[16.89452352  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 13)\n",
      "act action : 19\n",
      "reward: 28.144291562882\n",
      "current reward: 28.144291562882; current state: [27.444444444444443, 3.0243674778943186]\n",
      "maximizing action\n",
      "[10.90490531  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 15)\n",
      "act action : 19\n",
      "reward: 26.872309357627714\n",
      "current reward: 26.872309357627714; current state: [28.703703703703702, 2.5292906845071057]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 13)\n",
      "act action : 19\n",
      "reward: 26.965419165791673\n",
      "current reward: 26.965419165791673; current state: [29.51851851851852, 5.308057795564181]\n",
      "maximizing action\n",
      "[5.45001116 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 27.202897412203317\n",
      "current reward: 27.202897412203317; current state: [30.814814814814813, 6.11992663972408]\n",
      "maximizing action\n",
      "[11.57495725  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 27)\n",
      "act action : 19\n",
      "reward: 26.838949430945508\n",
      "current reward: 26.838949430945508; current state: [27.444444444444443, 3.5401973691941757]\n",
      "maximizing action\n",
      "[10.93481508  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 17)\n",
      "act action : 19\n",
      "reward: 27.053185777482582\n",
      "current reward: 27.053185777482582; current state: [23.666666666666668, 7.332134252475573]\n",
      "maximizing action\n",
      "[16.55327176  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (97, 31)\n",
      "act action : 19\n",
      "reward: 26.69170225075784\n",
      "current reward: 26.69170225075784; current state: [25.62962962962963, 5.31109827870603]\n",
      "maximizing action\n",
      "[34.77331254  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 27.02821743083213\n",
      "current reward: 27.02821743083213; current state: [28.22222222222222, 4.560034576143597]\n",
      "maximizing action\n",
      "[28.33512451  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 21)\n",
      "act action : 19\n",
      "reward: 27.242727331206293\n",
      "current reward: 27.242727331206293; current state: [23.666666666666668, 12.457217430819265]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 51)\n",
      "act action : 19\n",
      "reward: 27.278170099900375\n",
      "current reward: 27.278170099900375; current state: [26.925925925925927, 3.366505927157782]\n",
      "maximizing action\n",
      "[5.66475413 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (109, 15)\n",
      "act action : 19\n",
      "reward: 27.539363960249943\n",
      "current reward: 27.539363960249943; current state: [29.51851851851852, 4.619676688687271]\n",
      "maximizing action\n",
      "[57.47922125  5.53773411  0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 21)\n",
      "act action : 19\n",
      "reward: 28.47394752253761\n",
      "current reward: 28.47394752253761; current state: [27.666666666666668, 11.159333067436764]\n",
      "maximizing action\n",
      "[5.72663955 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (113, 47)\n",
      "act action : 19\n",
      "reward: 27.78425769619649\n",
      "current reward: 27.78425769619649; current state: [27.666666666666668, 1.863503200929186]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.         11.67311359  0.        ]\n",
      "Current action = 31, current state (113, 9)\n",
      "act action : 31\n",
      "reward: 28.025167547528707\n",
      "current reward: 28.025167547528707; current state: [29.0, 4.812702086142872]\n",
      "maximizing action\n",
      "[ 0.          0.         17.32563479  0.          0.          0.        ]\n",
      "Current action = 25, current state (119, 21)\n",
      "act action : 25\n",
      "reward: 28.123515192991523\n",
      "current reward: 28.123515192991523; current state: [29.0, 3.396279519102918]\n",
      "maximizing action\n",
      "[23.2003259  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (119, 15)\n",
      "act action : 19\n",
      "reward: 28.37059758935366\n",
      "current reward: 28.37059758935366; current state: [29.0, 7.889909099072773]\n",
      "maximizing action\n",
      "[ 0.          0.         11.03645172  0.          0.          0.        ]\n",
      "Current action = 25, current state (119, 33)\n",
      "act action : 25\n",
      "reward: 28.372429777245816\n",
      "current reward: 28.372429777245816; current state: [33.888888888888886, 2.8304123555665757]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (137, 13)\n",
      "act action : 19\n",
      "reward: 28.449325530245854\n",
      "current reward: 28.449325530245854; current state: [30.333333333333332, 3.744696885705362]\n",
      "maximizing action\n",
      "[11.31439716  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (123, 17)\n",
      "act action : 19\n",
      "reward: 28.04866461726316\n",
      "current reward: 28.04866461726316; current state: [27.666666666666668, 8.81851105456871]\n",
      "maximizing action\n",
      "[11.56728672  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 37)\n",
      "act action : 19\n",
      "reward: 28.23549150634788\n",
      "current reward: 28.23549150634788; current state: [28.22222222222222, 5.886806033889037]\n",
      "maximizing action\n",
      "[ 0.          0.          0.          0.         21.44178957  0.        ]\n",
      "Current action = 31, current state (115, 25)\n",
      "act action : 31\n",
      "reward: 28.3694753594491\n",
      "current reward: 28.3694753594491; current state: [29.962962962962962, 5.24034581127089]\n",
      "maximizing action\n",
      "[10.89059065  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 23)\n",
      "act action : 19\n",
      "reward: 28.44697003182341\n",
      "current reward: 28.44697003182341; current state: [32.48148148148148, 1.6533549510582577]\n",
      "maximizing action\n",
      "[10.88399042  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 29.25714205248217\n",
      "current reward: 29.25714205248217; current state: [26.666666666666668, 7.151782162740066]\n",
      "maximizing action\n",
      "[16.59594833  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 31)\n",
      "act action : 19\n",
      "reward: 26.844267411141796\n",
      "current reward: 26.844267411141796; current state: [28.703703703703702, 4.997346070052479]\n",
      "maximizing action\n",
      "[34.06605902  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 21)\n",
      "act action : 19\n",
      "reward: 28.185312574901513\n",
      "current reward: 28.185312574901513; current state: [29.962962962962962, 4.270030428535652]\n",
      "maximizing action\n",
      "[22.40058491  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 19)\n",
      "act action : 19\n",
      "reward: 29.233429629521822\n",
      "current reward: 29.233429629521822; current state: [27.444444444444443, 6.441472704598239]\n",
      "maximizing action\n",
      "[27.5231849   0.          5.29091594  0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.998746451333787\n",
      "current reward: 28.998746451333787; current state: [28.703703703703702, 8.281251582159493]\n",
      "maximizing action\n",
      "[17.48633912  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (117, 35)\n",
      "act action : 19\n",
      "reward: 28.737099719607794\n",
      "current reward: 28.737099719607794; current state: [29.962962962962962, 3.7465845605390076]\n",
      "maximizing action\n",
      "[39.94084062  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 17)\n",
      "act action : 19\n",
      "reward: 29.001396726146627\n",
      "current reward: 29.001396726146627; current state: [24.333333333333332, 8.308036296603756]\n",
      "maximizing action\n",
      "[11.42165386  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (99, 35)\n",
      "act action : 19\n",
      "reward: 29.140747223289946\n",
      "current reward: 29.140747223289946; current state: [24.925925925925927, 4.181186992491899]\n",
      "maximizing action\n",
      "[5.60011007 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (101, 19)\n",
      "act action : 19\n",
      "reward: 29.751058995936337\n",
      "current reward: 29.751058995936337; current state: [29.51851851851852, 7.049718196292952]\n",
      "maximizing action\n",
      "[16.52183475  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (121, 31)\n",
      "act action : 19\n",
      "reward: 28.933737225471557\n",
      "current reward: 28.933737225471557; current state: [27.444444444444443, 0.2804390884746588]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (111, 3)\n",
      "act action : 19\n",
      "reward: 29.097903960312706\n",
      "current reward: 29.097903960312706; current state: [24.22222222222222, 9.764812076889681]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (99, 41)\n",
      "act action : 19\n",
      "reward: 30.15229921920448\n",
      "current reward: 30.15229921920448; current state: [27.88888888888889, 3.5768937716147224]\n",
      "maximizing action\n",
      "[22.82182157  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (113, 17)\n",
      "act action : 19\n",
      "reward: 28.77087436811304\n",
      "current reward: 28.77087436811304; current state: [25.88888888888889, 5.348350194034079]\n",
      "maximizing action\n",
      "[40.17895602  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 23)\n",
      "act action : 19\n",
      "reward: 29.16819979995181\n",
      "current reward: 29.16819979995181; current state: [24.703703703703702, 6.659872342459545]\n",
      "maximizing action\n",
      "[16.71842206  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 29)\n",
      "act action : 19\n",
      "reward: 29.325831034479776\n",
      "current reward: 29.325831034479776; current state: [26.25925925925926, 5.169923665178688]\n",
      "maximizing action\n",
      "[44.02842765  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 28.45707164592495\n",
      "current reward: 28.45707164592495; current state: [26.555555555555557, 1.2865962682719]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 7)\n",
      "act action : 19\n",
      "reward: 27.753153258076352\n",
      "current reward: 27.753153258076352; current state: [26.25925925925926, 8.436028603478887]\n",
      "maximizing action\n",
      "[12.03643139  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 35)\n",
      "act action : 19\n",
      "reward: 28.363444815405913\n",
      "current reward: 28.363444815405913; current state: [25.444444444444443, 7.9294847657324015]\n",
      "maximizing action\n",
      "[22.00354826  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 33)\n",
      "act action : 19\n",
      "reward: 29.24406747214178\n",
      "current reward: 29.24406747214178; current state: [26.555555555555557, 4.246240008448374]\n",
      "maximizing action\n",
      "[44.12566845  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 19)\n",
      "act action : 19\n",
      "reward: 27.97965134185173\n",
      "current reward: 27.97965134185173; current state: [25.444444444444443, 6.9957814005626835]\n",
      "maximizing action\n",
      "[5.61024402 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 29)\n",
      "act action : 19\n",
      "reward: 27.60230977814072\n",
      "current reward: 27.60230977814072; current state: [20.51851851851852, 7.743952358587525]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (85, 33)\n",
      "act action : 19\n",
      "reward: 27.690709896984895\n",
      "current reward: 27.690709896984895; current state: [21.0, 7.656296961784526]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (87, 33)\n",
      "act action : 19\n",
      "reward: 27.851508902129\n",
      "current reward: 27.851508902129; current state: [25.444444444444443, 6.206144554077749]\n",
      "maximizing action\n",
      "[5.45348705 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 27.417944133618978\n",
      "current reward: 27.417944133618978; current state: [25.11111111111111, 6.085628352664135]\n",
      "maximizing action\n",
      "[10.93707587  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 27.58853674304338\n",
      "current reward: 27.58853674304338; current state: [27.40740740740741, 5.180550449851465]\n",
      "exploring action\n",
      "Current action = 25, current state (111, 23)\n",
      "act action : 25\n",
      "reward: 27.675095399141366\n",
      "current reward: 27.675095399141366; current state: [24.703703703703702, 8.766583834859036]\n",
      "maximizing action\n",
      "[11.28495113  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 28.823968463282885\n",
      "current reward: 28.823968463282885; current state: [25.88888888888889, 5.931019095173474]\n",
      "maximizing action\n",
      "[16.7431436  0.         0.         0.         0.         0.       ]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 28.222552912394843\n",
      "current reward: 28.222552912394843; current state: [25.88888888888889, 8.071616962251243]\n",
      "maximizing action\n",
      "[11.20211483  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 35)\n",
      "act action : 19\n",
      "reward: 29.843364550334798\n",
      "current reward: 29.843364550334798; current state: [27.88888888888889, 4.149542232200748]\n",
      "exploring action\n",
      "Current action = 19, current state (113, 19)\n",
      "act action : 19\n",
      "reward: 29.152021347232843\n",
      "current reward: 29.152021347232843; current state: [27.88888888888889, 4.491126088537878]\n",
      "exploring action\n",
      "Current action = 22, current state (113, 19)\n",
      "act action : 22\n",
      "reward: 28.50070873406899\n",
      "current reward: 28.50070873406899; current state: [32.48148148148148, 1.5824331892088896]\n",
      "maximizing action\n",
      "[16.73541883  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (131, 9)\n",
      "act action : 19\n",
      "reward: 27.831609029445897\n",
      "current reward: 27.831609029445897; current state: [28.703703703703702, 7.603359729901981]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (117, 33)\n",
      "act action : 19\n",
      "reward: 29.045391674346657\n",
      "current reward: 29.045391674346657; current state: [23.666666666666668, 5.515426296171804]\n",
      "maximizing action\n",
      "[5.25209793 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (97, 25)\n",
      "act action : 19\n",
      "reward: 27.89366315762541\n",
      "current reward: 27.89366315762541; current state: [25.62962962962963, 0.2059264556170628]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 3)\n",
      "act action : 19\n",
      "reward: 27.980353246361872\n",
      "current reward: 27.980353246361872; current state: [29.962962962962962, 3.084162704825702]\n",
      "maximizing action\n",
      "[ 5.47824789 23.73306048  0.          0.          0.          0.        ]\n",
      "Current action = 22, current state (121, 15)\n",
      "act action : 22\n",
      "reward: 30.479268683106966\n",
      "current reward: 30.479268683106966; current state: [33.407407407407405, 1.130825339496869]\n",
      "maximizing action\n",
      "[5.75636788 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 7)\n",
      "act action : 19\n",
      "reward: 27.613376227466187\n",
      "current reward: 27.613376227466187; current state: [25.62962962962963, 5.62523990026282]\n",
      "maximizing action\n",
      "[22.38765419  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (105, 25)\n",
      "act action : 19\n",
      "reward: 27.398241673557465\n",
      "current reward: 27.398241673557465; current state: [23.666666666666668, 4.027860823595137]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (97, 19)\n",
      "act action : 19\n",
      "reward: 27.68184891651462\n",
      "current reward: 27.68184891651462; current state: [30.333333333333332, 4.169443936128834]\n",
      "maximizing action\n",
      "[5.23852825 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (123, 19)\n",
      "act action : 19\n",
      "reward: 27.90661470052093\n",
      "current reward: 27.90661470052093; current state: [30.333333333333332, 9.094811765202387]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 39)\n",
      "act action : 19\n",
      "reward: 28.64715208578882\n",
      "current reward: 28.64715208578882; current state: [32.51851851851852, 4.270295026753458]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 19)\n",
      "act action : 19\n",
      "reward: 28.230802418876166\n",
      "current reward: 28.230802418876166; current state: [35.25925925925926, 4.019519867975867]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (143, 19)\n",
      "act action : 19\n",
      "reward: 27.940910014517574\n",
      "current reward: 27.940910014517574; current state: [33.370370370370374, 4.105385092626152]\n",
      "maximizing action\n",
      "[5.90790324 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 19)\n",
      "act action : 19\n",
      "reward: 28.057007036785524\n",
      "current reward: 28.057007036785524; current state: [33.370370370370374, 0.05546075085324231]\n",
      "maximizing action\n",
      "[5.80326076 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 3)\n",
      "act action : 19\n",
      "reward: 29.575335758997813\n",
      "current reward: 29.575335758997813; current state: [33.370370370370374, 7.048466251114405]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 31)\n",
      "act action : 19\n",
      "reward: 28.249498146968858\n",
      "current reward: 28.249498146968858; current state: [30.555555555555557, 5.918559964305149]\n",
      "exploring action\n",
      "Current action = 19, current state (125, 25)\n",
      "act action : 19\n",
      "reward: 29.906206697637497\n",
      "current reward: 29.906206697637497; current state: [28.40740740740741, 6.842750010979414]\n",
      "maximizing action\n",
      "[27.35418451  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 29)\n",
      "act action : 19\n",
      "reward: 28.27812263614959\n",
      "current reward: 28.27812263614959; current state: [31.962962962962962, 3.779857988373953]\n",
      "maximizing action\n",
      "[28.14124385  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (129, 17)\n",
      "act action : 19\n",
      "reward: 28.392873924513633\n",
      "current reward: 28.392873924513633; current state: [29.14814814814815, 6.254494961658336]\n",
      "maximizing action\n",
      "[6.2664138 0.        0.        0.        0.        0.       ]\n",
      "Current action = 19, current state (119, 27)\n",
      "act action : 19\n",
      "reward: 29.377668453832086\n",
      "current reward: 29.377668453832086; current state: [22.11111111111111, 11.9875573306918]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (91, 49)\n",
      "act action : 19\n",
      "reward: 28.219536399256324\n",
      "current reward: 28.219536399256324; current state: [33.370370370370374, 2.2813390049954663]\n",
      "maximizing action\n",
      "[17.47681016  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (135, 11)\n",
      "act action : 19\n",
      "reward: 28.00852637098988\n",
      "current reward: 28.00852637098988; current state: [33.370370370370374, 4.781155990119428]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (135, 21)\n",
      "act action : 19\n",
      "reward: 28.04194799647892\n",
      "current reward: 28.04194799647892; current state: [28.40740740740741, 3.123259674188621]\n",
      "maximizing action\n",
      "[11.56490878  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (115, 15)\n",
      "act action : 19\n",
      "reward: 28.323193218086583\n",
      "current reward: 28.323193218086583; current state: [33.370370370370374, 3.0679605144557107]\n",
      "maximizing action\n",
      "[5.90105046 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (135, 15)\n",
      "act action : 19\n",
      "reward: 28.4164389262298\n",
      "current reward: 28.4164389262298; current state: [33.370370370370374, 4.66009684765603]\n",
      "exploring action\n",
      "Current action = 22, current state (135, 21)\n",
      "act action : 22\n",
      "reward: 30.033215231810818\n",
      "current reward: 30.033215231810818; current state: [32.51851851851852, 4.629049951077185]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (133, 21)\n",
      "act action : 19\n",
      "reward: 28.794370137598673\n",
      "current reward: 28.794370137598673; current state: [31.14814814814815, 6.373783227228358]\n",
      "maximizing action\n",
      "[5.89526096 0.         0.         0.         0.         0.        ]\n",
      "Current action = 19, current state (127, 27)\n",
      "act action : 19\n",
      "reward: 28.809506916749992\n",
      "current reward: 28.809506916749992; current state: [30.333333333333332, 0.6985453680377444]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (123, 5)\n",
      "act action : 19\n",
      "reward: 30.189651590609788\n",
      "current reward: 30.189651590609788; current state: [25.62962962962963, 12.80221491266989]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (105, 53)\n",
      "act action : 19\n",
      "reward: 28.04125317921158\n",
      "current reward: 28.04125317921158; current state: [30.814814814814813, 2.8093261097907973]\n",
      "maximizing action\n",
      "[11.46141206  0.          0.          5.67601977  0.          0.        ]\n",
      "Current action = 19, current state (125, 13)\n",
      "act action : 19\n",
      "reward: 28.905726018890416\n",
      "current reward: 28.905726018890416; current state: [24.925925925925927, 13.75848496392254]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (101, 57)\n",
      "act action : 19\n",
      "reward: 28.932222960786863\n",
      "current reward: 28.932222960786863; current state: [28.22222222222222, 8.827793108906144]\n",
      "exploring action\n",
      "Current action = 31, current state (115, 37)\n",
      "act action : 31\n",
      "reward: 29.109608055633903\n",
      "current reward: 29.109608055633903; current state: [26.666666666666668, 8.764136960404235]\n",
      "maximizing action\n",
      "[17.97743496  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (109, 37)\n",
      "act action : 19\n",
      "reward: 29.24817914788602\n",
      "current reward: 29.24817914788602; current state: [26.666666666666668, 12.239953255267343]\n",
      "maximizing action\n",
      "[0. 0. 0. 0. 0. 0.]\n",
      "Current action = 19, current state (109, 51)\n",
      "act action : 19\n",
      "reward: 30.137216452857604\n",
      "current reward: 30.137216452857604; current state: [27.444444444444443, 7.16621550088936]\n",
      "maximizing action\n",
      "[22.12461906  0.          0.          6.03870247  5.7243492   0.        ]\n",
      "Current action = 19, current state (111, 31)\n",
      "act action : 19\n",
      "reward: 28.812512428112598\n",
      "current reward: 28.812512428112598; current state: [25.444444444444443, 6.368658686946862]\n",
      "maximizing action\n",
      "[16.45478322  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (103, 27)\n",
      "act action : 19\n",
      "reward: 28.93567728511212\n",
      "current reward: 28.93567728511212; current state: [24.925925925925927, 8.974351389845783]\n",
      "maximizing action\n",
      "[17.04974482  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (101, 37)\n",
      "act action : 19\n",
      "reward: 29.805032721916845\n",
      "current reward: 29.805032721916845; current state: [27.444444444444443, 4.249595449763491]\n",
      "maximizing action\n",
      "[28.36355884  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 19)\n",
      "act action : 19\n",
      "reward: 28.291942996141405\n",
      "current reward: 28.291942996141405; current state: [30.814814814814813, 6.588210799179222]\n",
      "maximizing action\n",
      "[11.15433917  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (125, 29)\n",
      "act action : 19\n",
      "reward: 28.271266456462097\n",
      "current reward: 28.271266456462097; current state: [26.185185185185187, 5.320854060715732]\n",
      "maximizing action\n",
      "[49.71984198  0.          0.          0.          0.          0.        ]\n",
      "Current action = 19, current state (107, 23)\n",
      "act action : 19\n",
      "reward: 28.43444465108259\n",
      "current reward: 28.43444465108259; current state: [27.444444444444443, 6.126147918515208]\n",
      "maximizing action\n",
      "[33.32293419  0.          5.29091594  0.          0.          0.        ]\n",
      "Current action = 19, current state (111, 27)\n",
      "act action : 19\n",
      "reward: 28.18143805986404\n",
      "current reward: 28.18143805986404; current state: [26.185185185185187, 9.34328920056798]\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "action_space= np.array([19, 22, 25, 28, 31, 33])\n",
    "try:\n",
    "    for i in range(1):#episodes\n",
    "        print(f\"episode: {i}\")\n",
    "        initial_states = env.reset()\n",
    "        #print(env.observation_space)\n",
    "        action_space_size = len(env.action_space)\n",
    "        state_grid= create_uniform_grid(env.observation_space.low, env.observation_space.high, bins= (400,400))\n",
    "        ql_agents = QLAgent.QLAgent(starting_state=initial_states,\n",
    "                                    state_space=env.observation_space,\n",
    "                                    state_grid = state_grid,\n",
    "                                    action_space=env.action_space,\n",
    "                                    alpha=0.2,\n",
    "                                    gamma=0.99,\n",
    "                                    exploration_strategy=EpsilonGreedy.EpsilonGreedy())\n",
    "        #print(f\"action_space_size{action_space_size}\")\n",
    "        for t in range(1000):#time steps\n",
    "            actions =ql_agents.act()\n",
    "            print(f\"act action : {actions}\")\n",
    "            s, r, done, _ = env.step(action=actions)\n",
    "            print(f\"current reward: {r}; current state: {s}\")\n",
    "            ql_agents.learn(next_state=s, reward=r)\n",
    "            if done:\n",
    "                break\n",
    "        env.close()\n",
    "except ValueError:\n",
    "    print(traceback.format_exc())\n",
    "    env.close()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "88117a4c4f7db09762e85aecb2e581e7c8f40331f8439cb18f9752f946649d6e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
